+ echo Logging output to experiments/logs/res101_car_track1_test__res101.txt.2018-03-22_15-06-06
Logging output to experiments/logs/res101_car_track1_test__res101.txt.2018-03-22_15-06-06
+ set +x
+ '[' '!' -f output/res101/car_track1_test/default/res101_faster_rcnn_iter_1000.ckpt.index ']'
+ [[ ! -z '' ]]
+ CUDA_VISIBLE_DEVICES=0
+ time python ./tools/trainval_net.py --weight data/imagenet_weights/res101.ckpt --imdb car_track1_test --imdbval car_track1_1 --iters 1000 --cfg experiments/cfgs/res101.yml --net res101 --set ANCHOR_SCALES '[4,8,16,32]' ANCHOR_RATIOS '[0.5,1,2]' TRAIN.STEPSIZE '[1000]'
Called with args:
Namespace(cfg_file='experiments/cfgs/res101.yml', imdb_name='car_track1_test', imdbval_name='car_track1_1', max_iters=1000, net='res101', set_cfgs=['ANCHOR_SCALES', '[4,8,16,32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'TRAIN.STEPSIZE', '[1000]'], tag=None, weight='data/imagenet_weights/res101.ckpt')
Using config:
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [4, 8, 16, 32],
 'DATA_DIR': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data',
 'EXP_DIR': 'res101',
 'MATLAB': 'matlab',
 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,
               'FIXED_LAYERS': 5,
               'REGU_DEPTH': False,
               'WEIGHT_DECAY': 4e-05},
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},
 'RNG_SEED': 3,
 'ROOT_DIR': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn',
 'RPN_CHANNELS': 512,
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'MODE': 'nms',
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'gt',
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'RPN_TOP_N': 5000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': False,
           'BATCH_SIZE': 256,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'BIAS_DECAY': False,
           'DISPLAY': 20,
           'DOUBLE_BIAS': False,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'GAMMA': 0.1,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'LEARNING_RATE': 0.001,
           'MAX_SIZE': 1000,
           'MOMENTUM': 0.9,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_ITERS': 5000,
           'SNAPSHOT_KEPT': 3,
           'SNAPSHOT_PREFIX': 'res101_faster_rcnn',
           'STEPSIZE': [1000],
           'SUMMARY_INTERVAL': 180,
           'TRUNCATED': False,
           'USE_ALL_GT': True,
           'USE_FLIPPED': True,
           'USE_GT': False,
           'WEIGHT_DECAY': 0.0001},
 'USE_GPU_NMS': True}
Loaded dataset `car_track1_test` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
done
Preparing training data...
test
[]
wrote gt roidb to /media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/cache/car_track1_test_gt_roidb.pkl
done
0 roidb entries
Output will be saved to `/media/ad/DATA/aicitychallenge/tf-faster-rcnn/output/res101/car_track1_test/default`
TensorFlow summaries will be saved to `/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tensorboard/res101/car_track1_test/default`
Loaded dataset `car_track1_1` for training
Set proposal method: gt
Preparing training data...
car_track1_1 gt roidb loaded from /media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/cache/car_track1_1_gt_roidb.pkl
done
300 validation roidb entries
Filtered 0 roidb entries: 0 -> 0
Filtered 0 roidb entries: 300 -> 300
2018-03-22 15:06:07.276095: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-03-22 15:06:07.401082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-03-22 15:06:07.401314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6575
pciBusID: 0000:01:00.0
totalMemory: 10.91GiB freeMemory: 10.37GiB
2018-03-22 15:06:07.401324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0
2018-03-22 15:06:07.550379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10034 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
Solving...
[{'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00001.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1115,  911, 1244, 1024],
       [1427, 1018, 1573, 1045],
       [1528,  922, 1682, 1022],
       [1682,  886, 1823,  968],
       [1484,  728, 1600,  811],
       [1327,  718, 1407,  782],
       [1171,  676, 1286,  789],
       [ 432,  647,  540,  749],
       [ 738,  641,  798,  684],
       [ 609,  603,  653,  639],
       [ 663,  580,  702,  614],
       [1238,  595, 1290,  634],
       [1121,  547, 1184,  609],
       [1205,  574, 1246,  614],
       [1025,  543, 1059,  574],
       [1065,  538, 1103,  563],
       [ 688,  541,  721,  568],
       [ 740,  532,  777,  564]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([14820.,  4116., 15655., 11786.,  9828.,  5265., 13224., 11227.,
        2684.,  1665.,  1400.,  2120.,  4032.,  1722.,  1120.,  1014.,
         952.,  1254.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00002.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1136,  939, 1271, 1045],
       [1742,  901, 1919, 1024],
       [1213,  759, 1305,  838],
       [1307,  732, 1398,  797],
       [1438,  726, 1523,  784],
       [1046,  711, 1117,  774],
       [1103,  603, 1186,  686],
       [1223,  634, 1282,  684],
       [1340,  639, 1417,  699],
       [ 634,  753,  719,  826],
       [ 209,  732,  377,  884],
       [ 536,  645,  598,  695],
       [ 598,  613,  653,  657],
       [ 667,  564,  702,  591],
       [ 727,  530,  773,  584],
       [1073,  526, 1130,  580],
       [1173,  561, 1219,  593],
       [ 632,  524,  665,  555],
       [ 678,  524,  717,  555]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14552., 22072.,  7440.,  6072.,  5074.,  4608.,  7056.,  3060.,
        4758.,  6364., 25857.,  3213.,  2520.,  1008.,  2585.,  3190.,
        1551.,  1088.,  1280.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00003.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1121,  882, 1238,  978],
       [1473,  732, 1575,  803],
       [1050,  720, 1123,  780],
       [1130,  655, 1196,  711],
       [1207,  643, 1269,  689],
       [1315,  643, 1373,  684],
       [1255,  589, 1311,  639],
       [1161,  588, 1209,  624],
       [1009,  626, 1061,  670],
       [1067,  561, 1132,  624],
       [1125,  538, 1155,  564],
       [1036,  509, 1084,  553],
       [ 417,  718,  496,  784],
       [ 507,  659,  578,  722],
       [ 565,  636,  621,  684],
       [ 630,  591,  677,  628],
       [ 702,  555,  757,  626],
       [ 659,  541,  702,  580],
       [ 615,  538,  648,  568]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11446.,  7416.,  4514.,  3819.,  2961.,  2478.,  2907.,  1813.,
        2385.,  4224.,   837.,  2205.,  5360.,  4608.,  2793.,  1824.,
        4032.,  1760.,  1054.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00004.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1173, 1016, 1315, 1047],
       [1840,  976, 1919, 1044],
       [ 152,  845,  288,  953],
       [ 348,  738,  448,  820],
       [ 459,  693,  538,  751],
       [1050,  701, 1119,  759],
       [1336,  643, 1405,  697],
       [ 644,  601,  711,  686],
       [1015,  626, 1067,  666],
       [1082,  599, 1130,  638],
       [1144,  589, 1190,  626],
       [1232,  586, 1277,  626],
       [ 984,  576, 1021,  605],
       [1036,  532, 1088,  584],
       [1109,  555, 1148,  582],
       [ 569,  632,  628,  674],
       [ 577,  559,  619,  599],
       [ 632,  564,  688,  601],
       [ 794,  534,  827,  557]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4576.,  5520., 14933.,  8383.,  4720.,  4130.,  3850.,  5848.,
        2173.,  1960.,  1786.,  1886.,  1140.,  2809.,  1120.,  2580.,
        1763.,  2166.,   816.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00005.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1678, 1007, 1859, 1047],
       [1269,  807, 1384,  913],
       [1453,  764, 1648,  955],
       [1069,  739, 1146,  807],
       [  42,  880,  198, 1009],
       [ 280,  788,  390,  868],
       [ 530,  663,  630,  782],
       [ 471,  688,  540,  743],
       [1017,  618, 1065,  655],
       [1248,  595, 1298,  636],
       [ 992,  576, 1030,  609],
       [1046,  561, 1082,  591],
       [1096,  561, 1138,  588],
       [1169,  559, 1205,  588],
       [ 588,  576,  655,  647],
       [ 523,  584,  575,  636],
       [ 790,  563,  825,  597],
       [ 648,  555,  692,  591],
       [ 588,  559,  630,  593],
       [ 955,  543,  988,  568],
       [1005,  514, 1044,  559],
       [1069,  534, 1098,  559],
       [1134,  532, 1169,  566]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 7462., 12412., 37632.,  5382., 20410.,  8991., 12120.,  3920.,
        1862.,  2142.,  1326.,  1147.,  1204.,  1110.,  4896.,  2809.,
        1260.,  1665.,  1505.,   884.,  1840.,   780.,  1260.],
      dtype=float32), 'gt_overlaps': <23x16 sparse matrix of type '<type 'numpy.float32'>'
	with 23 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00006.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1092,  820, 1207,  932],
       [1290,  853, 1413,  953],
       [1717,  897, 1878,  993],
       [1394,  778, 1500,  859],
       [1159,  682, 1230,  747],
       [1290,  655, 1411,  772],
       [   2,  970,   86, 1047],
       [ 278,  795,  467,  982],
       [ 515,  616,  607,  705],
       [ 444,  624,  505,  684],
       [1023,  636, 1078,  678],
       [ 761,  607,  807,  643],
       [ 613,  584,  665,  632],
       [ 542,  588,  590,  626],
       [1184,  563, 1232,  599],
       [ 990,  568, 1028,  601],
       [1119,  536, 1152,  564],
       [ 659,  538,  694,  561]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([13108., 12524., 15714.,  8774.,  4752., 14396.,  6630., 35720.,
        8370.,  3782.,  2408.,  1739.,  2597.,  1911.,  1813.,  1326.,
         986.,   864.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00007.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1117,  978, 1255, 1047],
       [1323,  886, 1459,  980],
       [1478,  859, 1617,  972],
       [1457,  730, 1550,  788],
       [1165,  699, 1240,  763],
       [1263,  672, 1336,  730],
       [1034,  672, 1105,  741],
       [1102,  611, 1159,  663],
       [1200,  595, 1290,  682],
       [   0,  961,   99, 1053],
       [ 705,  678,  771,  738],
       [ 394,  676,  519,  784],
       [ 328,  678,  405,  751],
       [ 563,  622,  628,  674],
       [ 463,  632,  521,  676],
       [ 578,  597,  628,  624],
       [ 619,  559,  655,  589],
       [ 996,  580, 1036,  613],
       [1132,  538, 1173,  572],
       [ 696,  543,  728,  576],
       [ 959,  541,  990,  568]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9730., 13015., 15960.,  5546.,  4940.,  4366.,  5040.,  3074.,
        8008.,  9300.,  4087., 13734.,  5772.,  3498.,  2655.,  1428.,
        1147.,  1394.,  1470.,  1122.,   896.], dtype=float32), 'gt_overlaps': <21x16 sparse matrix of type '<type 'numpy.float32'>'
	with 21 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00008.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1152,  963, 1290, 1045],
       [1498,  876, 1634,  966],
       [1046,  739, 1119,  799],
       [1177,  714, 1257,  774],
       [1307,  716, 1394,  786],
       [1317,  645, 1380,  686],
       [1105,  628, 1159,  672],
       [1190,  611, 1244,  655],
       [1005,  603, 1059,  649],
       [1063,  572, 1107,  613],
       [1142,  557, 1217,  626],
       [ 548,  845,  661,  941],
       [ 148,  776,  350,  938],
       [ 330,  693,  407,  751],
       [ 471,  672,  557,  738],
       [ 482,  638,  542,  680],
       [ 555,  591,  602,  626],
       [ 652,  574,  692,  607],
       [ 694,  547,  730,  582],
       [ 800,  551,  830,  586],
       [ 859,  555,  894,  582],
       [ 619,  543,  646,  568],
       [ 969,  547, 1002,  574]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11537., 12467.,  4514.,  4941.,  6248.,  2688.,  2475.,  2475.,
        2585.,  1890.,  5320., 11058., 33089.,  4602.,  5829.,  2623.,
        1728.,  1394.,  1332.,  1116.,  1008.,   728.,   952.],
      dtype=float32), 'gt_overlaps': <23x16 sparse matrix of type '<type 'numpy.float32'>'
	with 23 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00009.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1821,  997, 1919, 1045],
       [1267,  830, 1384,  918],
       [1467,  828, 1590,  926],
       [1059,  732, 1134,  795],
       [1319,  726, 1402,  788],
       [1019,  643, 1069,  684],
       [1115,  630, 1163,  676],
       [1219,  636, 1284,  689],
       [1232,  595, 1282,  628],
       [ 311,  751,  434,  849],
       [ 119,  788,  232,  866],
       [ 327,  707,  417,  755],
       [ 471,  636,  528,  672],
       [ 582,  613,  632,  653],
       [ 644,  574,  688,  626],
       [ 782,  595,  825,  628],
       [ 853,  591,  900,  634],
       [ 588,  561,  627,  593],
       [1065,  578, 1105,  614],
       [1138,  574, 1180,  609],
       [ 980,  561, 1023,  595],
       [ 728,  563,  763,  593],
       [ 861,  553,  894,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4851., 10502., 12276.,  4864.,  5292.,  2142.,  2303.,  3564.,
        1734., 12276.,  9006.,  4459.,  2146.,  2091.,  2385.,  1496.,
        2112.,  1320.,  1517.,  1548.,  1540.,  1116.,   884.],
      dtype=float32), 'gt_overlaps': <23x16 sparse matrix of type '<type 'numpy.float32'>'
	with 23 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00010.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1107,  838, 1228,  949],
       [1490,  753, 1594,  834],
       [1305,  699, 1384,  759],
       [1161,  693, 1234,  747],
       [1230,  647, 1288,  691],
       [1027,  638, 1078,  680],
       [1161,  593, 1207,  632],
       [1071,  582, 1111,  614],
       [1171,  559, 1211,  591],
       [ 996,  586, 1036,  620],
       [1028,  547, 1067,  578],
       [1096,  545, 1132,  576],
       [   0,  907,  186, 1043],
       [  75,  813,  203,  895],
       [ 342,  693,  419,  747],
       [ 477,  674,  544,  728],
       [ 571,  618,  628,  670],
       [ 738,  659,  796,  711],
       [ 834,  655,  894,  709],
       [ 773,  613,  819,  651],
       [ 690,  603,  736,  639],
       [ 542,  589,  592,  632],
       [ 628,  591,  673,  624],
       [ 861,  588,  900,  628],
       [ 794,  520,  832,  570]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([13664.,  8610.,  4880.,  4070.,  2655.,  2236.,  1880.,  1353.,
        1353.,  1435.,  1280.,  1184., 25619., 10707.,  4290.,  3740.,
        3074.,  3127.,  3355.,  1833.,  1739.,  2244.,  1564.,  1640.,
        1989.], dtype=float32), 'gt_overlaps': <25x16 sparse matrix of type '<type 'numpy.float32'>'
	with 25 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00011.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1600,  961, 1796, 1045],
       [1052,  686, 1127,  751],
       [1342,  651, 1411,  705],
       [1217,  626, 1271,  676],
       [1103,  616, 1157,  661],
       [1173,  595, 1219,  632],
       [1002,  582, 1042,  614],
       [1113,  559, 1155,  593],
       [1036,  549, 1073,  576],
       [ 969,  553, 1007,  580],
       [ 773,  782,  865,  870],
       [ 611,  793,  709,  874],
       [ 275,  776,  382,  855],
       [ 121,  791,  230,  870],
       [ 450,  686,  532,  759],
       [ 702,  693,  771,  749],
       [ 836,  653,  890,  705],
       [ 607,  666,  675,  722],
       [ 465,  632,  521,  676],
       [ 565,  636,  623,  678],
       [ 536,  588,  582,  626],
       [ 609,  595,  661,  639],
       [ 846,  593,  909,  653],
       [ 778,  549,  827,  605],
       [ 734,  545,  765,  578],
       [ 684,  538,  713,  561]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16745.,  5016.,  3850.,  2805.,  2530.,  1786.,  1353.,  1505.,
        1064.,  1092.,  8277.,  8118.,  8640.,  8800.,  6142.,  3990.,
        2915.,  3933.,  2565.,  2537.,  1833.,  2385.,  3904.,  2850.,
        1088.,   720.], dtype=float32), 'gt_overlaps': <26x16 sparse matrix of type '<type 'numpy.float32'>'
	with 26 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00012.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1594,  816, 1753,  939],
       [1359,  757, 1473,  839],
       [1067,  776, 1163,  851],
       [ 523,  863,  646,  963],
       [ 773,  778,  861,  863],
       [ 200,  799,  342,  905],
       [ 427,  797,  534,  880],
       [ 811,  659,  898,  757],
       [ 453,  699,  536,  755],
       [ 530,  641,  602,  695],
       [ 336,  691,  411,  749],
       [ 459,  630,  528,  674],
       [ 748,  572,  811,  664],
       [ 717,  578,  752,  607],
       [1025,  614, 1075,  659],
       [1252,  589, 1305,  634],
       [1165,  586, 1203,  620],
       [1065,  572, 1107,  611],
       [1125,  564, 1163,  591]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19840.,  9545.,  7372., 12524.,  7654., 15301.,  9072.,  8712.,
        4788.,  4015.,  4484.,  3150.,  5952.,  1080.,  2346.,  2484.,
        1365.,  1720.,  1092.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00013.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 721,  807,  857,  986],
       [ 242,  813,  363,  895],
       [ 105,  791,  223,  866],
       [ 394,  709,  484,  789],
       [ 665,  632,  773,  757],
       [ 332,  682,  413,  749],
       [1027,  661, 1088,  709],
       [1248,  664, 1323,  722],
       [1403,  682, 1503,  759],
       [ 992,  570, 1027,  607],
       [1117,  559, 1157,  588],
       [1186,  557, 1228,  589],
       [ 794,  570,  830,  601],
       [ 713,  572,  750,  611],
       [ 640,  576,  675,  607]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([24660., 10126.,  9044.,  7371., 13734.,  5576.,  3038.,  4484.,
        7878.,  1368.,  1230.,  1419.,  1184.,  1520.,  1152.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00014.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 119,  841,  273,  966],
       [ 102,  776,  221,  868],
       [ 494,  754,  683,  979],
       [ 663,  741,  738,  807],
       [ 584,  684,  648,  736],
       [ 657,  616,  717,  682],
       [ 763,  613,  815,  663],
       [ 594,  607,  634,  651],
       [ 634,  572,  680,  613],
       [ 577,  564,  619,  603],
       [1565,  797, 1678,  870],
       [1296,  609, 1365,  666],
       [1177,  605, 1234,  651],
       [1000,  599, 1048,  638],
       [1128,  532, 1165,  559],
       [ 967,  539, 1000,  563]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([19530., 11160., 42940.,  5092.,  3445.,  4087.,  2703.,  1845.,
        1974.,  1720.,  8436.,  4060.,  2726.,  1960.,  1064.,   850.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00015.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 415,  980,  573, 1045],
       [ 405,  795,  513,  874],
       [1403, 1014, 1555, 1047],
       [1444,  847, 1561,  924],
       [1536,  772, 1644,  847],
       [1234,  786, 1327,  863],
       [1384,  680, 1453,  730],
       [ 692,  693,  763,  766],
       [ 555,  680,  644,  770],
       [ 527,  659,  586,  709],
       [ 590,  605,  642,  651],
       [ 519,  601,  567,  639],
       [ 578,  564,  623,  601],
       [1221,  568, 1271,  611],
       [1132,  572, 1175,  607],
       [ 980,  561, 1017,  588]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([10494.,  8720.,  5202.,  9204.,  8284.,  7332.,  3570.,  5328.,
        8190.,  3060.,  2491.,  1911.,  1748.,  2244.,  1584.,  1064.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00016.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 500,  859,  630,  974],
       [ 334,  809,  486,  957],
       [ 400,  726,  484,  793],
       [ 515,  653,  584,  707],
       [ 428,  645,  488,  699],
       [ 505,  603,  567,  649],
       [1321,  918, 1467, 1038],
       [1425,  801, 1529,  880],
       [1084,  799, 1178,  876],
       [1213,  761, 1303,  832],
       [1290,  707, 1365,  764],
       [1369,  664, 1438,  716],
       [1140,  670, 1202,  713],
       [1275,  609, 1327,  657],
       [1152,  536, 1198,  572],
       [1088,  543, 1128,  574],
       [ 853,  547,  900,  605],
       [ 725,  561,  759,  591],
       [ 625,  532,  667,  564]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15196., 22797.,  5780.,  3850.,  3355.,  2961., 17787.,  8400.,
        7410.,  6552.,  4408.,  3710.,  2772.,  2597.,  1739.,  1312.,
        2832.,  1085.,  1419.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00017.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 157,  855,  292,  957],
       [ 382,  716,  473,  801],
       [ 265,  724,  353,  789],
       [ 390,  655,  475,  714],
       [1382,  974, 1573, 1045],
       [1584,  966, 1753, 1039],
       [1638,  861, 1777,  941],
       [1405,  795, 1513,  876],
       [1182,  730, 1265,  799],
       [1277,  684, 1352,  739],
       [1132,  659, 1190,  703],
       [1209,  638, 1261,  680],
       [1271,  601, 1325,  645],
       [1032,  655, 1094,  701],
       [1080,  607, 1134,  641],
       [1202,  574, 1248,  605],
       [ 844,  589,  903,  664],
       [ 688,  607,  734,  643],
       [ 598,  549,  640,  589],
       [ 667,  557,  692,  591],
       [ 792,  547,  832,  576],
       [1100,  520, 1136,  549]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14008.,  7912.,  5874.,  5160., 13824., 12580., 11340.,  8938.,
        5880.,  4256.,  2655.,  2279.,  2475.,  2961.,  1925.,  1504.,
        4560.,  1739.,  1763.,   910.,  1230.,  1110.], dtype=float32), 'gt_overlaps': <22x16 sparse matrix of type '<type 'numpy.float32'>'
	with 22 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00018.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 111,  857,  259,  978],
       [   0,  857,  100,  955],
       [ 175,  741,  311,  832],
       [ 605,  678,  675,  728],
       [ 809,  664,  892,  768],
       [1200,  743, 1303,  832],
       [1515,  897, 1648,  993],
       [1369,  768, 1461,  839],
       [1402,  705, 1478,  755],
       [1277,  688, 1348,  738],
       [1113,  638, 1167,  689],
       [1200,  628, 1255,  661],
       [1155,  597, 1198,  620],
       [1198,  570, 1252,  603],
       [1090,  601, 1128,  636],
       [1009,  591, 1049,  622],
       [1046,  566, 1084,  591],
       [ 552,  572,  605,  630],
       [ 623,  588,  669,  616],
       [ 661,  557,  703,  599],
       [ 784,  570,  827,  614]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18178.,  9999., 12604.,  3621.,  8820.,  9360., 12998.,  6696.,
        3927.,  3672.,  2860.,  1904.,  1056.,  1870.,  1404.,  1312.,
        1014.,  3186.,  1363.,  1849.,  1980.], dtype=float32), 'gt_overlaps': <21x16 sparse matrix of type '<type 'numpy.float32'>'
	with 21 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00019.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 705,  826,  850, 1018],
       [ 421,  809,  532,  891],
       [1515,  761, 1636,  838],
       [1325,  736, 1402,  801],
       [1252,  674, 1321,  724],
       [1278,  622, 1338,  659],
       [1200,  624, 1252,  668],
       [1123,  643, 1192,  703],
       [1071,  589, 1113,  628],
       [1144,  582, 1182,  616],
       [ 855,  609,  900,  641],
       [ 742,  613,  802,  663],
       [ 552,  632,  617,  678],
       [ 482,  607,  544,  668],
       [ 617,  597,  667,  632],
       [ 725,  563,  767,  595],
       [ 855,  549,  892,  586],
       [ 598,  566,  625,  593],
       [1040,  561, 1077,  588],
       [1111,  563, 1146,  591],
       [ 975,  553, 1013,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28178.,  9296.,  9516.,  5148.,  3570.,  2318.,  2385.,  4270.,
        1720.,  1365.,  1518.,  3111.,  3102.,  3906.,  1836.,  1419.,
        1444.,   784.,  1064.,  1044.,  1014.], dtype=float32), 'gt_overlaps': <21x16 sparse matrix of type '<type 'numpy.float32'>'
	with 21 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00020.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 425,  705,  511,  764],
       [ 363,  657,  448,  728],
       [ 536,  643,  600,  695],
       [ 669,  678,  755,  751],
       [ 825,  693,  888,  749],
       [1361,  657, 1432,  716],
       [1227,  657, 1282,  699],
       [1080,  586, 1128,  628],
       [1177,  614, 1230,  653],
       [1146,  578, 1188,  616],
       [1202,  576, 1250,  607],
       [ 686,  599,  734,  643],
       [ 861,  589,  902,  624],
       [ 546,  593,  582,  626],
       [ 603,  557,  634,  588],
       [1032,  553, 1071,  588],
       [1100,  553, 1136,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([5220., 6192., 3445., 6438., 3648., 4320., 2408., 2107., 2160.,
       1677., 1568., 2205., 1512., 1258., 1024., 1440.,  962.],
      dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00021.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1148,  955, 1315, 1041],
       [1669,  874, 1809,  963],
       [ 728,  866,  838,  970],
       [ 528,  799,  659,  918],
       [ 165,  838,  302,  932],
       [ 390,  720,  492,  797],
       [ 602,  664,  667,  728],
       [ 842,  655,  896,  707],
       [ 144,  741,  277,  847],
       [ 465,  639,  517,  678],
       [ 553,  576,  592,  618],
       [1267,  603, 1315,  643],
       [1167,  605, 1213,  647],
       [1115,  580, 1159,  609],
       [1038,  551, 1090,  582],
       [1146,  549, 1182,  580],
       [ 663,  566,  698,  597]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([14616., 12690., 11655., 15840., 13110.,  8034.,  4290.,  2915.,
       14338.,  2120.,  1720.,  2009.,  2021.,  1350.,  1696.,  1184.,
        1152.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00022.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  84,  868,  252,  989],
       [ 423,  784,  530,  882],
       [ 773,  788,  859,  864],
       [1061,  718, 1150,  795],
       [1396,  697, 1463,  747],
       [1196,  566, 1240,  595],
       [1121,  566, 1157,  597],
       [ 323,  705,  396,  761],
       [ 477,  620,  528,  659],
       [ 613,  607,  665,  638],
       [ 719,  563,  744,  589],
       [ 794,  547,  834,  589],
       [1053,  549, 1088,  576]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20618., 10692.,  6699.,  7020.,  3468.,  1350.,  1184.,  4218.,
        2080.,  1696.,   702.,  1763.,  1008.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00023.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  34,  824,  159,  911],
       [ 357,  674,  427,  728],
       [ 534,  659,  598,  701],
       [ 680,  605,  727,  639],
       [ 761,  582,  823,  641],
       [ 582,  572,  628,  611],
       [ 655,  547,  692,  584],
       [1032,  620, 1086,  674],
       [1261,  613, 1315,  653],
       [1248,  793, 1348,  872],
       [1469,  838, 1600,  938],
       [1090,  545, 1125,  572],
       [1144,  547, 1182,  574]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11088.,  3905.,  2795.,  1680.,  3780.,  1880.,  1444.,  3025.,
        2255.,  8080., 13332.,  1008.,  1092.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00024.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 132,  776,  242,  845],
       [ 375,  747,  467,  813],
       [1228,  778, 1321,  845],
       [1284,  689, 1363,  747],
       [1150,  674, 1211,  720],
       [ 717,  636,  794,  720],
       [ 613,  661,  673,  714],
       [ 515,  605,  569,  647],
       [ 623,  561,  673,  616],
       [1009,  568, 1053,  603],
       [1184,  568, 1227,  597],
       [ 738,  549,  777,  578],
       [ 819,  551,  848,  580],
       [ 673,  557,  705,  595]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([7770., 6231., 6392., 4720., 2914., 6630., 3294., 2365., 2856.,
       1620., 1320., 1200.,  900., 1287.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00025.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  19,  926,  188, 1043],
       [ 473,  764,  565,  838],
       [ 619,  734,  727,  843],
       [ 411,  655,  478,  711],
       [ 567,  609,  628,  672],
       [ 634,  588,  675,  632],
       [ 713,  576,  757,  609],
       [ 798,  588,  840,  618],
       [ 659,  551,  694,  586],
       [1138,  663, 1200,  711],
       [1200,  614, 1252,  663],
       [1092,  609, 1142,  645],
       [ 994,  532, 1028,  570]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20060.,  6975., 11990.,  3876.,  3968.,  1890.,  1530.,  1333.,
        1296.,  3087.,  2650.,  1887.,  1365.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00026.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 219,  747,  315,  807],
       [ 455,  663,  540,  738],
       [ 134,  964,  530, 1045],
       [1327,  895, 1459,  993],
       [1728,  911, 1892, 1003],
       [1082,  793, 1165,  861],
       [1092,  607, 1132,  641],
       [1140,  564, 1182,  599],
       [1052,  568, 1090,  595],
       [ 755,  647,  813,  699],
       [ 667,  624,  719,  666],
       [ 557,  639,  625,  684],
       [ 615,  584,  663,  636],
       [ 784,  564,  825,  611],
       [ 717,  570,  753,  605]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 5917.,  6536., 32554., 13167., 15345.,  5796.,  1435.,  1548.,
        1092.,  3127.,  2279.,  3174.,  2597.,  2016.,  1332.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00027.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1421,  805, 1544,  893],
       [1453,  732, 1544,  789],
       [1182,  718, 1253,  766],
       [1027,  651, 1078,  691],
       [1048,  564, 1096,  597],
       [ 654,  759,  735,  830],
       [ 238,  766,  378,  889],
       [ 423,  709,  511,  782],
       [ 578,  699,  648,  757],
       [ 538,  639,  594,  688],
       [ 686,  613,  728,  643],
       [ 757,  597,  811,  655],
       [ 717,  561,  757,  603],
       [ 796,  547,  827,  583]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([11036.,  5336.,  3528.,  2132.,  1666.,  5904., 17484.,  6586.,
        4189.,  2850.,  1333.,  3245.,  1763.,  1184.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00028.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 148,  845,  296,  963],
       [ 369,  838,  498,  939],
       [ 384,  716,  469,  782],
       [ 611,  666,  677,  718],
       [ 705,  657,  773,  732],
       [ 677,  599,  734,  657],
       [ 778,  588,  823,  624],
       [1325,  905, 1467, 1009],
       [1465,  805, 1567,  876],
       [1277,  674, 1350,  739],
       [1319,  647, 1384,  688],
       [1107,  626, 1163,  668],
       [1002,  586, 1040,  626]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17731., 13260.,  5762.,  3551.,  5244.,  3422.,  1702., 15015.,
        7416.,  4884.,  2772.,  2451.,  1599.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00029.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  48,  868,  203,  999],
       [ 473,  764,  565,  843],
       [ 596,  761,  696,  857],
       [ 594,  657,  688,  734],
       [ 744,  632,  803,  686],
       [ 527,  599,  573,  638],
       [ 625,  599,  667,  634],
       [ 577,  561,  619,  597],
       [1128,  959, 1275, 1045],
       [1411,  986, 1573, 1045],
       [1715,  905, 1865,  995],
       [1175,  709, 1252,  766],
       [1332,  680, 1400,  732],
       [1188,  609, 1250,  659],
       [1238,  593, 1280,  630],
       [1075,  578, 1113,  607],
       [ 790,  569,  823,  598]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([20592.,  7440.,  9797.,  7410.,  3300.,  1880.,  1548.,  1591.,
       12876.,  9780., 13741.,  4524.,  3657.,  3213.,  1634.,  1170.,
        1020.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00030.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 340, 1003,  503, 1039],
       [ 136, 1013,  275, 1043],
       [ 427,  759,  580,  864],
       [ 665,  714,  744,  786],
       [1052,  716, 1128,  788],
       [1202,  738, 1286,  807],
       [1427,  713, 1507,  766],
       [1109,  620, 1155,  657],
       [1248,  618, 1300,  645],
       [ 530,  657,  590,  699],
       [ 421,  653,  484,  701],
       [ 517,  599,  571,  639],
       [ 767,  607,  821,  643],
       [1130,  570, 1184,  618],
       [ 573,  561,  628,  605],
       [ 853,  582,  898,  620]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 6068.,  4340., 16324.,  5840.,  5621.,  5950.,  4374.,  1786.,
        1484.,  2623.,  3136.,  2255.,  2035.,  2695.,  2520.,  1794.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00031.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  40,  993,  311, 1051],
       [ 488,  876,  623, 1001],
       [ 332,  766,  427,  836],
       [ 221,  747,  313,  813],
       [ 417,  645,  488,  701],
       [ 500,  599,  567,  651],
       [ 719,  670,  777,  720],
       [ 846,  641,  892,  691],
       [1759,  832, 1919, 1047],
       [1452,  828, 1573,  918],
       [1123,  638, 1177,  688],
       [1294,  624, 1344,  664],
       [1017,  622, 1069,  663],
       [ 757,  603,  807,  636],
       [ 627,  605,  669,  636],
       [1194,  578, 1236,  601],
       [1061,  574, 1096,  603]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([16048., 17136.,  6816.,  6231.,  4104.,  3604.,  3009.,  2397.,
       34776., 11102.,  2805.,  2091.,  2226.,  1734.,  1376.,  1032.,
        1080.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00032.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1234,  803, 1334,  882],
       [1478,  672, 1773,  914],
       [1275,  676, 1344,  736],
       [ 794,  757,  869,  838],
       [ 588,  789,  686,  874],
       [ 236,  726,  332,  799],
       [ 377,  655,  463,  726],
       [ 519,  664,  584,  718],
       [ 707,  666,  773,  718],
       [ 477,  624,  530,  670],
       [ 848,  603,  890,  638],
       [ 773,  593,  815,  626],
       [1071,  582, 1121,  618],
       [1209,  576, 1255,  613],
       [ 984,  566, 1017,  601],
       [ 719,  564,  757,  599]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 8080., 71928.,  4270.,  6232.,  8514.,  7178.,  6264.,  3630.,
        3551.,  2538.,  1548.,  1462.,  1887.,  1786.,  1224.,  1404.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00033.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1236,  955, 1390, 1041],
       [1127,  663, 1194,  713],
       [1332,  601, 1511,  753],
       [1257,  670, 1327,  716],
       [1186,  601, 1240,  641],
       [ 577,  784,  680,  864],
       [ 311,  782,  411,  857],
       [ 142,  749,  278,  845],
       [ 328,  695,  405,  751],
       [ 817,  682,  880,  734],
       [ 727,  661,  782,  701],
       [ 675,  609,  728,  655],
       [ 527,  603,  575,  641]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([13485.,  3468., 27540.,  3337.,  2255.,  8424.,  7676., 13289.,
        4446.,  3392.,  2296.,  2538.,  1911.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00034.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 719,  855,  834,  953],
       [  32,  824,  171,  913],
       [ 609,  776,  694,  845],
       [ 586,  678,  663,  751],
       [ 415,  657,  478,  709],
       [ 600,  607,  650,  649],
       [ 707,  588,  748,  618],
       [1098,  728, 1173,  807],
       [1677,  859, 1819,  943],
       [1242,  559, 1363,  664],
       [1167,  599, 1225,  641],
       [1080,  595, 1119,  638],
       [1136,  564, 1178,  601]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11484., 12600.,  6020.,  5772.,  3392.,  2193.,  1302.,  6080.,
       12155., 12932.,  2537.,  1760.,  1634.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00035.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 386,  805,  505,  909],
       [ 211,  751,  315,  820],
       [ 502,  663,  567,  707],
       [ 657,  636,  711,  676],
       [1548,  901, 1707, 1020],
       [1436,  709, 1523,  761],
       [1044,  636, 1096,  684],
       [1177,  536, 1277,  609],
       [1111,  561, 1152,  591],
       [ 627,  584,  673,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12600.,  7350.,  2970.,  2255., 19200.,  4664.,  2597.,  7474.,
        1302.,  1927.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00036.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 309,  768,  407,  847],
       [ 555,  720,  634,  776],
       [1321,  886, 1457, 1001],
       [1327,  724, 1415,  793],
       [1315,  636, 1367,  670],
       [ 555,  628,  607,  670],
       [ 542,  597,  582,  632],
       [ 771,  578,  823,  626],
       [1013,  582, 1052,  626]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 7920.,  4560., 15892.,  6230.,  1855.,  2279.,  1476.,  2597.,
        1800.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00037.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 313,  884,  455,  995],
       [1521,  895, 1671,  995],
       [1175,  700, 1244,  771],
       [1217,  636, 1275,  688],
       [ 727,  639,  794,  707],
       [ 852,  624,  902,  655],
       [1219,  580, 1271,  614],
       [ 432,  705,  503,  764],
       [ 438,  643,  500,  686],
       [ 530,  597,  575,  634]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16016., 15251.,  5040.,  3127.,  4692.,  1632.,  1855.,  4320.,
        2772.,  1748.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00038.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1530,  886, 1680,  993],
       [ 588,  770,  694,  872],
       [ 153,  849,  282,  945],
       [ 248,  732,  338,  797],
       [ 815,  726,  884,  782],
       [1311,  713, 1388,  770],
       [1102,  618, 1150,  661],
       [1150,  582, 1190,  628],
       [ 430,  649,  496,  688],
       [ 544,  591,  594,  636],
       [ 861,  561,  903,  597]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16308., 11021., 12610.,  6006.,  3990.,  4524.,  2156.,  1927.,
        2680.,  2346.,  1591.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00039.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 682, 1001,  815, 1047],
       [ 253,  726,  346,  786],
       [ 450,  649,  517,  695],
       [ 525,  582,  592,  634],
       [ 640,  528,  700,  599],
       [ 848,  613,  903,  651],
       [1309,  709, 1398,  774],
       [1498,  745, 1590,  805],
       [1205,  630, 1257,  668],
       [1059,  574, 1096,  609]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([6298., 5734., 3196., 3604., 4392., 2184., 5940., 5673., 2067.,
       1368.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00040.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1377,  928, 1571, 1043],
       [1465,  859, 1592,  945],
       [1334,  639, 1398,  689],
       [ 809,  707,  886,  780],
       [ 284,  732,  373,  801],
       [ 430,  622,  519,  693],
       [ 586,  563,  665,  647],
       [ 742,  624,  800,  663],
       [1205,  626, 1267,  676],
       [1142,  578, 1184,  611],
       [ 780,  568,  823,  622],
       [ 717,  563,  759,  603],
       [   0,  891,   38,  982]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22620., 11136.,  3315.,  5772.,  6300.,  6480.,  6800.,  2360.,
        3213.,  1462.,  2420.,  1763.,  3588.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00041.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 648,  961,  802, 1045],
       [1190,  718, 1282,  805],
       [1290,  703, 1363,  755],
       [ 673,  711,  742,  766],
       [   3,  903,   71, 1028],
       [ 252,  688,  377,  789],
       [ 496,  603,  605,  714],
       [ 736,  618,  800,  691],
       [ 671,  601,  730,  659],
       [1238,  589, 1282,  624],
       [1140,  576, 1186,  614],
       [1090,  551, 1125,  574],
       [ 669,  530,  713,  576]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([13175.,  8184.,  3922.,  3920.,  8694., 12852., 12320.,  4810.,
        3540.,  1620.,  1833.,   864.,  2115.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00042.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  811,   94,  955],
       [ 475,  901,  609, 1003],
       [1496,  843, 1634,  943],
       [1115,  620, 1178,  680],
       [1192,  624, 1250,  668],
       [ 636,  724,  730,  826],
       [ 321,  672,  475,  830],
       [ 575,  674,  659,  747],
       [ 638,  549,  694,  607],
       [ 782,  578,  832,  609],
       [1086,  547, 1123,  576],
       [1165,  551, 1203,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([13485., 13905., 14039.,  3904.,  2655.,  9785., 24645.,  6290.,
        3363.,  1632.,  1140.,  1092.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00043.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  834,  203, 1047],
       [ 369,  934,  553, 1045],
       [ 361,  811,  505,  932],
       [ 173,  768,  275,  836],
       [1425,  801, 1536,  882],
       [1513,  759, 1621,  839],
       [1336,  691, 1415,  753],
       [1065,  570, 1117,  618],
       [1134,  578, 1178,  614],
       [ 759,  620,  809,  664],
       [ 588,  576,  657,  651],
       [ 707,  574,  753,  614]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([43014., 20720., 17690.,  7107.,  9184.,  8829.,  5040.,  2597.,
        1665.,  2295.,  5320.,  1927.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00044.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 690,  699,  761,  757],
       [1367,  772, 1463,  845],
       [1263,  672, 1332,  724],
       [1342,  653, 1421,  709],
       [1248,  611, 1313,  661],
       [ 657,  624,  711,  674],
       [ 490,  630,  596,  718],
       [1030,  541, 1073,  578],
       [1082,  547, 1113,  576],
       [ 678,  543,  713,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([4248., 7178., 3710., 4560., 3366., 2805., 9523., 1672.,  960.,
       1296.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00045.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 527,  859,  648,  959],
       [ 309,  709,  446,  832],
       [ 550,  697,  628,  772],
       [1102,  789, 1207,  888],
       [1290,  822, 1396,  913],
       [1517,  884, 1663,  989],
       [1230,  659, 1298,  703],
       [1177,  603, 1227,  639],
       [1246,  597, 1300,  639],
       [1190,  570, 1234,  607],
       [ 650,  570,  688,  609]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12322., 17112.,  6004., 10600.,  9844., 15582.,  3105.,  1887.,
        2365.,  1710.,  1560.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00046.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  876,  161, 1045],
       [ 309,  845,  448,  963],
       [  71,  786,  203,  872],
       [1596,  789, 1792,  930],
       [1302,  703, 1380,  763],
       [1163,  678, 1225,  741],
       [1042,  655, 1103,  713],
       [ 592,  611,  646,  659],
       [1159,  597, 1202,  632],
       [1178,  564, 1227,  601],
       [1111,  561, 1157,  593]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27030., 16660., 11571., 27974.,  4819.,  4032.,  3658.,  2695.,
        1584.,  1900.,  1551.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00047.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1271,  834, 1402,  936],
       [1384,  663, 1503,  755],
       [1192,  618, 1252,  666],
       [1098,  609, 1142,  653],
       [1013,  593, 1057,  632],
       [ 488,  678,  553,  730]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([13596., 11160.,  2989.,  2025.,  1800.,  3498.], dtype=float32), 'gt_overlaps': <6x16 sparse matrix of type '<type 'numpy.float32'>'
	with 6 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00048.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1538,  916, 1742, 1047],
       [ 271,  791,  378,  872],
       [1152,  688, 1228,  753],
       [1277,  601, 1357,  666],
       [ 567,  566,  627,  607],
       [1128,  570, 1175,  605],
       [1052,  566, 1088,  601],
       [ 988,  553, 1021,  588]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27060.,  8856.,  5082.,  5346.,  2562.,  1728.,  1332.,  1224.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00049.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1302,  714, 1403,  803],
       [1092,  616, 1150,  664],
       [1202,  563, 1267,  614],
       [ 500,  601,  573,  645],
       [ 775,  572,  805,  613],
       [ 732,  543,  761,  570]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([9180., 2891., 3432., 3330., 1302.,  840.], dtype=float32), 'gt_overlaps': <6x16 sparse matrix of type '<type 'numpy.float32'>'
	with 6 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00050.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1628,  884, 1919, 1043],
       [1282,  822, 1386,  897],
       [1198,  628, 1269,  689],
       [1057,  572, 1102,  611],
       [ 373,  647,  480,  713],
       [ 744,  620,  790,  661],
       [ 848,  557,  890,  591],
       [ 715,  566,  748,  601],
       [1142,  532, 1200,  580]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([46720.,  7980.,  4464.,  1840.,  7236.,  1974.,  1505.,  1224.,
        2891.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00051.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1132,  928, 1271, 1045],
       [1363,  953, 1530, 1045],
       [1761,  924, 1919, 1021],
       [1369,  707, 1540,  870],
       [1190,  682, 1255,  732],
       [ 142,  730,  309,  841],
       [ 673,  701,  742,  755],
       [ 850,  597,  902,  639],
       [ 684,  601,  727,  643],
       [ 634,  580,  673,  611],
       [ 786,  561,  825,  597],
       [ 719,  572,  757,  613],
       [1138,  572, 1190,  622]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16520., 15624., 15582., 28208.,  3366., 18816.,  3850.,  2279.,
        1892.,  1280.,  1480.,  1638.,  2703.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00052.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 511,  855,  623,  951],
       [ 830,  664,  894,  730],
       [ 623,  651,  682,  705],
       [ 573,  622,  625,  666],
       [ 680,  605,  736,  651],
       [ 767,  601,  815,  638],
       [ 532,  589,  586,  645],
       [1050,  716, 1134,  788],
       [1196,  736, 1284,  807],
       [1469,  736, 1565,  789],
       [1669,  845, 1867,  980],
       [1255,  618, 1357,  736],
       [1144,  609, 1184,  649]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10961.,  4355.,  3300.,  2385.,  2679.,  1862.,  3135.,  6205.,
        6408.,  5238., 27064., 12257.,  1681.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00053.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 740,  809,  853,  939],
       [ 511,  736,  592,  809],
       [ 453,  693,  530,  753],
       [ 436,  639,  503,  699],
       [ 619,  661,  686,  718],
       [ 707,  657,  784,  730],
       [ 598,  607,  640,  641],
       [ 788,  574,  828,  614],
       [1077,  776, 1192,  878],
       [1219,  772, 1309,  845],
       [1428,  813, 1538,  888],
       [1673,  876, 1813,  959],
       [1421,  695, 1532,  780],
       [1332,  641, 1394,  684],
       [1119,  639, 1184,  689],
       [1186,  576, 1265,  657],
       [1019,  630, 1069,  678],
       [1109,  570, 1146,  603],
       [ 657,  568,  688,  603]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14934.,  6068.,  4758.,  4148.,  3944.,  5772.,  1505.,  1681.,
       11948.,  6734.,  8436., 11844.,  9632.,  2772.,  3366.,  6560.,
        2499.,  1292.,  1152.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00054.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 253,  897,  400, 1026],
       [ 582,  774,  698,  891],
       [ 219,  811,  338,  905],
       [ 492,  749,  598,  836],
       [ 269,  724,  375,  813],
       [ 494,  664,  559,  720],
       [ 602,  607,  655,  647],
       [ 755,  616,  813,  676],
       [1036,  657, 1100,  722],
       [1134,  661, 1192,  713],
       [1284,  693, 1355,  745],
       [1432,  720, 1511,  778],
       [1296,  614, 1371,  678],
       [1073,  586, 1123,  622],
       [1138,  545, 1198,  611],
       [ 988,  576, 1034,  614],
       [1238,  589, 1288,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([19240., 13806., 11400.,  9416.,  9630.,  3762.,  2214.,  3599.,
        4290.,  3127.,  3816.,  4720.,  4940.,  1887.,  4087.,  1833.,
        1836.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00055.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 223,  924,  396, 1045],
       [   0,  880,   96, 1039],
       [ 284,  772,  394,  851],
       [ 678,  695,  757,  778],
       [ 507,  664,  569,  711],
       [ 532,  597,  577,  634],
       [1119,  882, 1240,  978],
       [1307,  632, 1365,  676],
       [1202,  626, 1257,  664],
       [1078,  603, 1127,  636],
       [1000,  589, 1055,  630],
       [1217,  570, 1273,  618]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21228., 15520.,  8880.,  6720.,  3024.,  1748., 11834.,  2655.,
        2184.,  1700.,  2352.,  2793.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00056.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1442,  759, 1819, 1039],
       [1228,  784, 1323,  857],
       [1055,  701, 1127,  757],
       [ 484,  861,  617, 1003],
       [ 330,  759,  427,  832],
       [ 427,  645,  492,  695],
       [ 613,  609,  665,  647],
       [ 538,  597,  584,  632],
       [1146,  584, 1186,  611],
       [1225,  584, 1277,  613],
       [ 778,  586,  821,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([106218.,   7104.,   4161.,  19162.,   7252.,   3366.,   2067.,
         1692.,   1148.,   1590.,   1716.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00057.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  964,   84, 1045],
       [1834,  972, 1919, 1045],
       [1252,  843, 1359,  924],
       [1292,  653, 1494,  851],
       [1138,  668, 1202,  714],
       [1027,  620, 1075,  657],
       [ 242,  730,  336,  801],
       [ 500,  676,  569,  726],
       [ 450,  641,  505,  688],
       [ 736,  643,  792,  689],
       [ 557,  582,  603,  622],
       [ 863,  570,  900,  605]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 6724.,  6364.,  8856., 40397.,  3055.,  1862.,  6840.,  3570.,
        2688.,  2679.,  1927.,  1368.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00058.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 259,  801,  375,  886],
       [ 277,  720,  367,  776],
       [ 642,  741,  725,  809],
       [ 480,  624,  542,  672],
       [ 532,  584,  578,  620],
       [ 615,  603,  655,  638],
       [ 848,  634,  896,  668],
       [1077,  768, 1167,  843],
       [1146,  695, 1211,  751],
       [1661,  853, 1786,  938],
       [1511,  766, 1619,  822],
       [1211,  591, 1342,  726],
       [1096,  607, 1140,  639],
       [1000,  572, 1038,  605]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([10062.,  5187.,  5796.,  3087.,  1739.,  1476.,  1715.,  6916.,
        3762., 10836.,  6213., 17952.,  1485.,  1326.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00059.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 398,  984,  561, 1053],
       [   2,  855,   84,  957],
       [ 348,  684,  428,  753],
       [ 525,  661,  586,  711],
       [ 800,  747,  873,  811],
       [ 452,  626,  511,  674],
       [1028,  645, 1082,  688],
       [1436,  709, 1509,  768],
       [1361,  666, 1427,  709],
       [1096,  622, 1138,  661],
       [1150,  563, 1250,  657],
       [ 777,  588,  821,  614],
       [ 709,  557,  750,  601],
       [ 592,  557,  627,  595]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([11480.,  8549.,  5670.,  3162.,  4810.,  2940.,  2420.,  4440.,
        2948.,  1720.,  9595.,  1215.,  1890.,  1404.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00060.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1615,  974, 1784, 1045],
       [1088,  759, 1169,  818],
       [1317,  632, 1371,  678],
       [1267,  603, 1317,  638],
       [1109,  534, 1190,  609],
       [1000,  582, 1042,  618],
       [1063,  576, 1103,  605],
       [  86,  801,  221,  903],
       [ 353,  755,  446,  818],
       [ 321,  688,  400,  755],
       [ 744,  632,  794,  678],
       [ 852,  607,  903,  655],
       [ 669,  595,  725,  647],
       [ 538,  588,  590,  626],
       [ 775,  584,  813,  616],
       [ 628,  586,  677,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([12240.,  4920.,  2585.,  1836.,  6232.,  1591.,  1230., 14008.,
        6016.,  5440.,  2397.,  2548.,  3021.,  2067.,  1287.,  1950.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00001.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  884,  150, 1043],
       [1630,  891, 1919, 1040],
       [1125,  688, 1248,  795],
       [1427,  647, 1553,  730],
       [1134,  497, 1205,  549],
       [1190,  413, 1246,  470],
       [ 975,  401, 1021,  436],
       [ 321,  545,  415,  613],
       [ 515,  324,  584,  407],
       [ 738,  361,  773,  393]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([23680., 43500., 13392., 10668.,  3816.,  3306.,  1692.,  6555.,
        5880.,  1188.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00002.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1842,  991, 1919, 1044],
       [   0,  778,   75,  909],
       [1340,  768, 1492,  884],
       [1246,  576, 1367,  664],
       [1019,  495, 1090,  557],
       [1246,  491, 1323,  547],
       [ 702,  409,  750,  449],
       [1065,  413, 1113,  457],
       [1130,  364, 1180,  411],
       [ 440,  349,  527,  455],
       [ 584,  380,  623,  411],
       [ 661,  382,  702,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4212., 10032., 17901., 10858.,  4536.,  4446.,  2009.,  2205.,
        2448.,  9416.,  1280.,  1344.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00003.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 311,  389,  434,  530],
       [ 632,  493,  702,  553],
       [ 507,  422,  569,  470],
       [ 609,  439,  663,  472],
       [1819,  943, 1919, 1046],
       [1644,  647, 1796,  751],
       [1392,  616, 1509,  691],
       [1153,  538, 1234,  599],
       [1105,  461, 1182,  514],
       [ 973,  411, 1023,  451],
       [1150,  416, 1203,  459]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17608.,  4331.,  3087.,  1870., 10504., 16065.,  8968.,  5084.,
        4212.,  2091.,  2376.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00004.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1440,  878, 1644, 1020],
       [ 442,  684,  571,  793],
       [1384,  595, 1509,  688],
       [1388,  488, 1477,  547],
       [1227,  478, 1303,  530],
       [1078,  439, 1130,  480],
       [1044,  393, 1086,  439],
       [ 507,  522,  582,  582],
       [ 692,  438,  742,  484],
       [ 355,  520,  440,  584],
       [  75,  457,  271,  659],
       [ 577,  401,  625,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([29315., 14300., 11844.,  5400.,  4081.,  2226.,  2021.,  4636.,
        2397.,  5590., 39991.,  1764.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00005.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1473,  897, 1721, 1045],
       [1575,  613, 1698,  691],
       [1190,  570, 1282,  638],
       [1221,  468, 1292,  526],
       [ 238,  718,  386,  834],
       [   0,  730,  113,  864],
       [ 582,  561,  675,  630],
       [ 473,  461,  542,  509],
       [1255,  413, 1317,  459],
       [1144,  409, 1192,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([37101.,  9796.,  6417.,  4248., 17433., 15390.,  6580.,  3430.,
        2961.,  1911.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00006.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 211,  918,  425, 1043],
       [1202,  891, 1392, 1034],
       [1194,  566, 1305,  655],
       [1344,  472, 1413,  522],
       [ 252,  591,  361,  666],
       [ 621,  397,  665,  434],
       [ 796,  411,  844,  453],
       [1096,  457, 1153,  499],
       [1142,  401, 1196,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27090., 27504., 10080.,  3570.,  8360.,  1710.,  2107.,  2494.,
        2255.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00007.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1561,  607, 1686,  693],
       [1048,  566, 1130,  636],
       [1092,  449, 1161,  503],
       [1223,  401, 1275,  443],
       [ 767,  489,  838,  549],
       [ 513,  464,  580,  511],
       [ 503,  351,  571,  411],
       [1036,  391, 1078,  426],
       [1094,  353, 1132,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10962.,  5893.,  3850.,  2279.,  4392.,  3264.,  4209.,  1548.,
        1833.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00008.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 686,  657,  805,  763],
       [1484,  568, 1603,  647],
       [1336,  470, 1413,  524],
       [ 444,  366,  527,  449],
       [ 611,  380,  653,  413],
       [ 986,  449, 1042,  493],
       [1040,  389, 1088,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12840.,  9600.,  4290.,  7056.,  1462.,  2565.,  2254.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00009.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 721,  403,  769,  445],
       [ 344,  409,  455,  514],
       [ 530,  436,  594,  480],
       [ 498,  388,  538,  422],
       [1298,  453, 1369,  509],
       [1221,  401, 1271,  445],
       [ 961,  391,  998,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 2107., 11872.,  2925.,  1435.,  4104.,  2295.,  1140.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00010.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 171,  466,  323,  613],
       [ 373,  530,  461,  595],
       [ 652,  486,  727,  549],
       [ 428,  422,  478,  466],
       [1198,  388, 1248,  434],
       [ 602,  359,  650,  397],
       [1146,  361, 1186,  393],
       [ 550,  355,  592,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22644.,  5874.,  4864.,  2295.,  2397.,  1911.,  1353.,  1763.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00011.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  732,  159,  855],
       [ 467,  668,  598,  791],
       [   2,  572,   96,  722],
       [ 315,  484,  386,  532],
       [ 546,  397,  602,  447],
       [ 517,  388,  550,  434],
       [1131,  359, 1179,  394]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19468., 16368., 14345.,  3528.,  2907.,  1598.,  1764.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00012.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1119,  782, 1257,  901],
       [ 125,  566,  223,  636],
       [ 453,  453,  523,  514],
       [ 463,  418,  513,  459],
       [ 505,  384,  546,  413],
       [ 732,  374,  769,  407],
       [ 815,  364,  853,  393],
       [ 677,  355,  715,  389]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16680.,  7029.,  4402.,  2142.,  1260.,  1292.,  1170.,  1365.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00013.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 255,  549,  373,  649],
       [1023,  538, 1098,  603],
       [ 817,  414,  861,  461],
       [ 380,  472,  450,  536],
       [ 432,  420,  484,  468],
       [ 694,  428,  750,  476],
       [ 634,  409,  678,  445],
       [ 521,  370,  563,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12019.,  5016.,  2160.,  4615.,  2597.,  2793.,  1665.,  1548.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00014.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 213,  572,  317,  655],
       [ 611,  520,  684,  595],
       [ 773,  505,  842,  564],
       [ 527,  501,  598,  557],
       [ 298,  488,  375,  543],
       [ 453,  401,  509,  443],
       [ 638,  399,  680,  430],
       [ 809,  401,  852,  430],
       [ 546,  366,  582,  401],
       [ 980,  434, 1034,  480]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([8820., 5624., 4200., 4104., 4368., 2451., 1376., 1320., 1332.,
       2585.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00015.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1480,  588, 1834,  893],
       [1111,  693, 1259,  816],
       [ 650,  716,  773,  834],
       [ 350,  749,  513,  899],
       [ 182,  722,  344,  843],
       [  32,  609,  159,  695],
       [ 350,  453,  423,  505],
       [ 563,  459,  628,  507],
       [ 784,  468,  844,  509],
       [ 482,  399,  534,  441],
       [ 728,  376,  777,  416],
       [ 959,  380,  992,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([108630.,  18476.,  14756.,  24764.,  19886.,  11136.,   3922.,
         3234.,   2562.,   2279.,   2050.,   1088.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00016.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1273,  447, 1444,  611],
       [ 703,  628,  803,  709],
       [1011,  495, 1086,  559],
       [ 411,  568,  500,  641],
       [ 167,  534,  269,  611],
       [ 377,  453,  450,  509],
       [ 686,  436,  744,  489],
       [ 732,  363,  775,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28380.,  8282.,  4940.,  6660.,  8034.,  4218.,  3186.,  1628.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00017.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  868,  161, 1028],
       [ 192,  539,  294,  609],
       [ 596,  541,  678,  622],
       [ 700,  413,  748,  461],
       [1161,  816, 1315,  951],
       [1328,  741, 1496,  891],
       [1532,  722, 1696,  824],
       [1169,  380, 1282,  501],
       [ 973,  407, 1025,  451],
       [ 663,  366,  700,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([25760.,  7313.,  6806.,  2401., 21080., 25519., 16995., 13908.,
        2385.,  1292.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00018.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 303,  809,  503,  989],
       [1302,  711, 1438,  816],
       [1469,  688, 1600,  766],
       [1878,  807, 1919,  889],
       [1296,  526, 1384,  589],
       [1144,  518, 1227,  591],
       [1034,  541, 1103,  599],
       [1105,  343, 1188,  434],
       [ 615,  493,  696,  561],
       [ 605,  403,  659,  449],
       [ 565,  393,  609,  437],
       [ 944,  361,  990,  391],
       [ 523,  366,  569,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([36381., 14522., 10428.,  3486.,  5696.,  6216.,  4130.,  7728.,
        5658.,  2585.,  2025.,  1457.,  1974.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00019.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 423,  666,  563,  797],
       [ 484,  478,  571,  543],
       [ 463,  399,  519,  439],
       [1127,  509, 1198,  568],
       [1457,  538, 1567,  622],
       [1255,  507, 1328,  564],
       [1178,  441, 1240,  480],
       [1069,  420, 1119,  468],
       [ 986,  432, 1030,  468],
       [1052,  320, 1127,  393],
       [ 671,  363,  711,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18612.,  5808.,  2337.,  4320.,  9435.,  4292.,  2520.,  2499.,
        1665.,  5624.,  1845.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00020.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 200,  632,  346,  747],
       [ 317,  549,  407,  613],
       [ 363,  447,  440,  507],
       [ 628,  409,  677,  449],
       [ 559,  401,  603,  432],
       [1369,  611, 1477,  693],
       [1290,  436, 1353,  495],
       [1150,  430, 1205,  470],
       [1057,  420, 1102,  455],
       [1109,  382, 1148,  416],
       [1013,  372, 1057,  399],
       [ 959,  366,  990,  412],
       [1017,  303, 1078,  366]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17052.,  5915.,  4758.,  2050.,  1440.,  9047.,  3840.,  2296.,
        1656.,  1400.,  1260.,  1504.,  3968.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00021.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1752,  716, 1919,  850],
       [   2,  770,   94,  889],
       [ 184,  520,  294,  611],
       [ 544,  466,  611,  534],
       [ 475,  455,  532,  501],
       [ 563,  403,  603,  436],
       [1200,  468, 1263,  518],
       [1186,  378, 1236,  420],
       [1092,  378, 1132,  409],
       [1011,  374, 1046,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22680., 11160., 10212.,  4692.,  2726.,  1394.,  3264.,  2193.,
        1312.,  1008.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00022.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 382,  576,  486,  678],
       [ 303,  555,  398,  620],
       [1275,  659, 1436,  784],
       [1436,  532, 1540,  609],
       [ 484,  449,  540,  499],
       [ 478,  384,  532,  436],
       [1113,  399, 1153,  434],
       [1115,  345, 1157,  380]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10815.,  6336., 20412.,  8190.,  2907.,  2915.,  1476.,  1548.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00023.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1417,  843, 1603,  980],
       [1028,  588, 1111,  653],
       [1132,  488, 1217,  563],
       [1292,  443, 1355,  497],
       [   0,  851,  159, 1043],
       [   0,  764,   75,  851],
       [ 325,  539,  415,  601],
       [ 373,  441,  442,  501]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([25806.,  5544.,  6536.,  3520., 30880.,  6688.,  5733.,  4270.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00024.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  728,  130,  847],
       [ 169,  526,  273,  620],
       [1180,  561, 1273,  630],
       [ 978,  447, 1036,  493],
       [1059,  409, 1123,  459],
       [1200,  388, 1255,  430],
       [ 577,  376,  619,  413],
       [ 665,  355,  703,  386]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15480.,  9975.,  6580.,  2773.,  3315.,  2408.,  1634.,  1248.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00025.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 503,  432,  559,  480],
       [ 638,  391,  677,  434],
       [ 728,  382,  769,  418],
       [ 594,  374,  628,  399],
       [1090,  451, 1152,  493],
       [ 952,  386,  986,  414],
       [1017,  366, 1059,  399],
       [1132,  355, 1173,  386],
       [ 807,  353,  848,  386]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([2793., 1760., 1554.,  910., 2709., 1015., 1462., 1344., 1428.],
      dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00026.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1294,  699, 1428,  791],
       [ 350,  522,  434,  584],
       [ 569,  445,  627,  499],
       [ 692,  426,  744,  482],
       [ 528,  422,  578,  455],
       [ 807,  397,  853,  439],
       [1040,  397, 1088,  434],
       [ 744,  353,  782,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12555.,  5355.,  3245.,  3021.,  1734.,  2021.,  1862.,  1833.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00027.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  732,  128,  857],
       [1342,  770, 1544,  930],
       [1044,  624, 1155,  711],
       [1484,  551, 1602,  636],
       [1140,  513, 1207,  563],
       [ 442,  534,  530,  611],
       [ 598,  518,  682,  591],
       [ 392,  501,  469,  555],
       [ 769,  476,  842,  539],
       [ 673,  468,  734,  511],
       [ 722,  392,  774,  450],
       [ 488,  403,  532,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16002., 32683.,  9856., 10234.,  3468.,  6942.,  6290.,  4290.,
        4736.,  2728.,  3127.,  1755.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00028.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 384,  713,  532,  859],
       [ 115,  736,  282,  876],
       [  65,  666,  209,  770],
       [ 680,  639,  798,  772],
       [ 569,  576,  661,  661],
       [ 298,  499,  371,  549],
       [ 678,  464,  761,  553],
       [1148,  532, 1244,  613],
       [ 994,  474, 1053,  522],
       [1305,  447, 1382,  501],
       [1065,  424, 1121,  466]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21903., 23688., 15225., 15946.,  7998.,  3774.,  7560.,  7954.,
        2940.,  4290.,  2451.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00029.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 236,  876,  442, 1043],
       [ 584,  624,  721,  795],
       [1640,  695, 1790,  780],
       [ 419,  418,  486,  470],
       [1069,  432, 1138,  488],
       [1205,  391, 1263,  432],
       [ 957,  399, 1009,  445],
       [1015,  372, 1061,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([34776., 23736., 12986.,  3604.,  3990.,  2478.,  2491.,  1692.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00030.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 234,  501,  325,  570],
       [1236,  655, 1359,  738],
       [1471,  657, 1655,  791],
       [1403,  528, 1488,  582],
       [1019,  382, 1071,  414],
       [ 738,  388,  773,  420],
       [ 650,  361,  692,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 6440., 10416., 24975.,  4730.,  1749.,  1188.,  2322.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00031.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1665,  795, 1919, 1011],
       [1650,  663, 1803,  757],
       [1273,  501, 1377,  591],
       [1094,  478, 1159,  532],
       [1280,  443, 1340,  484],
       [ 588,  411,  652,  480],
       [ 703,  439,  755,  480],
       [ 555,  363,  628,  428],
       [ 648,  395,  694,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([55335., 14630.,  9555.,  3630.,  2562.,  4550.,  2226.,  4884.,
        1974.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00032.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1355,  555, 1484,  672],
       [1396,  501, 1486,  557],
       [1171,  424, 1242,  486],
       [1203,  393, 1248,  430],
       [1025,  397, 1073,  434],
       [ 740,  378,  780,  411],
       [ 632,  526,  707,  582],
       [ 455,  503,  548,  593],
       [ 567,  459,  636,  518],
       [ 463,  409,  580,  491],
       [ 580,  370,  627,  422],
       [ 644,  395,  698,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15340.,  5187.,  4536.,  1748.,  1862.,  1394.,  4332.,  8554.,
        4200.,  9794.,  2544.,  2200.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00033.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  96,  688,  302,  880],
       [ 455,  705,  582,  813],
       [ 384,  580,  494,  678],
       [ 307,  457,  477,  605],
       [ 511,  413,  577,  476],
       [ 578,  451,  642,  511],
       [ 711,  438,  763,  482],
       [1500,  591, 1611,  663],
       [1215,  459, 1302,  532],
       [1267,  428, 1327,  474],
       [1105,  380, 1161,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([39951., 13952., 10989., 25479.,  4288.,  3965.,  2385.,  8176.,
        6512.,  2867.,  2907.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00034.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1490,  974, 1711, 1045],
       [1113,  789, 1248,  895],
       [1328,  476, 1403,  534],
       [1140,  397, 1203,  455],
       [   0,  564,  265,  838],
       [ 436,  551,  534,  636],
       [ 627,  545,  711,  613],
       [ 384,  484,  475,  566]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15984., 14552.,  4484.,  3776., 73150.,  8514.,  5865.,  7636.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00035.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 346,  822,  528,  972],
       [  69,  772,  255,  918],
       [ 100,  607,  261,  755],
       [1057,  664, 1188,  774],
       [1475,  672, 1657,  809],
       [1211,  607, 1311,  682],
       [1005,  522, 1073,  576],
       [1230,  414, 1284,  449],
       [1086,  363, 1138,  407],
       [ 505,  374,  550,  416],
       [ 584,  370,  634,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27633., 27489., 24138., 14652., 25254.,  7676.,  3795.,  1980.,
        2385.,  1978.,  2142.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00036.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1150,  853, 1371, 1045],
       [1442,  878, 1646, 1018],
       [1477,  691, 1628,  784],
       [1496,  507, 1671,  659],
       [1269,  507, 1367,  586],
       [ 994,  489, 1065,  553],
       [1100,  474, 1169,  528],
       [ 959,  422, 1005,  455],
       [ 411,  426,  475,  474],
       [ 534,  407,  600,  451],
       [ 805,  361,  846,  399],
       [1161,  376, 1207,  405],
       [1042,  336, 1088,  374],
       [ 544,  320,  598,  386]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([42846., 28905., 14288., 26928.,  7920.,  4680.,  3850.,  1598.,
        3185.,  3015.,  1638.,  1410.,  1833.,  3685.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00037.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1021,  543, 1121,  632],
       [1192,  574, 1288,  641],
       [1263,  520, 1346,  570],
       [1315,  422, 1430,  526],
       [1169,  420, 1234,  476],
       [ 963,  413, 1015,  459],
       [1046,  409, 1096,  447],
       [ 794,  416,  848,  461],
       [ 230,  505,  327,  572],
       [ 444,  455,  527,  518],
       [ 486,  341,  559,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9090.,  6596.,  4284., 12180.,  3762.,  2491.,  1989.,  2530.,
        6664.,  5376.,  6068.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00038.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1157,  861, 1327,  999],
       [1605,  807, 1792,  930],
       [1536,  599, 1661,  676],
       [1315,  736, 1453,  843],
       [ 748,  514,  827,  586],
       [ 294,  530,  411,  620],
       [ 388,  376,  488,  480],
       [1090,  459, 1155,  509],
       [ 986,  436, 1040,  488],
       [1167,  428, 1217,  476],
       [1232,  370, 1300,  449],
       [1113,  376, 1165,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([23769., 23312.,  9828., 15012.,  5840., 10738., 10605.,  3366.,
        2915.,  2499.,  5520.,  2385.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00039.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 603,  772,  765,  945],
       [   0,  613,  223,  828],
       [ 213,  434,  363,  582],
       [1390,  861, 1582, 1005],
       [1650,  826, 1853,  968],
       [1659,  661, 1848,  788],
       [1332,  578, 1434,  649],
       [1148,  532, 1225,  593],
       [1038,  555, 1115,  620],
       [1342,  476, 1409,  514]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28362., 48384., 22499., 27985., 29172., 24320.,  7416.,  4836.,
        5148.,  2652.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00040.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  538,  107,  749],
       [1563,  618, 1688,  695],
       [1361,  584, 1465,  661],
       [1163,  574, 1259,  641],
       [1388,  505, 1496,  580],
       [1207,  472, 1275,  520],
       [1075,  445, 1132,  489],
       [ 984,  445, 1042,  488],
       [1230,  413, 1286,  449],
       [ 528,  413,  580,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22896.,  9828.,  8190.,  6596.,  8284.,  3381.,  2610.,  2596.,
        2109.,  2756.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00041.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 421,  472,  494,  522],
       [ 461,  399,  517,  447],
       [ 575,  378,  621,  413],
       [ 734,  376,  773,  413],
       [1077,  455, 1148,  503],
       [1223,  476, 1294,  534],
       [1350,  480, 1430,  528],
       [1252,  420, 1327,  470],
       [1127,  413, 1180,  449],
       [ 953,  386,  992,  414],
       [1028,  391, 1071,  424],
       [1159,  370, 1202,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([3774., 2793., 1692., 1520., 3528., 4248., 3969., 3876., 1998.,
       1160., 1496., 1672.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00042.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 225,  580,  334,  668],
       [1509,  574, 1619,  655],
       [1238,  413, 1288,  455],
       [1148,  414, 1198,  453],
       [1038,  401, 1077,  438],
       [1165,  374, 1221,  414],
       [ 693,  428,  741,  472],
       [ 346,  451,  427,  513],
       [ 494,  416,  548,  463],
       [ 602,  370,  642,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([9790., 9102., 2193., 2040., 1520., 2337., 2205., 5166., 2640.,
       1394.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00043.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 150,  536,  265,  626],
       [ 613,  532,  690,  589],
       [ 359,  476,  434,  541],
       [ 413,  432,  469,  474],
       [ 555,  409,  605,  441],
       [1292,  705, 1436,  818],
       [1517,  572, 1621,  645],
       [1338,  470, 1411,  524],
       [ 800,  374,  838,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10556.,  4524.,  5016.,  2451.,  1683., 16530.,  7770.,  4070.,
        1404.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00044.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 375,  772,  527,  897],
       [  96,  582,  213,  674],
       [ 275,  493,  359,  557],
       [ 469,  466,  530,  511],
       [ 790,  424,  838,  472],
       [1140,  514, 1223,  586],
       [1521,  568, 1640,  657],
       [1342,  466, 1409,  518],
       [1228,  414, 1290,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19278., 10974.,  5525.,  2852.,  2401.,  6132., 10800.,  3604.,
        2520.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00045.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  25,  597,  150,  693],
       [ 311,  557,  400,  624],
       [ 742,  522,  819,  588],
       [ 478,  380,  532,  438],
       [1590,  782, 1786,  920],
       [1342,  463, 1417,  522],
       [1067,  430, 1130,  478],
       [1244,  403, 1288,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12222.,  6120.,  5226.,  3245., 27383.,  4560.,  3136.,  2115.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00046.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 611,  743,  753,  889],
       [   2,  753,  119,  864],
       [ 380,  422,  452,  495],
       [ 525,  380,  567,  413],
       [ 736,  372,  775,  409],
       [1644,  807, 1838,  926],
       [1313,  553, 1413,  628],
       [1236,  397, 1290,  441],
       [1021,  376, 1067,  418],
       [1173,  370, 1215,  405],
       [ 602,  359,  644,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21021., 13216.,  5402.,  1462.,  1520., 23400.,  7676.,  2475.,
        2021.,  1548.,  1763.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00047.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 202,  491,  315,  603],
       [ 700,  418,  755,  463],
       [ 467,  413,  513,  451],
       [ 555,  399,  605,  434],
       [1273,  678, 1392,  766],
       [1340,  570, 1434,  630],
       [1188,  453, 1255,  501],
       [1165,  361, 1213,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12882.,  2576.,  1833.,  1836., 10680.,  5795.,  3332.,  2107.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00048.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1857,  814, 1919,  907],
       [1442,  678, 1586,  770],
       [1132,  513, 1200,  566],
       [1207,  461, 1277,  507],
       [ 621,  507,  703,  570],
       [ 473,  443,  544,  499],
       [ 369,  463,  428,  507],
       [ 638,  411,  682,  447],
       [ 584,  386,  630,  426],
       [1121,  399, 1169,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 5922., 13485.,  3726.,  3337.,  5312.,  4104.,  2700.,  1665.,
        1927.,  2107.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00049.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 411,  714,  567,  845],
       [ 225,  528,  302,  593],
       [ 327,  522,  419,  599],
       [ 571,  468,  628,  518],
       [ 509,  436,  569,  489],
       [1555,  751, 1725,  853],
       [1480,  578, 1592,  645],
       [1252,  511, 1336,  570],
       [1067,  430, 1115,  470],
       [1134,  399, 1182,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20724.,  5148.,  7254.,  2958.,  3294., 17613.,  7684.,  5100.,
        2009.,  2009.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00050.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1661,  807, 1907,  989],
       [1267,  664, 1403,  788],
       [1609,  641, 1752,  730],
       [1303,  549, 1398,  613],
       [1317,  470, 1386,  512],
       [1152,  428, 1213,  474],
       [   5,  668,  175,  793],
       [ 425,  572,  519,  645],
       [ 355,  520,  440,  593],
       [ 607,  403,  667,  463],
       [ 734,  401,  777,  439],
       [1021,  384, 1059,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([45201., 17125., 12960.,  6240.,  3010.,  2914., 21546.,  7030.,
        6364.,  3721.,  1716.,  1170.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00051.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  78,  801,  255,  938],
       [  25,  682,  177,  813],
       [ 511,  464,  596,  543],
       [ 680,  464,  742,  516],
       [ 652,  389,  694,  424],
       [1282,  711, 1407,  795],
       [1342,  566, 1461,  653],
       [1521,  599, 1634,  674],
       [1123,  503, 1209,  570],
       [1378,  499, 1465,  553],
       [1190,  455, 1257,  499],
       [1211,  405, 1269,  447],
       [1092,  384, 1140,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24564., 20196.,  6880.,  3339.,  1548., 10710., 10560.,  8664.,
        5916.,  4840.,  3060.,  2537.,  1813.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00052.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1250,  668, 1375,  763],
       [1136,  530, 1209,  580],
       [1205,  459, 1284,  518],
       [1334,  482, 1402,  530],
       [1259,  426, 1321,  464],
       [1055,  424, 1113,  468],
       [1117,  393, 1173,  430],
       [ 315,  586,  453,  716],
       [ 559,  578,  661,  661],
       [ 588,  445,  648,  488]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12096.,  3774.,  4800.,  3381.,  2457.,  2655.,  2166., 18209.,
        8652.,  2684.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00053.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 244,  878,  450, 1043],
       [ 455,  536,  548,  597],
       [1830,  961, 1919, 1048],
       [1415,  651, 1542,  732],
       [1127,  509, 1200,  564],
       [1065,  443, 1119,  480],
       [1230,  411, 1282,  455],
       [1128,  399, 1186,  441],
       [ 805,  397,  859,  443],
       [ 627,  395,  675,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([34362.,  5828.,  7920., 10496.,  4144.,  2090.,  2385.,  2537.,
        2585.,  2058.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00054.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 167,  724,  327,  839],
       [1594,  780, 1778,  905],
       [1400,  616, 1513,  697],
       [1234,  497, 1311,  547],
       [ 780,  461,  855,  528],
       [ 686,  455,  748,  505],
       [ 548,  457,  619,  511],
       [ 532,  413,  582,  463],
       [ 713,  411,  757,  449],
       [1063,  428, 1117,  472]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18676., 23310.,  9348.,  3978.,  5168.,  3213.,  3960.,  2601.,
        1755.,  2475.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00055.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 713,  603,  830,  705],
       [ 592,  564,  678,  634],
       [ 375,  561,  486,  661],
       [ 417,  484,  494,  545],
       [ 657,  484,  723,  538],
       [1855,  774, 1919,  887],
       [1325,  555, 1421,  630],
       [1230,  484, 1305,  541],
       [1144,  424, 1196,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12154.,  6177., 11312.,  4836.,  3685.,  7410.,  7372.,  4408.,
        1802.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00056.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  828,  146, 1045],
       [ 325,  828,  498,  988],
       [ 528,  624,  632,  713],
       [ 186,  605,  311,  709],
       [1346,  759, 1494,  880],
       [1513,  716, 1665,  820],
       [1480,  503, 1636,  649],
       [1200,  453, 1263,  505],
       [1144,  411, 1202,  457],
       [ 448,  418,  505,  463]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([32046., 28014.,  9450., 13230., 18178., 16065., 23079.,  3392.,
        2773.,  2668.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00057.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1802,  970, 1919, 1044],
       [1302,  763, 1452,  870],
       [1486,  713, 1648,  826],
       [1584,  616, 1734,  720],
       [1305,  543, 1388,  601],
       [1163,  549, 1246,  603],
       [1313,  416, 1411,  514],
       [1130,  401, 1182,  439],
       [ 311,  482,  390,  541],
       [ 490,  391,  536,  426],
       [1086,  370, 1132,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 8850., 16308., 18582., 15855.,  4956.,  4620.,  9801.,  2067.,
        4800.,  1692.,  1692.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00058.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1330,  764, 1496,  893],
       [1428,  653, 1540,  738],
       [1298,  553, 1396,  622],
       [1384,  499, 1478,  563],
       [1144,  543, 1230,  605],
       [1194,  454, 1265,  500],
       [1084,  445, 1138,  489],
       [1213,  363, 1288,  441],
       [  40,  607,  167,  686],
       [ 405,  438,  463,  476],
       [ 580,  380,  627,  418],
       [ 502,  391,  542,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21710.,  9718.,  6930.,  6175.,  5481.,  3384.,  2475.,  6004.,
       10240.,  2301.,  1872.,  1312.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00059.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1157,  874, 1405, 1043],
       [1840,  970, 1919, 1043],
       [1571,  614, 1711,  714],
       [1146,  545, 1238,  614],
       [1271,  522, 1350,  574],
       [1205,  468, 1273,  522],
       [1265,  428, 1328,  476],
       [1073,  449, 1127,  497],
       [1130,  403, 1177,  441],
       [ 244,  516,  328,  568],
       [ 417,  430,  471,  476],
       [ 494,  436,  553,  478],
       [1036,  388, 1077,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([42330.,  5920., 14241.,  6510.,  4240.,  3795.,  3136.,  2695.,
        1872.,  4505.,  2585.,  2580.,  1890.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00060.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1600,  645, 1725,  732],
       [1442,  641, 1571,  732],
       [1013,  536, 1121,  649],
       [1373,  497, 1461,  563],
       [1190,  453, 1248,  497],
       [1073,  449, 1138,  499],
       [1146,  413, 1198,  457],
       [ 327,  528,  421,  603],
       [   0,  661,   53,  759],
       [ 284,  503,  355,  555],
       [ 455,  403,  511,  449],
       [1027,  395, 1069,  434],
       [1194,  388, 1236,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11088., 11960., 12426.,  5963.,  2655.,  3366.,  2385.,  7220.,
        5346.,  3816.,  2679.,  1720.,  1763.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00001.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1457,  909, 1682, 1041],
       [1717,  709, 1882,  811],
       [1250,  641, 1359,  716],
       [1148,  464, 1211,  511],
       [ 686,  622,  798,  709],
       [ 596,  522,  688,  622],
       [ 480,  528,  563,  586],
       [ 384,  503,  461,  568],
       [ 544,  397,  596,  439],
       [ 723,  405,  765,  441],
       [1138,  403, 1177,  441],
       [1227,  405, 1284,  447],
       [1182,  432, 1234,  474],
       [ 663,  382,  705,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([30058., 17098.,  8360.,  3072.,  9944.,  9393.,  4956.,  5148.,
        2279.,  1591.,  1560.,  2494.,  2279.,  1591.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00002.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1509,  978, 1763, 1038],
       [ 344,  738,  534,  951],
       [ 129,  767,  297,  892],
       [  59,  666,  211,  778],
       [ 661,  480,  725,  536],
       [ 442,  461,  513,  522],
       [ 600,  438,  659,  489],
       [ 796,  441,  852,  482],
       [1202,  591, 1305,  676],
       [1419,  522, 1503,  582],
       [1125,  488, 1190,  534],
       [1067,  401, 1111,  439],
       [ 802,  378,  846,  413],
       [1128,  389, 1169,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([15555., 40874., 21294., 17289.,  3705.,  4464.,  3120.,  2394.,
        8944.,  5185.,  3102.,  1755.,  1620.,  1428.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00003.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 503,  638,  609,  738],
       [ 215,  582,  334,  666],
       [ 453,  541,  550,  622],
       [ 750,  559,  827,  634],
       [1203,  599, 1327,  699],
       [1104,  470, 1173,  528],
       [1269,  428, 1334,  470],
       [ 778,  434,  842,  495],
       [1065,  416, 1111,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10807., 10200.,  8036.,  5928., 12625.,  4130.,  2838.,  4030.,
        1880.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00004.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  40,  799,  244,  980],
       [ 552,  922,  734, 1045],
       [1392,  866, 1586, 1001],
       [1842,  803, 1919,  914],
       [ 707,  559,  805,  655],
       [1100,  472, 1175,  534],
       [ 440,  424,  492,  464],
       [1046,  409, 1094,  445],
       [ 723,  393,  763,  432],
       [1177,  380, 1227,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([37310., 22692., 26520.,  8736.,  9603.,  4788.,  2173.,  1813.,
        1640.,  1887.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00005.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 473,  939,  694, 1047],
       [ 315,  491,  386,  547],
       [1486,  934, 1748, 1043],
       [1807,  963, 1919, 1045],
       [1461,  559, 1561,  626],
       [ 673,  463,  730,  509],
       [1163,  559, 1250,  628],
       [1044,  409, 1098,  451],
       [ 721,  407,  769,  443],
       [ 540,  374,  586,  407],
       [1007,  366, 1046,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24198.,  4104., 28930.,  9379.,  6868.,  2726.,  6160.,  2365.,
        1813.,  1598.,  1200.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00006.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  92,  595,  205,  676],
       [ 571,  580,  653,  651],
       [ 667,  474,  736,  528],
       [ 471,  409,  523,  449],
       [1513,  995, 1707, 1047],
       [1423,  638, 1552,  714],
       [1507,  568, 1636,  664],
       [1203,  586, 1317,  672],
       [1298,  457, 1359,  503],
       [ 717,  389,  769,  428],
       [1078,  455, 1140,  499],
       [1009,  364, 1057,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9348.,  5976.,  3850.,  2173., 10335., 10010., 12610., 10005.,
        2914.,  2120.,  2835.,  2058.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00007.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 223,  916,  415, 1047],
       [ 536,  614,  648,  707],
       [ 353,  472,  423,  524],
       [ 640,  453,  709,  505],
       [ 723,  372,  767,  414],
       [1473,  668, 1615,  774],
       [1200,  599, 1294,  672],
       [1273,  503, 1350,  557],
       [1311,  451, 1392,  514],
       [1100,  457, 1175,  514],
       [1194,  397, 1242,  432],
       [1030,  395, 1073,  424]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([25476., 10622.,  3763.,  3710.,  1935., 15301.,  7030.,  4290.,
        5248.,  4408.,  1764.,  1320.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00008.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1330,  761, 1492,  893],
       [1538,  601, 1659,  678],
       [ 448,  580,  563,  678],
       [ 136,  572,  248,  638],
       [1278,  514, 1363,  580],
       [1098,  466, 1157,  511],
       [1192,  430, 1248,  468],
       [ 688,  422,  746,  472],
       [ 640,  405,  684,  443],
       [1044,  391, 1096,  438],
       [ 575,  374,  621,  418],
       [1203,  391, 1261,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21679.,  9516., 11484.,  7571.,  5762.,  2760.,  2223.,  3009.,
        1755.,  2544.,  2115.,  2478.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00009.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1148,  528, 1228,  601],
       [1644,  628, 1823,  757],
       [ 609,  511,  694,  582],
       [ 542,  482,  607,  538],
       [ 492,  420,  561,  482],
       [ 425,  424,  480,  461],
       [1342,  480, 1415,  530],
       [1173,  432, 1234,  482],
       [ 719,  399,  765,  434],
       [1042,  403, 1080,  430],
       [1144,  380, 1190,  414],
       [ 659,  351,  711,  403],
       [   0,  989,   86, 1045]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 5994., 23400.,  6192.,  3762.,  4410.,  2128.,  3774.,  3162.,
        1692.,  1092.,  1645.,  2809.,  4959.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00010.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 394,  713,  552,  853],
       [ 284,  647,  409,  749],
       [1311,  751, 1461,  857],
       [1396,  489, 1655,  722],
       [1069,  428, 1123,  476],
       [1232,  413, 1288,  451],
       [1105,  382, 1152,  418],
       [ 661,  480,  723,  522],
       [ 328,  505,  432,  597],
       [ 252,  514,  330,  564],
       [ 623,  384,  688,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22419., 12978., 16157., 60840.,  2695.,  2223.,  1776.,  2709.,
        9765.,  4029.,  4356.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00011.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  668,  144,  820],
       [ 498,  632,  611,  724],
       [ 552,  432,  644,  516],
       [1103,  788, 1252,  905],
       [1428,  895, 1636, 1038],
       [1140,  530, 1215,  589],
       [1205,  407, 1334,  530]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22185., 10602.,  7905., 17700., 30096.,  4560., 16120.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00012.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 415,  503,  552,  622],
       [1178,  570, 1271,  638],
       [1003,  526, 1077,  580],
       [1071,  432, 1121,  478],
       [1109,  347, 1188,  439],
       [1198,  376, 1248,  424],
       [ 467,  403,  515,  438],
       [ 571,  378,  613,  422],
       [ 653,  368,  698,  413],
       [ 736,  388,  771,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16560.,  6486.,  4125.,  2397.,  7440.,  2499.,  1764.,  1935.,
        2116.,  1044.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00013.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 123,  663,  352,  855],
       [ 353,  459,  419,  514],
       [ 494,  434,  557,  482],
       [ 602,  413,  659,  474],
       [ 694,  443,  748,  488],
       [ 969,  424, 1017,  463],
       [1084,  447, 1136,  488],
       [1050,  320, 1113,  384],
       [1130,  349, 1177,  382],
       [1023,  384, 1059,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([44390.,  3752.,  3136.,  3596.,  2530.,  1960.,  2226.,  4160.,
        1632.,  1036.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00014.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 136,  559,  240,  639],
       [ 342,  514,  438,  593],
       [ 494,  484,  586,  574],
       [ 600,  551,  684,  620],
       [1027,  593, 1111,  651],
       [1202,  597, 1303,  670],
       [1536,  611, 1655,  686],
       [ 492,  389,  542,  424],
       [1028,  389, 1067,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([8505., 7760., 8463., 5950., 5015., 7548., 9120., 1836., 1360.],
      dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00015.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 336,  826,  509,  976],
       [ 263,  628,  413,  776],
       [   2,  686,  169,  830],
       [ 255,  576,  355,  649],
       [ 402,  441,  463,  486],
       [ 621,  420,  677,  461],
       [ 553,  384,  607,  422],
       [1478,  664, 1621,  774],
       [1338,  478, 1407,  524],
       [1094,  463, 1153,  511],
       [ 978,  461, 1034,  497]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([26274., 22499., 24360.,  7474.,  2852.,  2394.,  2145., 15984.,
        3290.,  2940.,  2109.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00016.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1473,  909, 1711, 1041],
       [1552,  757, 1725,  866],
       [1744,  724, 1913,  818],
       [1517,  582, 1619,  649],
       [1269,  501, 1346,  557],
       [1227,  409, 1271,  449],
       [1036,  393, 1078,  424],
       [ 950,  389,  990,  420],
       [ 530,  491,  602,  545],
       [ 467,  439,  538,  499],
       [ 238,  518,  323,  576],
       [ 586,  380,  628,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([31787., 19140., 16150.,  7004.,  4446.,  1845.,  1376.,  1312.,
        4015.,  4392.,  5074.,  1462.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00017.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   1,  668,   42,  778],
       [ 323,  636,  442,  726],
       [ 284,  532,  398,  618],
       [ 519,  428,  580,  468],
       [ 471,  399,  517,  436],
       [1194,  576, 1294,  655],
       [1459,  547, 1552,  611],
       [1288,  538, 1377,  601],
       [1344,  476, 1411,  522],
       [1163,  418, 1221,  461]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4662., 10920., 10005.,  2542.,  1786.,  8080.,  6110.,  5760.,
        3196.,  2596.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00018.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  745,   77,  884],
       [1155,  813, 1652, 1045],
       [1225,  630, 1338,  711],
       [1088,  453, 1152,  509],
       [1169,  439, 1232,  486],
       [1315,  461, 1384,  505],
       [ 390,  507,  482,  572],
       [ 355,  459,  421,  505],
       [ 498,  391,  538,  420],
       [ 665,  378,  703,  407],
       [1096,  370, 1136,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 10920., 116034.,   9348.,   3705.,   3072.,   3150.,   6138.,
         3149.,   1230.,   1170.,   1312.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00019.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  90,  659,  242,  768],
       [ 125,  564,  228,  630],
       [1444,  897, 1653, 1036],
       [1021,  505, 1196,  722],
       [1205,  589, 1323,  684],
       [1228,  399, 1282,  441],
       [ 398,  436,  463,  476],
       [ 615,  422,  665,  463],
       [1032,  389, 1077,  430],
       [1100,  386, 1146,  418],
       [1178,  376, 1223,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16830.,  6968., 29400., 38368., 11424.,  2365.,  2706.,  2142.,
        1932.,  1551.,  1564.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00020.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1638,  788, 1825,  916],
       [1182,  572, 1280,  649],
       [ 977,  405, 1084,  547],
       [1107,  464, 1175,  522],
       [ 527,  497,  596,  547],
       [ 232,  518,  317,  564],
       [ 715,  374,  763,  426],
       [ 602,  357,  650,  397],
       [1167,  372, 1207,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24252.,  7722., 15444.,  4071.,  3570.,  4042.,  2597.,  2009.,
        1312.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00021.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1473,  922, 1703, 1043],
       [1363,  570, 1457,  647],
       [1084,  450, 1148,  504],
       [ 953,  353, 1028,  457],
       [1048,  395, 1102,  436],
       [ 661,  426,  732,  511],
       [ 317,  636,  434,  724],
       [ 542,  395,  605,  445],
       [ 805,  353,  850,  401],
       [ 592,  376,  630,  403],
       [   0,  659,   36,  749],
       [ 540,  363,  580,  393]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28182.,  7410.,  3575.,  7980.,  2310.,  6192., 10502.,  3264.,
        2254.,  1092.,  3367.,  1271.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00022.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1630,  826, 1832,  955],
       [1182,  572, 1284,  651],
       [1228,  470, 1294,  524],
       [1036,  393, 1077,  426],
       [ 927,  322,  990,  403],
       [1011,  359, 1046,  388],
       [ 532,  532,  655,  674],
       [ 792,  403,  853,  470],
       [ 442,  447,  538,  520],
       [ 530,  416,  582,  455],
       [ 480,  397,  527,  438],
       [ 550,  355,  592,  391],
       [ 690,  345,  725,  374]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([26390.,  8240.,  3685.,  1428.,  5248.,  1080., 17732.,  4216.,
        7178.,  2120.,  2016.,  1591.,  1080.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00023.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1111,  770, 1271,  922],
       [1502,  695, 1652,  793],
       [1521,  591, 1630,  666],
       [1328,  576, 1427,  638],
       [1088,  451, 1148,  503],
       [1146,  411, 1198,  453],
       [ 123,  855,  398, 1045],
       [ 244,  545,  398,  655],
       [ 748,  493,  838,  599],
       [ 428,  482,  496,  536],
       [ 367,  457,  427,  511],
       [ 498,  384,  548,  434],
       [ 657,  386,  700,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24633., 14949.,  8360.,  6300.,  3233.,  2279., 52716., 17205.,
        9737.,  3795.,  3355.,  2601.,  1628.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00024.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 598,  732,  778,  968],
       [   0,  747,   98,  922],
       [ 212,  607,  325,  695],
       [ 128,  572,  234,  645],
       [ 398,  432,  471,  489],
       [ 575,  461,  636,  509],
       [1011,  516, 1094,  589],
       [1827,  791, 1919,  902],
       [1432,  647, 1563,  738],
       [1284,  524, 1367,  580],
       [1344,  482, 1413,  530],
       [1196,  464, 1263,  513],
       [1094,  374, 1136,  411],
       [1030,  388, 1077,  426],
       [ 509,  389,  555,  418],
       [ 594,  338,  644,  407],
       [ 732,  368,  773,  397],
       [ 805,  372,  842,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([42897., 17424., 10146.,  7918.,  4292.,  3038.,  6216., 10416.,
       12144.,  4788.,  3430.,  3400.,  1634.,  1872.,  1410.,  3570.,
        1260.,  1520.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00025.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1609,  834, 1790,  938],
       [1478,  574, 1586,  641],
       [1255,  503, 1340,  563],
       [1167,  441, 1230,  484],
       [ 969,  418, 1021,  466],
       [1246,  418, 1296,  459],
       [1125,  405, 1175,  439],
       [ 348,  626,  469,  718],
       [ 213,  518,  325,  599],
       [ 423,  434,  484,  478],
       [ 530,  370,  603,  457],
       [ 694,  420,  748,  468],
       [ 790,  428,  840,  474]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19110.,  7412.,  5246.,  2816.,  2597.,  2142.,  1785., 11346.,
        9266.,  2790.,  6512.,  2695.,  2397.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00026.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1532,  732, 1698,  838],
       [1523,  553, 1723,  707],
       [1317,  574, 1411,  638],
       [1323,  468, 1390,  518],
       [1165,  428, 1221,  466],
       [ 748,  528,  825,  595],
       [ 594,  532,  678,  607],
       [ 398,  426,  511,  549],
       [ 263,  516,  344,  570],
       [1092,  391, 1138,  426],
       [1169,  380, 1219,  413],
       [ 536,  366,  580,  405],
       [ 936,  368,  977,  405],
       [1073,  372, 1111,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([17869., 31155.,  6175.,  3468.,  2223.,  5304.,  6460., 14136.,
        4510.,  1692.,  1734.,  1800.,  1596.,  1092.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00027.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1665,  851, 1886, 1014],
       [1294,  534, 1386,  603],
       [1338,  451, 1465,  557],
       [1196,  466, 1255,  505],
       [1221,  411, 1275,  443],
       [1103,  378, 1148,  411],
       [ 619,  766,  769,  909],
       [ 227,  861,  428, 1041],
       [ 119,  532,  323,  724],
       [   2,  664,   52,  774],
       [ 463,  407,  521,  453],
       [ 798,  389,  842,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([36408.,  6510., 13696.,  2400.,  1815.,  1564., 21744., 36562.,
       39565.,  5661.,  2773.,  1440.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00028.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1832,  795, 1919,  910],
       [1544,  588, 1665,  672],
       [1344,  574, 1444,  661],
       [1177,  443, 1240,  491],
       [1238,  391, 1328,  468],
       [1128,  403, 1171,  436],
       [ 780,  453,  838,  495],
       [ 332,  470,  413,  536],
       [ 644,  397,  690,  432],
       [ 807,  386,  848,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10208., 10370.,  8888.,  3136.,  7098.,  1496.,  2537.,  5494.,
        1692.,  1554.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00029.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  67,  584,  196,  676],
       [ 705,  578,  798,  653],
       [ 786,  451,  846,  511],
       [ 573,  445,  634,  505],
       [ 657,  384,  698,  424],
       [ 727,  399,  769,  432],
       [1803,  768, 1919,  878],
       [1488,  574, 1588,  645],
       [1361,  472, 1436,  534],
       [1207,  466, 1275,  516],
       [1171,  357, 1238,  420],
       [1107,  389, 1150,  426],
       [ 819,  374,  857,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12090.,  7144.,  3721.,  3782.,  1722.,  1462., 12987.,  7272.,
        4788.,  3519.,  4352.,  1672.,  1248.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00030.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 453,  991,  642, 1045],
       [ 728,  580,  823,  674],
       [ 430,  547,  525,  624],
       [ 678,  459,  734,  511],
       [ 600,  439,  653,  491],
       [ 813,  422,  859,  464],
       [1482,  566, 1584,  632],
       [1328,  470, 1390,  520],
       [1248,  413, 1313,  459],
       [1127,  401, 1173,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10450.,  9120.,  7488.,  3021.,  2862.,  2021.,  6901.,  3213.,
        3102.,  2021.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00031.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  67,  757,  257,  914],
       [ 552,  993,  715, 1049],
       [1555,  607, 1688,  693],
       [1323,  468, 1390,  516],
       [1230,  411, 1284,  445],
       [ 561,  586,  653,  664],
       [ 482,  526,  563,  597],
       [ 778,  518,  852,  580],
       [ 800,  424,  850,  472],
       [ 648,  413,  688,  443],
       [1182,  372, 1228,  407],
       [1075,  363, 1115,  395],
       [ 744,  345,  778,  378]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([30178.,  9348., 11658.,  3332.,  1925.,  7347.,  5904.,  4725.,
        2499.,  1271.,  1692.,  1353.,  1190.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00032.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 178,  961,  392, 1043],
       [ 659,  745,  794,  868],
       [ 198,  711,  357,  843],
       [ 759,  520,  834,  591],
       [ 559,  480,  625,  532],
       [1730,  861, 1917, 1043],
       [1361,  484, 1440,  545],
       [1232,  411, 1280,  447],
       [ 728,  382,  775,  426],
       [ 569,  395,  619,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17845., 16864., 21280.,  5472.,  3551., 34404.,  4960.,  1813.,
        2160.,  1632.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00033.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 630,  759,  771,  895],
       [ 377,  611,  486,  699],
       [ 484,  453,  546,  488],
       [ 678,  439,  744,  501],
       [ 803,  428,  848,  466],
       [ 817,  368,  855,  401],
       [1357,  568, 1467,  664],
       [1248,  413, 1307,  461],
       [1163,  374, 1207,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19454.,  9790.,  2268.,  4221.,  1794.,  1326., 10767.,  2940.,
        1530.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00034.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  995,   65, 1047],
       [ 311,  551,  407,  613],
       [ 571,  547,  671,  639],
       [ 771,  522,  846,  589],
       [ 803,  420,  859,  463],
       [1538,  764, 1717,  882],
       [1588,  634, 1723,  713],
       [1211,  455, 1280,  514],
       [1180,  374, 1230,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 3498.,  6111.,  9393.,  5168.,  2508., 21420., 10880.,  4200.,
        1938.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00035.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  786,   67,  907],
       [ 234,  834,  455, 1045],
       [ 657,  759,  794,  905],
       [1269, 1026, 1436, 1045],
       [1367,  811, 1528,  930],
       [1786,  968, 1919, 1044],
       [1857,  797, 1915,  889],
       [1234,  524, 1319,  582],
       [1382,  505, 1467,  559],
       [ 767,  518,  838,  580],
       [1127,  389, 1180,  436],
       [1127,  349, 1163,  376],
       [ 744,  374,  777,  405],
       [ 817,  370,  848,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 8296., 47064., 20286.,  3360., 19440., 10318.,  5487.,  5074.,
        4730.,  4536.,  2592.,  1036.,  1088.,  1024.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00036.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 640,  755,  777,  891],
       [1030,  584, 1142,  684],
       [ 709,  424,  757,  463],
       [ 803,  420,  850,  455],
       [1363,  607, 1469,  676],
       [1507,  576, 1611,  643],
       [1275,  430, 1336,  476],
       [1105,  424, 1163,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18906., 11413.,  1960.,  1728.,  7490.,  7140.,  2914.,  2419.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00037.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1567,  747, 1742,  855],
       [1498,  568, 1607,  643],
       [1338,  476, 1405,  520],
       [1209,  472, 1273,  518],
       [ 980,  453, 1050,  511],
       [1075,  434, 1123,  478],
       [ 767,  509,  834,  566],
       [ 638,  499,  702,  561],
       [ 792,  407,  848,  461],
       [1196,  388, 1242,  422],
       [1025,  368, 1071,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19184.,  8360.,  3060.,  3055.,  4189.,  2205.,  3944.,  4095.,
        3135.,  1645.,  1786.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00038.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 655,  724,  782,  843],
       [ 473,  661,  582,  763],
       [ 746,  489,  821,  566],
       [1305,  536, 1394,  599],
       [1319,  457, 1394,  514],
       [1234,  416, 1288,  453],
       [1123,  403, 1169,  438],
       [ 640,  395,  692,  443],
       [ 721,  382,  765,  420],
       [ 959,  391, 1002,  432],
       [1027,  376, 1067,  413],
       [1136,  357, 1173,  388],
       [ 805,  347,  846,  382]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15360., 11330.,  5928.,  5760.,  4408.,  2090.,  1692.,  2597.,
        1755.,  1848.,  1558.,  1216.,  1512.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00039.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 628,  666,  757,  814],
       [1302,  695, 1480,  841],
       [1546,  607, 1663,  684],
       [1188,  447, 1252,  493],
       [1223,  401, 1277,  443],
       [ 567,  457,  636,  520],
       [ 667,  432,  723,  482],
       [ 803,  384,  850,  426],
       [1167,  378, 1205,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19370., 26313.,  9204.,  3055.,  2365.,  4480.,  2907.,  2064.,
        1248.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00040.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 382,  576,  502,  682],
       [ 552,  511,  628,  578],
       [ 778,  445,  840,  516],
       [1125,  493, 1217,  578],
       [1338,  474, 1402,  524],
       [ 582,  368,  638,  416],
       [ 732,  382,  775,  422],
       [1113,  389, 1155,  424],
       [1157,  364, 1203,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12947.,  5236.,  4536.,  7998.,  3315.,  2793.,  1804.,  1548.,
        1880.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00041.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  941,   69, 1045],
       [ 278,  676,  421,  814],
       [ 702,  584,  809,  705],
       [ 696,  438,  753,  488],
       [ 519,  411,  596,  470],
       [ 653,  372,  703,  420],
       [ 740,  395,  782,  428],
       [1271,  689, 1442,  818],
       [1530,  728, 1700,  845],
       [1505,  557, 1638,  659],
       [1052,  409, 1111,  464],
       [1230,  403, 1282,  451],
       [1055,  355, 1098,  388]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 7350., 20016., 13176.,  2958.,  4680.,  2499.,  1462., 22360.,
       20178., 13802.,  3360.,  2597.,  1496.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00042.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 417,  466,  521,  541],
       [ 605,  526,  690,  607],
       [ 609,  407,  671,  480],
       [ 703,  445,  750,  499],
       [ 769,  399,  807,  432],
       [ 517,  389,  557,  420],
       [1273,  520, 1357,  582],
       [1634,  643, 1782,  745],
       [1327,  457, 1411,  526],
       [1115,  493, 1196,  563],
       [1005,  366, 1050,  407],
       [1152,  366, 1192,  407],
       [ 675,  314,  725,  388],
       [ 817,  378,  852,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 7980.,  7052.,  4662.,  2640.,  1326.,  1312.,  5355., 15347.,
        5950.,  5822.,  1932.,  1722.,  3825.,  1224.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00043.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 373,  741,  527,  897],
       [ 223,  549,  390,  666],
       [ 605,  551,  688,  620],
       [ 515,  470,  617,  559],
       [ 434,  428,  492,  470],
       [ 719,  457,  778,  507],
       [ 815,  434,  861,  466],
       [ 640,  334,  705,  426],
       [ 734,  334,  788,  399],
       [1750,  714, 1919,  829],
       [1394,  505, 1490,  572],
       [1046,  407, 1107,  457],
       [1151,  418, 1213,  476],
       [1221,  395, 1286,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([24335., 19824.,  5880.,  9270.,  2537.,  3060.,  1551.,  6138.,
        3630., 19720.,  6596.,  3162.,  3717.,  3234.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00044.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  722,  125,  870],
       [ 344,  803,  509,  947],
       [ 327,  582,  509,  734],
       [ 300,  499,  382,  555],
       [ 615,  574,  711,  647],
       [ 794,  539,  859,  601],
       [ 578,  366,  669,  488],
       [ 713,  363,  780,  445],
       [ 502,  393,  542,  426],
       [1440,  526, 1536,  603],
       [1273,  430, 1334,  474],
       [ 998,  357, 1050,  395],
       [1082,  374, 1127,  414],
       [1152,  359, 1205,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([18774., 24070., 27999.,  4731.,  7178.,  4158., 11316.,  5644.,
        1394.,  7566.,  2790.,  2067.,  1886.,  2214.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00045.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  843,  209, 1045],
       [ 294,  884,  498, 1043],
       [ 652,  845,  802,  993],
       [  42,  632,  173,  722],
       [ 467,  422,  602,  593],
       [ 657,  418,  746,  528],
       [ 415,  441,  463,  476],
       [1286,  441, 1352,  493],
       [1190,  382, 1244,  426],
       [ 807,  388,  850,  426],
       [ 578,  380,  625,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([42630., 32800., 22499., 12012., 23392.,  9990.,  1764.,  3551.,
        2475.,  1716.,  1872.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00046.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 202,  520,  444,  811],
       [ 525,  514,  673,  689],
       [ 571,  459,  636,  495],
       [ 790,  445,  844,  486],
       [ 515,  426,  569,  474],
       [ 571,  386,  627,  426],
       [ 494,  384,  534,  426],
       [1198,  389, 1248,  434],
       [1130,  349, 1169,  380],
       [ 811,  355,  850,  389],
       [ 642,  347,  686,  395],
       [ 742,  357,  786,  389]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([70956., 26224.,  2442.,  2310.,  2695.,  2337.,  1763.,  2346.,
        1280.,  1400.,  2205.,  1485.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00047.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  92,  772,  446, 1049],
       [   2,  655,   80,  749],
       [ 734,  559,  819,  626],
       [ 448,  549,  542,  616],
       [ 390,  495,  471,  557],
       [ 403,  434,  463,  480],
       [ 494,  432,  567,  491],
       [1378,  763, 1550,  897],
       [ 592,  382,  640,  434],
       [ 807,  399,  852,  438],
       [ 730,  395,  769,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([98690.,  7505.,  5848.,  6460.,  5166.,  2867.,  4440., 23355.,
        2597.,  1840.,  1600.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00048.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 594,  832,  750,  988],
       [ 163,  741,  321,  864],
       [ 136,  622,  267,  730],
       [ 236,  509,  327,  574],
       [ 352,  511,  455,  589],
       [ 498,  430,  571,  497],
       [ 686,  453,  742,  503],
       [ 788,  466,  846,  526],
       [1172,  540, 1263,  618],
       [ 794,  391,  840,  434],
       [ 598,  370,  638,  409],
       [ 734,  366,  773,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24649., 19716., 14388.,  6072.,  8216.,  5032.,  2907.,  3599.,
        7268.,  2068.,  1640.,  1440.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00049.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  645,   49,  770],
       [  52,  659,  232,  795],
       [ 702,  613,  805,  718],
       [ 586,  566,  665,  641],
       [ 327,  511,  428,  614],
       [ 448,  476,  507,  526],
       [ 775,  459,  832,  520],
       [ 542,  401,  602,  453],
       [ 705,  405,  755,  453],
       [1494,  705, 1646,  818],
       [1584,  578, 1746,  709],
       [1194,  589, 1288,  672],
       [1084,  439, 1146,  495]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 6300., 24797., 11024.,  6080., 10608.,  3060.,  3596.,  3233.,
        2499., 17442., 21516.,  7980.,  3591.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00050.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  682,  140,  853],
       [ 294,  843,  469,  995],
       [ 705,  599,  802,  701],
       [ 246,  582,  350,  659],
       [ 442,  457,  532,  526],
       [ 650,  470,  721,  536],
       [1261,  511, 1346,  578],
       [1380,  470, 1475,  547],
       [1065,  453, 1123,  505],
       [ 796,  418,  838,  459],
       [ 575,  403,  615,  438],
       [1032,  389, 1080,  418],
       [ 650,  380,  692,  409],
       [ 813,  374,  850,  409],
       [ 732,  374,  771,  413],
       [ 532,  368,  571,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([24252., 26928., 10094.,  8190.,  6370.,  4824.,  5848.,  7488.,
        3127.,  1806.,  1476.,  1470.,  1290.,  1368.,  1600.,  1120.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00051.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1730,  901, 1919, 1044],
       [ 515,  603,  623,  711],
       [ 252,  563,  377,  668],
       [1517,  584, 1628,  655],
       [ 494,  451,  550,  495],
       [ 761,  505,  827,  563],
       [ 459,  407,  511,  441],
       [ 605,  424,  653,  461],
       [ 702,  428,  755,  472],
       [ 794,  428,  850,  470],
       [1150,  420, 1205,  464],
       [1261,  403, 1330,  463],
       [ 984,  382, 1034,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27360., 11881., 13356.,  8064.,  2565.,  3953.,  1855.,  1862.,
        2430.,  2451.,  2520.,  4270.,  2091.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00052.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 134, 1003,  325, 1047],
       [ 673,  678,  782,  791],
       [1342,  805, 1513,  932],
       [1350,  584, 1453,  668],
       [1332,  474, 1402,  526],
       [1182,  364, 1234,  409],
       [1082,  370, 1125,  405],
       [ 748,  520,  827,  582],
       [ 636,  507,  707,  578],
       [ 505,  497,  584,  551],
       [ 350,  539,  430,  605],
       [ 327,  468,  398,  530],
       [ 467,  384,  525,  443],
       [ 577,  474,  634,  522]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 8640., 12540., 22016.,  8840.,  3763.,  2438.,  1584.,  5040.,
        5184.,  4400.,  5427.,  4536.,  3540.,  2842.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00053.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   7,  714,  155,  824],
       [  48,  586,  165,  680],
       [ 311,  618,  430,  714],
       [ 448,  686,  578,  809],
       [ 632,  716,  761,  841],
       [ 346,  434,  425,  516],
       [ 473,  395,  521,  432],
       [1723,  713, 1903,  834],
       [1148,  549, 1221,  605],
       [1202,  464, 1269,  518],
       [1223,  411, 1275,  451]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16539., 11210., 11640., 16244., 16380.,  6640.,  1862., 22082.,
        4218.,  3740.,  2173.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00054.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  96,  799,  282,  939],
       [ 113,  526,  236,  649],
       [1392,  597, 1513,  668],
       [1413,  524, 1503,  589],
       [1065,  434, 1113,  480],
       [1119,  399, 1167,  438],
       [ 382,  439,  442,  491]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([26367., 15376.,  8784.,  6006.,  2303.,  1960.,  3233.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00055.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1207,  618, 1317,  699],
       [1202,  457, 1269,  507],
       [1267,  428, 1321,  484],
       [ 219,  520,  305,  584],
       [ 455,  411,  503,  449],
       [ 644,  376,  690,  422],
       [1009,  382, 1050,  414],
       [1063,  359, 1105,  391],
       [ 632,  326,  684,  380]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([9102., 3468., 3135., 5655., 1911., 2209., 1386., 1419., 2915.],
      dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00056.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 348,  468,  413,  511],
       [ 586,  434,  657,  488],
       [ 494,  388,  538,  422],
       [ 592,  343,  661,  414],
       [ 742,  374,  780,  407],
       [1765,  891, 1919, 1049],
       [1067,  684, 1178,  784],
       [1586,  605, 1744,  726],
       [1098,  474, 1169,  528],
       [1109,  395, 1161,  434],
       [1178,  380, 1223,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 2904.,  3960.,  1575.,  5040.,  1326., 24645., 11312., 19398.,
        3960.,  2120.,  1794.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00057.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 163,  551,  255,  622],
       [ 465,  518,  565,  599],
       [ 392,  439,  448,  486],
       [ 527,  364,  623,  464],
       [ 711,  416,  759,  472],
       [ 992,  489, 1048,  534],
       [1227,  616, 1340,  716],
       [1340,  568, 1459,  659],
       [1603,  636, 1732,  726],
       [1350,  468, 1434,  530],
       [1046,  403, 1092,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 6696.,  8282.,  2736.,  9797.,  2793.,  2622., 11514., 11040.,
       11830.,  5355.,  1927.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00058.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 157,  651,  353,  861],
       [ 207,  534,  296,  586],
       [ 405,  424,  550,  543],
       [ 634,  507,  707,  582],
       [1386,  841, 1567,  963],
       [1105,  484, 1177,  532],
       [1369,  486, 1446,  543],
       [1188,  447, 1265,  501],
       [1225,  397, 1284,  447],
       [ 953,  399,  998,  438],
       [ 650,  384,  698,  430],
       [ 505,  380,  548,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([41567.,  4770., 17520.,  5624., 22386.,  3577.,  4524.,  4290.,
        3060.,  1840.,  2303.,  1628.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00059.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 409,  716,  553,  859],
       [ 186,  503,  421,  682],
       [ 584,  428,  652,  495],
       [ 413,  436,  471,  476],
       [1627,  795, 1805,  914],
       [1144,  541, 1221,  595],
       [1048,  401, 1098,  451],
       [1246,  413, 1296,  447],
       [1109,  382, 1165,  424],
       [ 661,  386,  707,  420],
       [ 538,  364,  577,  395],
       [1146,  357, 1194,  397]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20880., 42480.,  4692.,  2419., 21480.,  4290.,  2601.,  1785.,
        2451.,  1645.,  1280.,  2009.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00060.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  649,  152,  903],
       [ 244,  513,  328,  568],
       [ 461,  507,  561,  613],
       [1307,  538, 1390,  599],
       [1040,  424, 1096,  468],
       [1161,  372, 1211,  401],
       [ 603,  428,  659,  484],
       [ 480,  399,  528,  436],
       [ 711,  413,  759,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([39015.,  4760., 10807.,  5208.,  2565.,  1530.,  3249.,  1862.,
        1813.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00001.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  605,   98,  726],
       [ 353,  591,  461,  699],
       [ 405,  476,  478,  536],
       [ 553,  397,  598,  432],
       [ 702,  434,  750,  472],
       [ 809,  384,  850,  416],
       [1282,  663, 1413,  782],
       [1128,  516, 1200,  566],
       [1198,  426, 1307,  536],
       [1038,  403, 1086,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11834., 11881.,  4514.,  1656.,  1911.,  1386., 15840.,  3723.,
       12210.,  1813.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00002.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  884,   90, 1045],
       [ 138,  628,  263,  722],
       [ 615,  528,  696,  591],
       [ 478,  443,  540,  491],
       [ 791,  436,  841,  482],
       [1177,  922, 1363, 1043],
       [1534,  745, 1707,  857],
       [1127,  620, 1236,  705],
       [1140,  507, 1221,  582],
       [1055,  424, 1107,  470],
       [1125,  376, 1202,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14742., 11970.,  5248.,  3087.,  2397., 22814., 19662.,  9460.,
        6232.,  2491.,  6396.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00003.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 363,  770,  521,  905],
       [ 342,  526,  425,  586],
       [ 746,  539,  819,  603],
       [ 671,  366,  707,  414],
       [1036,  578, 1121,  657],
       [1294,  547, 1382,  613],
       [1503,  578, 1607,  647],
       [1007,  466, 1067,  513],
       [1071,  422, 1123,  474],
       [1073,  345, 1136,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21624.,  5124.,  4810.,  1813.,  6880.,  5963.,  7350.,  2928.,
        2809.,  3904.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00004.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 605,  795,  752,  941],
       [  36,  688,  188,  805],
       [ 621,  409,  675,  463],
       [1223,  609, 1336,  701],
       [1525,  516, 1873,  797],
       [1313,  457, 1373,  503],
       [1182,  455, 1242,  497],
       [ 986,  455, 1042,  497],
       [ 950,  389,  998,  430],
       [1023,  376, 1067,  414],
       [ 728,  370,  769,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21756., 18054.,  3025., 10602., 98418.,  2867.,  2623.,  2451.,
        2058.,  1755.,  1512.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00005.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1805,  916, 1919, 1048],
       [1327,  414, 1503,  580],
       [1098,  472, 1171,  530],
       [ 525,  476,  609,  559],
       [ 705,  416,  748,  455],
       [ 648,  389,  678,  424],
       [ 959,  395, 1002,  432],
       [1119,  397, 1163,  432],
       [1205,  395, 1253,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15295., 29559.,  4366.,  7140.,  1760.,  1116.,  1672.,  1620.,
        1764.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00006.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 317,  605,  457,  749],
       [ 642,  488,  707,  538],
       [ 582,  441,  636,  482],
       [ 713,  399,  759,  443],
       [ 573,  378,  623,  424],
       [ 648,  386,  688,  424],
       [1044,  403, 1092,  445],
       [1219,  361, 1336,  478],
       [1130,  355, 1169,  388],
       [1063,  359, 1109,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20445.,  3366.,  2310.,  2115.,  2397.,  1599.,  2107., 13924.,
        1360.,  1739.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00007.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 509,  624,  617,  713],
       [ 471,  526,  550,  586],
       [ 663,  455,  732,  524],
       [ 602,  428,  652,  472],
       [ 492,  426,  561,  486],
       [1278,  697, 1413,  803],
       [1117,  466, 1196,  543],
       [1221,  470, 1294,  526],
       [1146,  332, 1230,  414],
       [ 730,  403,  773,  436],
       [ 659,  370,  700,  413],
       [1005,  357, 1046,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9810.,  4880.,  4900.,  2295.,  4270., 14552.,  6240.,  4218.,
        7055.,  1496.,  1848.,  1638.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00008.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 213,  701,  357,  813],
       [ 548,  574,  650,  664],
       [ 334,  507,  438,  597],
       [ 505,  499,  577,  561],
       [ 682,  463,  736,  509],
       [ 615,  414,  665,  459],
       [1125,  501, 1200,  572],
       [1053,  397, 1109,  453],
       [1136,  403, 1192,  447],
       [1082,  318, 1157,  380],
       [ 488,  397,  536,  436],
       [ 663,  382,  709,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16385.,  9373.,  9555.,  4599.,  2585.,  2346.,  5472.,  3249.,
        2565.,  4788.,  1960.,  1833.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00009.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 221,  866,  440, 1043],
       [   2,  674,  173,  830],
       [ 296,  626,  417,  718],
       [ 573,  578,  667,  647],
       [ 527,  482,  609,  547],
       [ 369,  459,  428,  507],
       [ 611,  426,  677,  478],
       [ 717,  389,  767,  426],
       [1065,  638, 1177,  728],
       [1055,  418, 1109,  459],
       [1009,  355, 1052,  399],
       [1075,  366, 1123,  399],
       [ 815,  384,  842,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([39160., 27004., 11346.,  6650.,  5478.,  2940.,  3551.,  1938.,
       10283.,  2310.,  1980.,  1666.,   840.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00010.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 265,  878,  444, 1038],
       [ 109,  572,  219,  639],
       [ 355,  595,  471,  693],
       [ 513,  509,  594,  584],
       [1411,  866, 1615, 1030],
       [1690,  691, 1850,  782],
       [ 998,  474, 1059,  520],
       [ 673,  443,  734,  497],
       [ 800,  438,  844,  474]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28980.,  7548., 11583.,  6232., 33825., 14812.,  2914.,  3410.,
        1665.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00011.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  895,  130, 1059],
       [ 278,  659,  423,  786],
       [ 567,  549,  671,  632],
       [ 759,  539,  832,  595],
       [ 494,  338,  580,  424],
       [ 652,  391,  698,  428],
       [ 728,  401,  771,  434],
       [1157,  545, 1242,  614],
       [1400,  632, 1517,  707],
       [1577,  611, 1711,  709],
       [1394,  507, 1484,  561],
       [ 961,  399, 1005,  432],
       [ 825,  384,  861,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21615., 18688.,  8820.,  4218.,  7569.,  1786.,  1496.,  6020.,
        8968., 13365.,  5005.,  1530.,  1591.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00012.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 627,  784,  767,  914],
       [ 280,  797,  482,  986],
       [ 805,  459,  859,  499],
       [ 676,  466,  738,  511],
       [ 584,  449,  640,  495],
       [ 402,  366,  527,  478],
       [ 721,  378,  775,  443],
       [ 648,  353,  686,  389],
       [1225,  486, 1296,  532],
       [1348,  474, 1425,  532],
       [1069,  436, 1125,  478],
       [1255,  422, 1313,  459]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18471., 38570.,  2255.,  2898.,  2679., 14238.,  3630.,  1443.,
        3384.,  4602.,  2451.,  2242.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00013.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 227,  414,  423,  572],
       [ 434,  563,  523,  634],
       [ 571,  578,  657,  651],
       [ 738,  599,  825,  678],
       [ 667,  434,  738,  528],
       [ 578,  393,  628,  432],
       [1046,  618, 1144,  697],
       [1715,  891, 1919, 1045],
       [1727,  649, 1919,  869],
       [1227,  399, 1280,  445],
       [1130,  409, 1180,  447],
       [1167,  374, 1219,  401],
       [1015,  376, 1059,  409],
       [ 615,  349,  652,  391]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([31323.,  6480.,  6438.,  7040.,  6840.,  2040.,  7920., 31775.,
       42653.,  2538.,  1989.,  1484.,  1530.,  1634.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00014.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  857,  194, 1005],
       [ 236,  882,  432, 1041],
       [ 530,  541,  653,  699],
       [1315,  555, 1411,  636],
       [1409,  478, 1578,  609],
       [ 988,  464, 1046,  516],
       [   0,  503,  234,  763],
       [ 446,  468,  523,  534],
       [ 565,  376,  615,  432],
       [ 498,  380,  546,  418],
       [1146,  361, 1190,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28608., 31520., 19716.,  7954., 22440.,  3127., 61335.,  5226.,
        2907.,  1911.,  1575.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00015.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 136,  861,  405, 1045],
       [ 123,  630,  265,  747],
       [ 490,  420,  555,  486],
       [ 400,  422,  465,  478],
       [1403,  791, 1632,  999],
       [1259,  401, 1365,  489],
       [1163,  436, 1227,  491],
       [ 957,  393, 1002,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([49950., 16874.,  4422.,  3762., 48070.,  9523.,  3640.,  1840.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00016.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 334,  499,  440,  591],
       [ 213,  507,  311,  586],
       [1159,  530, 1261,  622],
       [1171,  355, 1246,  420],
       [1086,  380, 1136,  413],
       [ 469,  409,  515,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([9951., 7920., 9579., 5016., 1734., 2115.], dtype=float32), 'gt_overlaps': <6x16 sparse matrix of type '<type 'numpy.float32'>'
	with 6 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00017.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  657,  177,  826],
       [ 340,  478,  409,  530],
       [ 555,  303,  609,  384],
       [1061,  672, 1184,  788],
       [1300,  713, 1438,  809],
       [1457,  668, 1588,  757],
       [1498,  486, 1698,  672],
       [1073,  426, 1132,  488],
       [1109,  328, 1163,  382]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([29920.,  3710.,  4510., 14508., 13483., 11880., 37587.,  3780.,
        3025.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00018.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  71,  599,  186,  686],
       [ 519,  324,  584,  414],
       [1325,  714, 1453,  811],
       [ 996,  486, 1063,  549],
       [1132,  513, 1209,  568],
       [1238,  497, 1311,  547],
       [1321,  401, 1436,  522],
       [1023,  372, 1065,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10208.,  6006., 12642.,  4352.,  4368.,  3774., 14152.,  1849.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00019.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 444,  347,  538,  459],
       [1146,  513, 1215,  572],
       [1211,  347, 1294,  453],
       [1136,  413, 1184,  451],
       [1061,  422, 1111,  463],
       [ 959,  403, 1003,  441],
       [ 530,  334,  586,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10735.,  4200.,  8988.,  1911.,  2142.,  1755.,  4104.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00020.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 309,  388,  436,  536],
       [ 463,  361,  538,  443],
       [1425,  628, 1586,  749],
       [1067,  424, 1115,  463],
       [1138,  322, 1205,  399],
       [1073,  368, 1107,  395],
       [1013,  372, 1052,  405],
       [ 932,  355,  969,  384]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19072.,  6308., 19764.,  1960.,  5304.,   980.,  1360.,  1140.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00021.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  53,  459,  259,  672],
       [ 344,  407,  444,  520],
       [1148,  874, 1334, 1034],
       [1359,  761, 1503,  859],
       [1242,  480, 1330,  549],
       [ 530,  361,  573,  405],
       [1084,  303, 1136,  363],
       [1019,  378, 1053,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([44298., 11514., 30107., 14355.,  6230.,  1980.,  3233.,  1050.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00022.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 123,  480,  277,  638],
       [1344,  801, 1500,  913],
       [1550,  759, 1732,  872],
       [1240,  651, 1357,  728],
       [1169,  543, 1246,  597],
       [1025,  549, 1109,  613],
       [1140,  405, 1205,  457],
       [ 469,  395,  525,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24645., 17741., 20862.,  9204.,  4290.,  5525.,  3498.,  2907.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00023.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1515,  574, 1640,  655],
       [1294,  541, 1382,  603],
       [1148,  553, 1227,  609],
       [1111,  493, 1184,  547],
       [1084,  447, 1142,  484],
       [ 980,  436, 1036,  480],
       [ 371,  445,  442,  505],
       [ 471,  403,  528,  447],
       [ 594,  309,  663,  413],
       [1080,  361, 1132,  401],
       [ 682,  374,  721,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10332.,  5607.,  4560.,  4070.,  2242.,  2565.,  4392.,  2610.,
        7350.,  2173.,  1280.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00024.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 194,  524,  294,  611],
       [1734,  903, 1919, 1042],
       [1317,  463, 1398,  518],
       [1184,  447, 1240,  491],
       [1077,  451, 1130,  501],
       [ 384,  449,  452,  499],
       [ 625,  420,  678,  464],
       [ 546,  330,  634,  451],
       [1053,  420, 1102,  463]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 8888., 26040.,  4592.,  2565.,  2754.,  3519.,  2430., 10858.,
        2200.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00025.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 209,  528,  309,  597],
       [ 513,  505,  590,  564],
       [1359,  591, 1467,  661],
       [ 452,  355,  590,  526],
       [ 796,  405,  842,  451],
       [1028,  395, 1069,  432],
       [1115,  391, 1157,  430],
       [1205,  397, 1259,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 7070.,  4680.,  7739., 23908.,  2209.,  1596.,  1720.,  2585.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00026.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 248,  684,  382,  789],
       [   2,  666,   36,  749],
       [ 271,  409,  505,  655],
       [ 759,  472,  825,  547],
       [1453,  670, 1594,  770],
       [1602,  624, 1730,  709],
       [1213,  470, 1282,  518],
       [ 707,  428,  753,  468],
       [ 642,  418,  686,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14310.,  2940., 58045.,  5092., 14342., 11094.,  3430.,  1927.,
        1710.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00027.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  501,  328,  968],
       [ 659,  626,  778,  745],
       [ 644,  511,  713,  570],
       [ 542,  499,  607,  555],
       [1294,  713, 1425,  807],
       [1253,  501, 1330,  563],
       [1359,  476, 1436,  528],
       [1128,  401, 1186,  443],
       [ 615,  407,  671,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([153972.,  14400.,   4200.,   3762.,  12540.,   4914.,   4134.,
         2537.,   3306.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00028.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 488,  672,  604,  762],
       [ 334,  649,  440,  730],
       [ 525,  476,  603,  543],
       [ 427,  430,  477,  470],
       [ 527,  411,  582,  461],
       [1292,  705, 1427,  803],
       [1132,  520, 1202,  574],
       [1153,  422, 1205,  470],
       [1230,  405, 1286,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10647.,  8774.,  5372.,  2091.,  2856., 13464.,  3905.,  2597.,
        2223.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00029.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1134,  893, 1313, 1043],
       [1446,  582, 1709,  791],
       [1094,  661, 1203,  747],
       [1132,  509, 1207,  564],
       [1067,  430, 1111,  470],
       [ 332,  593,  463,  713],
       [ 396,  484,  484,  553],
       [ 286,  503,  357,  559],
       [ 511,  416,  580,  472]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27180., 55440.,  9570.,  4256.,  1845., 15972.,  6230.,  4104.,
        3990.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00030.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  916,   69, 1045],
       [ 109,  634,  265,  743],
       [  19,  622,  128,  699],
       [ 392,  474,  488,  563],
       [1021,  557, 1103,  634],
       [1211,  613, 1325,  689],
       [1453,  680, 1594,  772],
       [1259,  459, 1400,  586],
       [1007,  482, 1071,  534],
       [1063,  424, 1115,  466],
       [ 423,  416,  484,  474]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9100., 17270.,  8580.,  8730.,  6474.,  8855., 13206., 18176.,
        3445.,  2279.,  3658.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00031.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 123,  597,  292,  741],
       [ 282,  484,  363,  559],
       [ 428,  422,  484,  464],
       [ 527,  418,  580,  457],
       [1255,  513, 1336,  570],
       [1107,  474, 1167,  528],
       [1169,  386, 1263,  482],
       [ 980,  441, 1032,  484]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24650.,  6232.,  2451.,  2160.,  4756.,  3355.,  9215.,  2332.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00032.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  603,  123,  719],
       [ 296,  491,  375,  539],
       [ 415,  488,  492,  539],
       [ 702,  416,  753,  451],
       [ 505,  382,  550,  416],
       [ 586,  376,  638,  416],
       [1161,  428, 1217,  474],
       [1044,  405, 1096,  445],
       [1109,  351, 1184,  416],
       [ 952,  380,  994,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14274.,  3920.,  4056.,  1872.,  1610.,  2173.,  2679.,  2173.,
        5016.,  1677.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00033.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 184,  614,  309,  705],
       [  53,  601,  178,  670],
       [ 628,  505,  703,  568],
       [ 517,  418,  578,  474],
       [ 617,  426,  673,  463],
       [ 440,  420,  498,  459],
       [1336,  711, 1475,  839],
       [1719,  597, 1919,  852],
       [1094,  380, 1136,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11592.,  8820.,  4864.,  3534.,  2166.,  2360., 18060., 51456.,
        1505.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00034.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 405,  722,  548,  849],
       [1580,  749, 1773,  889],
       [1738,  720, 1896,  824],
       [1234,  641, 1352,  722],
       [1448,  464, 1630,  628],
       [1157,  516, 1228,  586],
       [ 505,  522,  580,  564],
       [ 380,  491,  477,  570],
       [ 319,  476,  388,  530],
       [ 448,  420,  498,  459],
       [ 565,  395,  617,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18432., 27354., 16695.,  9758., 30195.,  5112.,  3268.,  7840.,
        3850.,  2040.,  2226.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00035.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 186,  738,  338,  845],
       [  84,  641,  246,  772],
       [ 105,  578,  215,  643],
       [ 321,  478,  396,  532],
       [ 484,  441,  544,  503],
       [1503,  974, 1755, 1041],
       [1842,  734, 1919,  912],
       [1469,  553, 1559,  614],
       [1317,  541, 1411,  618],
       [1109,  489, 1178,  541],
       [1298,  403, 1423,  513],
       [1073,  426, 1127,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16524., 21516.,  7326.,  4180.,  3843., 17204., 13962.,  5642.,
        7410.,  3710., 13986.,  2365.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00036.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 100,  572,  209,  657],
       [ 334,  524,  428,  603],
       [ 509,  430,  569,  474],
       [ 428,  414,  488,  463],
       [1194,  591, 1303,  682],
       [1509,  541, 1659,  676],
       [1327,  461, 1394,  507],
       [1186,  447, 1248,  495],
       [1202,  361, 1298,  445],
       [1057,  409, 1100,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9460.,  7600.,  2745.,  3050., 10120., 20536.,  3196.,  3087.,
        8245.,  1980.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00037.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  686,  163,  834],
       [ 367,  514,  448,  574],
       [ 300,  480,  380,  541],
       [1538,  993, 1784, 1043],
       [1394,  618, 1515,  705],
       [1532,  588, 1663,  674],
       [1346,  451, 1446,  549],
       [1092,  461, 1159,  518],
       [ 723,  378,  769,  422],
       [ 496,  386,  540,  432],
       [1232,  407, 1286,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24138.,  5002.,  5022., 12597., 10736., 11484.,  9999.,  3944.,
        2115.,  2115.,  2365.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00038.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  38,  684,  188,  788],
       [  46,  589,  173,  678],
       [ 403,  436,  463,  482],
       [ 684,  424,  746,  491],
       [1494,  697, 1644,  797],
       [1207,  588, 1336,  691],
       [1525,  586, 1655,  680],
       [1359,  482, 1438,  539],
       [1227,  482, 1303,  539],
       [1248,  397, 1321,  474],
       [1032,  397, 1086,  441],
       [ 732,  389,  773,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15855., 11520.,  2867.,  4284., 15251., 13520., 12445.,  4640.,
        4466.,  5772.,  2475.,  1680.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00039.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 244,  513,  325,  578],
       [ 602,  503,  692,  593],
       [ 444,  363,  525,  449],
       [ 698,  445,  750,  489],
       [1480,  584, 1603,  655],
       [1265,  514, 1350,  576],
       [1092,  453, 1175,  524],
       [1350,  480, 1436,  541],
       [1255,  420, 1321,  466],
       [1142,  411, 1194,  449],
       [ 723,  380,  771,  420],
       [ 653,  391,  700,  424],
       [1180,  361, 1236,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([5412., 8281., 7134., 2385., 8928., 5418., 6048., 5394., 3149.,
       2067., 2009., 1632., 2907.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00040.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 388,  670,  559,  855],
       [1480,  938, 1696, 1045],
       [1727,  884, 1919, 1041],
       [1255,  609, 1402,  753],
       [1717,  697, 1900,  807],
       [   0,  653,   51,  772],
       [ 619,  543,  700,  611],
       [1278,  476, 1353,  522],
       [ 334,  413,  428,  514],
       [ 577,  455,  638,  503],
       [ 686,  438,  746,  495],
       [1163,  428, 1217,  468],
       [1244,  418, 1309,  464],
       [1036,  388, 1086,  436],
       [1188,  382, 1236,  426],
       [ 552,  403,  603,  445],
       [ 452,  414,  498,  455],
       [ 725,  401,  767,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([31992., 23436., 30494., 21460., 20424.,  6240.,  5658.,  3572.,
        9690.,  3038.,  3538.,  2255.,  3102.,  2499.,  2205.,  2236.,
        1974.,  1763.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00041.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 403,  755,  550,  891],
       [ 392,  586,  503,  672],
       [ 584,  534,  688,  622],
       [ 671,  466,  736,  513],
       [ 459,  459,  530,  520],
       [ 325,  474,  396,  524],
       [ 125,  484,  275,  632],
       [ 598,  428,  652,  474],
       [1423,  870, 1625, 1013],
       [1605,  770, 1850,  932],
       [1373,  593, 1498,  678],
       [1205,  591, 1303,  661],
       [1428,  522, 1532,  595],
       [1128,  470, 1215,  553],
       [1157,  409, 1211,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([20276.,  9744.,  9345.,  3168.,  4464.,  3672., 22499.,  2585.,
       29232., 40098., 10836.,  7029.,  7770.,  7392.,  2145.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00042.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  974,   82, 1041],
       [ 327,  766,  528,  949],
       [ 550,  591,  646,  668],
       [ 278,  555,  388,  647],
       [ 105,  574,  202,  647],
       [ 486,  514,  565,  582],
       [ 411,  432,  473,  476],
       [ 536,  414,  594,  459],
       [1082,  726, 1213,  832],
       [1302,  699, 1473,  838],
       [1553,  761, 1719,  864],
       [1527,  595, 1648,  664],
       [1330,  549, 1448,  639],
       [1192,  578, 1286,  653],
       [1225,  474, 1309,  532],
       [1290,  439, 1363,  486],
       [1100,  468, 1161,  513],
       [1065,  391, 1121,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 5508., 37168.,  7566., 10323.,  7252.,  5520.,  2835.,  2714.,
       14124., 24080., 17368.,  8540., 10829.,  7220.,  5015.,  3552.,
        2852.,  3819.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00043.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 184,  939,  402, 1045],
       [ 203,  714,  350,  838],
       [   0,  768,   44,  926],
       [ 448,  478,  525,  545],
       [ 280,  491,  359,  553],
       [ 509,  438,  569,  491],
       [1375,  861, 1578, 1011],
       [1503,  701, 1663,  818],
       [1309,  557, 1394,  613],
       [1136,  516, 1234,  593],
       [ 998,  509, 1069,  566],
       [1094,  463, 1159,  513],
       [1203,  453, 1278,  509],
       [1344,  480, 1417,  526]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([23433., 18500.,  7155.,  5304.,  5040.,  3294., 30804., 18998.,
        4902.,  7722.,  4176.,  3366.,  4332.,  3478.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00044.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 267,  599,  386,  705],
       [  32,  603,  157,  680],
       [ 373,  513,  459,  591],
       [ 452,  461,  517,  511],
       [ 684,  457,  742,  505],
       [ 432,  414,  484,  470],
       [1490,  914, 1752, 1043],
       [1632,  661, 1784,  766],
       [1044,  622, 1134,  699],
       [1169,  578, 1261,  655],
       [1282,  528, 1373,  597],
       [1188,  455, 1250,  497],
       [1238,  414, 1294,  453],
       [1069,  430, 1132,  484],
       [1123,  395, 1184,  439],
       [ 965,  420, 1009,  457],
       [ 807,  418,  855,  455],
       [1042,  397, 1082,  434],
       [ 488,  389,  530,  422],
       [ 715,  391,  752,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12840.,  9828.,  6873.,  3366.,  2891.,  3021., 34190., 16218.,
        7098.,  7254.,  6440.,  2709.,  2280.,  3520.,  2790.,  1710.,
        1862.,  1558.,  1462.,  1216.], dtype=float32), 'gt_overlaps': <20x16 sparse matrix of type '<type 'numpy.float32'>'
	with 20 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00045.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  78,  661,  234,  786],
       [ 253,  551,  353,  622],
       [ 573,  574,  665,  659],
       [ 788,  491,  850,  543],
       [ 302,  482,  377,  541],
       [ 646,  447,  698,  484],
       [ 407,  432,  473,  480],
       [1542,  720, 1725,  851],
       [1559,  639, 1688,  716],
       [1198,  572, 1307,  663],
       [1380,  503, 1471,  564],
       [1180,  438, 1236,  491],
       [1086,  472, 1144,  516],
       [ 980,  470, 1042,  513],
       [1111,  399, 1157,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([19782.,  7272.,  7998.,  3339.,  4560.,  2014.,  3283., 24288.,
       10140., 10120.,  5704.,  3078.,  2655.,  2772.,  1598.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00046.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 202,  930,  413, 1041],
       [  55,  584,  167,  676],
       [ 705,  645,  811,  738],
       [ 503,  547,  588,  605],
       [ 265,  503,  348,  561],
       [1636,  814, 1846,  943],
       [1290,  526, 1384,  599],
       [1102,  451, 1169,  513],
       [1253,  420, 1309,  468],
       [1327,  495, 1392,  543],
       [ 684,  447,  744,  499],
       [ 417,  436,  471,  482],
       [ 553,  401,  615,  445],
       [ 494,  393,  546,  436],
       [1038,  407, 1082,  441],
       [1121,  389, 1161,  432],
       [ 946,  397,  998,  432],
       [ 719,  386,  765,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([23744., 10509., 10058.,  5074.,  4956., 27430.,  7030.,  4284.,
        2793.,  3234.,  3233.,  2585.,  2835.,  2332.,  1575.,  1804.,
        1908.,  2021.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00047.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 152,  772,  317,  901],
       [   3,  628,  115,  720],
       [ 250,  507,  338,  586],
       [ 577,  563,  665,  632],
       [ 461,  449,  538,  511],
       [ 382,  441,  450,  495],
       [ 682,  432,  746,  493],
       [ 715,  391,  757,  438],
       [1246,  636, 1363,  734],
       [1328,  561, 1427,  630],
       [1180,  424, 1240,  491],
       [1048,  386, 1100,  436],
       [1171,  382, 1221,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21580., 10509.,  7120.,  6230.,  4914.,  3795.,  4030.,  2064.,
       11682.,  7000.,  4148.,  2703.,  1632.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00048.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 246,  861,  444, 1020],
       [   2,  651,   50,  789],
       [ 190,  526,  292,  603],
       [ 313,  526,  413,  609],
       [ 594,  526,  682,  611],
       [ 669,  449,  728,  501],
       [ 592,  422,  655,  470],
       [ 796,  422,  848,  463],
       [ 713,  403,  755,  432],
       [1596,  584, 1763,  734],
       [1121,  482, 1182,  545],
       [1196,  455, 1259,  501],
       [1113,  384, 1161,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([31840.,  6811.,  8034.,  8484.,  7654.,  3180.,  3136.,  2226.,
        1290., 25368.,  3968.,  3008.,  2107.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00049.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 346,  730,  519,  895],
       [  38,  655,  200,  782],
       [ 575,  543,  663,  624],
       [ 467,  505,  553,  578],
       [ 765,  509,  828,  563],
       [ 663,  463,  725,  513],
       [ 803,  439,  852,  482],
       [ 532,  420,  588,  463],
       [ 465,  418,  519,  457],
       [1452,  684, 1594,  788],
       [1765,  749, 1919,  856],
       [1369,  457, 1465,  553],
       [1044,  407, 1088,  449],
       [1123,  399, 1173,  438],
       [ 809,  397,  852,  438]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([28884., 20864.,  7298.,  6438.,  3520.,  3213.,  2200.,  2508.,
        2200., 15015., 16740.,  9409.,  1935.,  2040.,  1848.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00050.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 311,  766,  486,  936],
       [ 157,  705,  342,  851],
       [ 675,  693,  780,  793],
       [ 546,  580,  644,  649],
       [ 765,  539,  838,  605],
       [ 394,  499,  475,  559],
       [ 786,  466,  836,  513],
       [ 350,  474,  417,  516],
       [1527,  697, 1678,  807],
       [1448,  545, 1530,  609],
       [1238,  503, 1321,  570],
       [1242,  393, 1315,  459],
       [ 582,  405,  634,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([30096., 27342., 10706.,  6930.,  4958.,  5002.,  2448.,  2924.,
       16872.,  5395.,  5712.,  4958.,  2173.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00051.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 227,  878,  417, 1039],
       [ 642,  780,  780,  926],
       [  88,  655,  228,  774],
       [ 142,  568,  252,  641],
       [ 713,  595,  798,  674],
       [ 455,  478,  527,  532],
       [1088,  741, 1211,  853],
       [1363,  770, 1548,  905],
       [1277,  507, 1361,  570],
       [1292,  453, 1355,  497],
       [1144,  424, 1200,  468],
       [ 552,  403,  600,  443],
       [1169,  349, 1217,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([30942., 20433., 16920.,  8214.,  6880.,  4015., 14012., 25296.,
        5440.,  2880.,  2565.,  2009.,  2891.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00052.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 517,  972,  686, 1043],
       [ 198,  603,  323,  703],
       [ 465,  455,  528,  501],
       [ 428,  418,  488,  463],
       [ 530,  413,  586,  455],
       [ 709,  407,  757,  447],
       [1475,  947, 1700, 1039],
       [1527,  728, 1692,  838],
       [1153,  530, 1253,  614],
       [1000,  507, 1067,  564],
       [1163,  420, 1221,  466]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12240., 12726.,  3008.,  2806.,  2451.,  2009., 21018., 18426.,
        8585.,  3944.,  2773.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00053.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1119,  716, 1257,  836],
       [1200,  597, 1294,  670],
       [1275,  528, 1357,  589],
       [ 317,  543,  402,  605],
       [ 286,  499,  361,  545],
       [ 432,  474,  507,  532],
       [ 650,  484,  713,  541],
       [1071,  434, 1130,  486],
       [ 957,  414, 1003,  451],
       [ 723,  411,  767,  451],
       [ 809,  384,  848,  418],
       [ 663,  376,  702,  413],
       [ 596,  384,  642,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16819.,  7030.,  5146.,  5418.,  3572.,  4484.,  3712.,  3180.,
        1786.,  1845.,  1400.,  1520.,  1410.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00054.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  732,  138,  845],
       [   0,  632,   98,  726],
       [ 223,  574,  340,  672],
       [ 503,  634,  615,  734],
       [ 661,  484,  717,  539],
       [ 794,  445,  848,  497],
       [ 613,  416,  671,  468],
       [ 542,  418,  592,  459],
       [ 717,  395,  767,  441],
       [1015,  518, 1092,  588],
       [1098,  468, 1157,  516],
       [1161,  430, 1217,  476],
       [1023,  382, 1071,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15618.,  9405., 11682., 11413.,  3192.,  2915.,  3127.,  2142.,
        2397.,  5538.,  2940.,  2679.,  1911.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00055.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 494,  647,  605,  745],
       [ 736,  574,  825,  657],
       [ 498,  493,  586,  572],
       [ 436,  486,  500,  536],
       [ 665,  457,  728,  528],
       [ 461,  411,  513,  441],
       [ 569,  391,  613,  434],
       [1223,  618, 1327,  695],
       [ 977,  432, 1028,  482],
       [1044,  403, 1090,  441],
       [1090,  384, 1138,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11088.,  7560.,  7120.,  3315.,  4608.,  1643.,  1980.,  8190.,
        2652.,  1833.,  1617.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00056.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 534,  982,  713, 1043],
       [1319,  757, 1467,  872],
       [1107,  478, 1169,  532],
       [ 528,  586,  644,  705],
       [ 252,  651,  403,  789],
       [ 317,  472,  388,  528],
       [ 490,  436,  553,  489],
       [ 719,  405,  767,  443],
       [ 577,  397,  617,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11160., 17284.,  3465., 14040., 21128.,  4104.,  3456.,  1911.,
        1476.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00057.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 130,  951,  375, 1047],
       [  40,  601,  161,  682],
       [ 359,  511,  448,  580],
       [ 661,  480,  725,  530],
       [ 496,  447,  552,  493],
       [1138,  536, 1217,  593],
       [1048,  407, 1098,  447],
       [ 555,  401,  602,  441],
       [ 805,  370,  850,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([23862., 10004.,  6300.,  3315.,  2679.,  4640.,  2091.,  1968.,
        1840.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00058.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  59,  657,  221,  786],
       [ 509,  636,  617,  730],
       [ 352,  532,  430,  597],
       [ 463,  461,  532,  509],
       [ 786,  428,  842,  482],
       [ 711,  393,  755,  434],
       [ 450,  416,  492,  463],
       [ 659,  364,  709,  403],
       [1419,  830, 1642, 1011],
       [1690,  693, 1867,  811],
       [1067,  436, 1113,  470],
       [1005,  364, 1048,  397]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21190., 10355.,  5214.,  3430.,  3135.,  1890.,  2064.,  2040.,
       40768., 21182.,  1645.,  1496.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00059.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  17,  705,  165,  822],
       [ 288,  561,  386,  630],
       [ 311,  484,  382,  538],
       [ 728,  536,  821,  622],
       [ 659,  453,  723,  513],
       [ 615,  403,  671,  459],
       [ 513,  366,  555,  403],
       [1184,  545, 1282,  636],
       [1386,  513, 1475,  578],
       [1017,  382, 1061,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17582.,  6930.,  3960.,  8178.,  3965.,  3249.,  1634.,  9108.,
        5940.,  1755.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00060.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 532,  845,  734, 1043],
       [   2,  772,   57,  891],
       [  32,  607,  144,  691],
       [ 540,  570,  644,  661],
       [ 515,  472,  600,  549],
       [ 438,  413,  494,  463],
       [1740,  818, 1919, 1046],
       [1196,  601, 1307,  703],
       [1465,  572, 1567,  638],
       [1244,  420, 1303,  468],
       [1094,  443, 1155,  491]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([40397.,  6720.,  9605.,  9660.,  6708.,  2907., 41220., 11536.,
        6901.,  2940.,  3038.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00001.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 403,  722,  544,  841],
       [ 134,  572,  252,  641],
       [ 484,  447,  552,  505],
       [ 780,  459,  834,  507],
       [ 452,  409,  502,  449],
       [ 721,  399,  765,  436],
       [1640,  674, 1800,  782],
       [1103,  466, 1163,  509],
       [1065,  411, 1115,  463],
       [1252,  420, 1307,  463]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17040.,  8330.,  4071.,  2695.,  2091.,  1710., 17549.,  2684.,
        2703.,  2464.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00002.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1765,  876, 1919, 1046],
       [1655,  653, 1850,  795],
       [1363,  497, 1446,  561],
       [ 709,  597,  792,  670],
       [ 305,  543,  411,  620],
       [ 365,  457,  430,  503],
       [ 663,  463,  725,  520],
       [ 523,  382,  563,  414],
       [ 725,  393,  769,  434],
       [ 655,  358,  715,  412],
       [1040,  395, 1086,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([26505., 28028.,  5460.,  6216.,  8346.,  3102.,  3654.,  1353.,
        1890.,  3355.,  1786.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00003.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  747,   96,  893],
       [ 538,  586,  640,  682],
       [ 221,  524,  311,  589],
       [ 680,  461,  738,  516],
       [ 617,  399,  680,  463],
       [ 467,  413,  509,  453],
       [ 513,  357,  559,  413],
       [1515,  922, 1753, 1041],
       [1771,  761, 1919,  880],
       [1348,  559, 1471,  668],
       [1367,  484, 1465,  557],
       [1228,  411, 1290,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14259.,  9991.,  6006.,  3304.,  4160.,  1763.,  2679., 28680.,
       17880., 13640.,  7326.,  2961.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00004.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 165,  949,  371, 1047],
       [   0,  628,  111,  714],
       [ 559,  588,  650,  668],
       [ 363,  470,  436,  520],
       [ 534,  466,  625,  539],
       [ 455,  389,  521,  451],
       [ 555,  413,  636,  468],
       [1432,  851, 1686, 1045],
       [1215,  582, 1317,  666],
       [1419,  534, 1509,  601],
       [1194,  443, 1273,  509],
       [1228,  403, 1300,  459],
       [ 809,  405,  850,  443],
       [ 730,  389,  777,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([20493.,  9744.,  7452.,  3774.,  6808.,  4221.,  4592., 49725.,
        8755.,  6188.,  5360.,  4161.,  1638.,  2304.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00005.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 169,  968,  384, 1045],
       [ 382,  563,  515,  661],
       [ 425,  484,  523,  555],
       [ 194,  553,  288,  611],
       [ 373,  428,  444,  507],
       [ 684,  451,  744,  522],
       [ 773,  493,  834,  543],
       [1175,  559, 1298,  649],
       [1494,  707, 1646,  807],
       [1109,  459, 1171,  514],
       [1265,  439, 1325,  480],
       [1113,  380, 1167,  430],
       [ 727,  407,  771,  443],
       [ 815,  384,  855,  418],
       [ 577,  382,  621,  422],
       [ 517,  376,  559,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([16848., 13266.,  7128.,  5605.,  5760.,  4392.,  3162., 11284.,
       15453.,  3528.,  2562.,  2805.,  1665.,  1435.,  1845.,  1634.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00006.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  11,  780,  267,  970],
       [ 128,  626,  294,  755],
       [   0,  695,   23,  786],
       [ 219,  480,  334,  576],
       [ 559,  582,  667,  691],
       [ 678,  672,  794,  774],
       [ 671,  478,  728,  530],
       [ 794,  443,  846,  501],
       [ 505,  432,  559,  482],
       [1461,  695, 1600,  789],
       [1261,  509, 1340,  566],
       [1086,  445, 1157,  505],
       [1046,  395, 1092,  434],
       [1173,  382, 1223,  414],
       [ 471,  399,  519,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([49087., 21710.,  2208., 11252., 11990., 12051.,  3074.,  3127.,
        2805., 13300.,  4640.,  4392.,  1880.,  1683.,  2107.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00007.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 532,  626,  636,  714],
       [ 738,  564,  830,  653],
       [   0,  564,  144,  703],
       [ 175,  978,  377, 1051],
       [ 375,  491,  453,  566],
       [ 400,  436,  459,  484],
       [ 507,  436,  557,  474],
       [ 482,  407,  528,  441],
       [ 719,  397,  775,  438],
       [ 805,  372,  859,  424],
       [1250,  503, 1330,  557],
       [1150,  422, 1205,  464],
       [1034,  388, 1080,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9345.,  8370., 20300., 15022.,  6004.,  2940.,  1989.,  1645.,
        2394.,  2915.,  4455.,  2408.,  2115.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00008.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 561,  943,  748, 1049],
       [ 117,  626,  246,  739],
       [ 288,  489,  367,  549],
       [ 398,  505,  469,  555],
       [ 663,  457,  732,  524],
       [ 788,  436,  853,  511],
       [ 415,  443,  469,  480],
       [1848,  993, 1919, 1047],
       [1461,  664, 1609,  770],
       [1152,  420, 1200,  455],
       [ 467,  407,  519,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20116., 14820.,  4880.,  3672.,  4760.,  5016.,  2090.,  3960.,
       15943.,  1764.,  2173.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00009.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 178,  616,  298,  701],
       [ 109,  561,  223,  653],
       [ 544,  582,  650,  680],
       [ 713,  555,  827,  678],
       [ 302,  497,  377,  545],
       [ 398,  447,  448,  488],
       [1332,  726, 1528,  876],
       [1711,  630, 1919,  860],
       [1415,  618, 1534,  695],
       [1267,  507, 1346,  570],
       [ 503,  401,  550,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10406., 10695., 10593., 14260.,  3724.,  2142., 29747., 48279.,
        9360.,  5120.,  1632.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00010.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 142,  974,  352, 1045],
       [ 457,  949,  711, 1043],
       [ 121,  582,  228,  647],
       [ 275,  509,  353,  566],
       [ 425,  438,  486,  480],
       [1261,  663, 1382,  757],
       [1442,  480, 1742,  713],
       [1146,  511, 1246,  595],
       [1263,  474, 1330,  524],
       [1157,  426, 1219,  472]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15192., 24225.,  7128.,  4582.,  2666., 11590., 70434.,  8585.,
        3468.,  2961.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00011.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  71,  595,  190,  672],
       [ 311,  503,  388,  559],
       [1048,  605, 1138,  678],
       [1592,  782, 1780,  905],
       [1713,  707, 1877,  799],
       [1303,  411, 1486,  559],
       [1119,  499, 1190,  559],
       [1069,  424, 1134,  472],
       [ 542,  409,  590,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9360.,  4446.,  6734., 23436., 15345., 27416.,  4392.,  3234.,
        2009.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00012.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 107,  616,  225,  701],
       [ 557,  491,  621,  534],
       [ 457,  468,  525,  520],
       [ 423,  426,  478,  472],
       [ 709,  405,  763,  453],
       [1090,  697, 1217,  816],
       [1338,  761, 1552,  939],
       [1598,  799, 1809,  949],
       [1630,  639, 1784,  739],
       [1448,  538, 1540,  603],
       [1307,  553, 1405,  618],
       [ 990,  461, 1040,  505],
       [1225,  374, 1340,  472],
       [1050,  420, 1100,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([10234.,  2860.,  3657.,  2632.,  2695., 15360., 38485., 32012.,
       15655.,  6138.,  6534.,  2295., 11484.,  1734.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00013.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 365,  641,  469,  711],
       [ 288,  557,  388,  641],
       [ 311,  474,  388,  538],
       [ 659,  472,  730,  539],
       [ 413,  430,  467,  468],
       [ 798,  422,  848,  468],
       [1005,  505, 1078,  574],
       [1153,  538, 1250,  622],
       [1313,  563, 1417,  645],
       [1402,  495, 1488,  566],
       [1309,  451, 1369,  499],
       [1186,  455, 1250,  488],
       [1153,  341, 1248,  418],
       [ 957,  393,  996,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([7455., 8585., 5070., 4896., 2145., 2397., 5180., 8330., 8715.,
       6264., 2989., 2210., 7488., 1440.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00014.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  747,   92,  901],
       [ 111,  568,  225,  653],
       [ 536,  595,  642,  716],
       [ 752,  511,  827,  586],
       [ 296,  488,  371,  545],
       [ 394,  434,  463,  484],
       [1453,  653, 1588,  757],
       [1767,  739, 1919,  836],
       [1194,  457, 1259,  514],
       [1277,  424, 1346,  470],
       [1077,  438, 1142,  499],
       [ 967,  422, 1019,  463],
       [ 702,  432,  752,  470],
       [ 803,  409,  859,  457],
       [ 618,  399,  668,  457],
       [ 511,  403,  545,  441],
       [1221,  401, 1271,  436],
       [1115,  391, 1159,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([14105.,  9890., 13054.,  5776.,  4408.,  3570., 14280., 14994.,
        3828.,  3290.,  4092.,  2226.,  1989.,  2793.,  3009.,  1365.,
        1836.,  1800.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00015.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 157,  970,  378, 1047],
       [ 607,  732,  763,  874],
       [  77,  586,  188,  666],
       [ 265,  491,  357,  566],
       [ 450,  451,  509,  493],
       [ 550,  461,  615,  524],
       [ 619,  520,  696,  580],
       [ 771,  493,  840,  564],
       [1263,  497, 1340,  566],
       [1446,  545, 1536,  601],
       [ 707,  420,  750,  457],
       [1124,  393, 1174,  445],
       [1025,  382, 1077,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17316., 22451.,  9072.,  7068.,  2580.,  4224.,  4758.,  5040.,
        5460.,  5187.,  1672.,  2703.,  2173.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00016.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  27,  588,  167,  689],
       [ 398,  720,  540,  836],
       [ 665,  666,  790,  795],
       [ 400,  559,  498,  653],
       [ 332,  526,  403,  586],
       [ 638,  497,  702,  549],
       [ 811,  472,  869,  522],
       [ 482,  455,  548,  493],
       [1655,  672, 1817,  772],
       [1294,  451, 1357,  488],
       [1159,  426, 1221,  472],
       [ 536,  405,  584,  447],
       [ 719,  401,  763,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14382., 16731., 16380.,  9405.,  4392.,  3445.,  3009.,  2613.,
       16463.,  2432.,  2961.,  2107.,  1935.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00017.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  792,  208,  982],
       [  61,  678,  190,  778],
       [ 477,  655,  584,  753],
       [ 748,  622,  840,  711],
       [ 342,  534,  425,  597],
       [ 411,  461,  471,  509],
       [ 665,  464,  730,  522],
       [ 550,  411,  598,  449],
       [ 494,  386,  544,  430],
       [1219,  618, 1350,  728],
       [1423,  659, 1548,  738],
       [1394,  514, 1480,  580],
       [1202,  391, 1255,  430],
       [1096,  378, 1148,  416],
       [ 652,  388,  700,  424]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([39919., 13130., 10692.,  8370.,  5376.,  2989.,  3894.,  1911.,
        2295., 14652., 10080.,  5829.,  2160.,  2067.,  1813.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00018.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1275,  707, 1402,  809],
       [1516,  699, 1656,  809],
       [1844,  972, 1919, 1044],
       [1642,  618, 1823,  766],
       [1244,  507, 1321,  564],
       [1103,  474, 1186,  541],
       [1261,  434, 1327,  478],
       [  50,  688,  198,  795],
       [ 534,  582,  646,  680],
       [ 186,  551,  282,  624],
       [ 457,  461,  525,  511],
       [ 605,  434,  663,  474],
       [ 713,  426,  761,  457],
       [ 411,  422,  478,  478],
       [ 567,  349,  628,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([13184., 15651.,  5548., 27118.,  4524.,  5712.,  3015., 16092.,
       11187.,  7178.,  3519.,  2419.,  1568.,  3876.,  4464.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00019.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 148,  928,  377, 1043],
       [ 300,  545,  394,  614],
       [ 269,  493,  361,  559],
       [ 523,  505,  598,  555],
       [ 650,  509,  715,  557],
       [ 507,  372,  590,  474],
       [ 703,  420,  753,  464],
       [1184,  845, 1346,  988],
       [1317,  741, 1477,  880],
       [1405,  591, 1542,  720],
       [1661,  689, 1796,  768],
       [1390,  482, 1496,  576],
       [1296,  530, 1380,  595],
       [1130,  516, 1202,  570],
       [1053,  409, 1109,  451],
       [1148,  430, 1207,  472],
       [1177,  382, 1228,  424]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([26680.,  6650.,  6231.,  3876.,  3234.,  8652.,  2295., 23472.,
       22540., 17940., 10880., 10165.,  5610.,  4015.,  2451.,  2580.,
        2236.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00020.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1128,  864, 1288, 1014],
       [1621,  759, 1869,  957],
       [1144,  524, 1228,  597],
       [1027,  513, 1098,  568],
       [1411,  526, 1488,  578],
       [1236,  478, 1323,  549],
       [1261,  418, 1336,  478],
       [1190,  443, 1250,  489],
       [1067,  430, 1117,  470],
       [   0,  709,  136,  826],
       [  17,  588,  155,  705],
       [ 340,  632,  459,  724],
       [ 488,  659,  609,  759],
       [ 632,  499,  702,  568],
       [ 394,  422,  511,  541]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([24311., 49551.,  6290.,  4032.,  4134.,  6336.,  4636.,  2867.,
        2091., 16166., 16402., 11160., 12322.,  4970., 14160.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00021.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1540,  939, 1763, 1041],
       [1788,  738, 1919,  856],
       [1328,  547, 1455,  651],
       [1019,  572, 1102,  647],
       [   2,  978,   82, 1045],
       [ 450,  668,  578,  793],
       [ 182,  501,  373,  674],
       [ 436,  426,  488,  461],
       [ 552,  403,  600,  445],
       [ 625,  332,  705,  447],
       [ 723,  384,  767,  418],
       [1069,  430, 1125,  482],
       [1153,  414, 1211,  466],
       [1277,  441, 1338,  482],
       [ 977,  405, 1015,  441],
       [1188,  372, 1240,  422],
       [ 821,  384,  861,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([23072., 15708., 13440.,  6384.,  5508., 16254., 33408.,  1908.,
        2107.,  9396.,  1575.,  3021.,  3127.,  2604.,  1443.,  2703.,
        1230.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00022.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  653,   61,  886],
       [ 288,  497,  369,  545],
       [ 473,  447,  538,  505],
       [ 555,  361,  675,  518],
       [ 686,  443,  740,  491],
       [ 805,  439,  859,  480],
       [1221,  595, 1317,  676],
       [1463,  539, 1553,  609],
       [1205,  449, 1282,  518],
       [ 982,  455, 1034,  505]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14040.,  4018.,  3894., 19118.,  2695.,  2310.,  7954.,  6461.,
        5460.,  2703.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00023.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  630,  117,  713],
       [ 415,  409,  617,  641],
       [ 344,  513,  430,  601],
       [ 588,  549,  675,  634],
       [ 757,  534,  834,  601],
       [1502,  628, 1650,  728],
       [1105,  476, 1167,  518],
       [1305,  447, 1369,  497],
       [1136,  397, 1194,  447],
       [ 725,  403,  777,  445],
       [ 953,  395,  996,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9744., 47299.,  7743.,  7568.,  5304., 15049.,  2709.,  3315.,
        3009.,  2279.,  1584.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00024.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 280,  816,  475, 1007],
       [ 642,  772,  777,  911],
       [ 107,  486,  486,  893],
       [ 669,  480,  734,  538],
       [1453,  678, 1600,  766],
       [1840,  784, 1919,  895],
       [1265,  482, 1350,  547]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 37632.,  19040., 155040.,   3894.,  13172.,   8960.,   5676.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00025.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  674,  178, 1043],
       [ 523,  624,  632,  720],
       [1405,  638, 1528,  713],
       [1453,  547, 1555,  613],
       [1267,  522, 1346,  576],
       [ 792,  432,  838,  478],
       [ 621,  416,  675,  457],
       [ 434,  403,  496,  461],
       [1152,  414, 1211,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([65490., 10670.,  9424.,  6901.,  4400.,  2209.,  2310.,  3717.,
        2520.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00026.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1357,  793, 1515,  924],
       [1528,  695, 1694,  816],
       [1244,  499, 1317,  549],
       [1292,  444, 1352,  485],
       [1173,  438, 1227,  486],
       [ 746,  524,  819,  580],
       [ 542,  478,  607,  539],
       [ 302,  464,  394,  538],
       [ 802,  438,  852,  480],
       [ 713,  395,  759,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20988., 20374.,  3774.,  2562.,  2695.,  4218.,  4092.,  6975.,
        2193.,  1974.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00027.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1388,  828, 1571,  957],
       [1542,  591, 1663,  682],
       [1146,  541, 1227,  607],
       [1315,  509, 1403,  576],
       [ 636,  720,  763,  838],
       [ 363,  597,  473,  688],
       [  55,  561,  192,  678],
       [ 757,  532,  838,  593],
       [ 659,  459,  721,  513],
       [1159,  422, 1213,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([23920., 11224.,  5494.,  6052., 15232., 10212., 16284.,  5084.,
        3465.,  2365.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00028.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  897,  119, 1047],
       [ 646,  747,  782,  880],
       [ 538,  578,  642,  672],
       [1746,  743, 1919,  845],
       [1167,  553, 1252,  618],
       [1352,  476, 1425,  532],
       [1065,  439, 1119,  480],
       [1219,  422, 1277,  466],
       [ 790,  468,  846,  511],
       [ 503,  422,  569,  476],
       [ 627,  420,  677,  461]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17667., 18358.,  9975., 17922.,  5676.,  4218.,  2310.,  2655.,
        2508.,  3685.,  2142.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00029.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1476,  936, 1679, 1045],
       [1452,  555, 1546,  614],
       [1084,  443, 1136,  489],
       [1244,  411, 1302,  453],
       [ 161,  932,  388, 1039],
       [ 727,  591,  817,  670],
       [ 527,  509,  602,  563],
       [ 392,  489,  480,  551],
       [ 786,  459,  840,  505],
       [ 690,  445,  750,  493],
       [ 434,  434,  486,  476],
       [ 628,  422,  673,  466],
       [ 728,  399,  778,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22440.,  5700.,  2491.,  2537., 24624.,  7280.,  4180.,  5607.,
        2585.,  2989.,  2279.,  2070.,  2397.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00030.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 542,  964,  723, 1045],
       [1828,  999, 1919, 1047],
       [1292,  722, 1423,  811],
       [1580,  634, 1719,  724],
       [1186,  580, 1275,  651],
       [1303,  461, 1371,  503],
       [ 255,  688,  400,  799],
       [ 173,  591,  311,  701],
       [ 563,  566,  665,  655],
       [ 730,  578,  815,  651],
       [ 323,  497,  402,  563],
       [ 521,  513,  598,  568],
       [ 663,  474,  742,  539],
       [ 453,  414,  502,  449],
       [ 802,  426,  853,  470],
       [ 580,  374,  623,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([14924.,  4508., 11880., 12740.,  6480.,  2967., 16352., 15429.,
        9270.,  6364.,  5360.,  4368.,  5280.,  1800.,  2340.,  2156.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00031.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 559,  911,  727, 1041],
       [ 159,  955,  371, 1039],
       [ 273,  684,  407,  788],
       [ 505,  622,  632,  739],
       [  88,  614,  221,  711],
       [ 317,  476,  390,  534],
       [ 761,  514,  834,  591],
       [1390,  626, 1521,  713],
       [1561,  607, 1675,  680],
       [1369,  501, 1453,  557],
       [1136,  526, 1202,  570],
       [1094,  459, 1148,  501],
       [ 784,  468,  838,  516],
       [ 513,  413,  573,  470],
       [ 700,  422,  750,  466],
       [1221,  407, 1269,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([22139., 18105., 14175., 15104., 13132.,  4366.,  5772., 11616.,
        8510.,  4845.,  3015.,  2365.,  2695.,  3538.,  2295.,  1813.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00032.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 628,  743,  780,  909],
       [  11,  616,  134,  701],
       [ 702,  599,  796,  674],
       [ 403,  468,  490,  549],
       [ 621,  503,  692,  566],
       [1400,  691, 1536,  778],
       [1734,  745, 1919,  848],
       [1227,  486, 1309,  547],
       [1355,  478, 1434,  534],
       [ 517,  441,  573,  482],
       [1261,  432, 1321,  474],
       [1061,  432, 1109,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([25551., 10664.,  7220.,  7216.,  4608., 12056., 19344.,  5146.,
        4560.,  2394.,  2623.,  1813.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00033.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 477,  995,  646, 1047],
       [1432,  551, 1530,  611],
       [1886,  822, 1919,  889],
       [ 428,  688,  555,  797],
       [ 200,  564,  336,  689],
       [ 400,  509,  482,  568],
       [ 653,  486,  717,  553],
       [ 555,  480,  619,  526],
       [ 357,  466,  421,  511],
       [1175,  503, 1246,  553],
       [1144,  413, 1209,  463],
       [1250,  414, 1302,  457],
       [ 709,  414,  765,  451],
       [ 544,  405,  592,  438],
       [ 811,  393,  848,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 9010.,  6039.,  2312., 14080., 17262.,  4980.,  4420.,  3055.,
        2990.,  3672.,  3366.,  2332.,  2166.,  1666.,  1520.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00034.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 507,  636,  613,  745],
       [ 394,  595,  490,  676],
       [ 159,  632,  288,  720],
       [ 121,  568,  223,  639],
       [ 649,  497,  717,  549],
       [ 457,  461,  525,  505],
       [ 782,  459,  838,  514],
       [ 617,  420,  667,  461],
       [1227,  622, 1342,  713],
       [1494,  568, 1594,  628],
       [1286,  457, 1353,  501],
       [1073,  413, 1123,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11770.,  7954., 11570.,  7416.,  3657.,  3105.,  3192.,  2142.,
       10672.,  6161.,  3060.,  2091.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00035.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1209,  622, 1307,  695],
       [1827,  857, 1919, 1022],
       [   0,  899,  157, 1045],
       [ 496,  657,  619,  745],
       [ 719,  599,  817,  695],
       [ 292,  549,  384,  618],
       [ 530,  493,  609,  549],
       [ 791,  441,  847,  489],
       [ 502,  439,  561,  478],
       [1105,  476, 1173,  532],
       [1321,  459, 1386,  507],
       [1198,  403, 1252,  434],
       [ 732,  368,  769,  401],
       [ 503,  349,  571,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 7326., 15438., 23226., 11036.,  9603.,  6510.,  4560.,  2793.,
        2400.,  3933.,  3234.,  1760.,  1292.,  4554.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00036.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  747,   94,  870],
       [ 346,  624,  467,  716],
       [ 742,  557,  823,  632],
       [ 367,  516,  448,  574],
       [1452,  576, 1571,  661],
       [1094,  480, 1161,  530],
       [ 427,  378,  511,  459],
       [ 580,  388,  621,  420],
       [ 702,  405,  759,  453],
       [1044,  405, 1092,  449],
       [1227,  401, 1273,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11780., 11346.,  6232.,  4838., 10320.,  3468.,  6970.,  1386.,
        2842.,  2205.,  1833.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00037.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  974,   69, 1043],
       [ 563,  876,  738, 1043],
       [  69,  668,  217,  768],
       [ 313,  413,  428,  526],
       [ 646,  478,  719,  539],
       [1315,  738, 1455,  845],
       [1702,  720, 1873,  816],
       [1302,  459, 1378,  516],
       [ 784,  447,  834,  493],
       [ 615,  428,  661,  470],
       [ 517,  432,  573,  470],
       [1040,  405, 1086,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4900., 29568., 15049., 13224.,  4588., 15228., 16684.,  4466.,
        2397.,  2021.,  2223.,  1833.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00038.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1100,  738, 1227,  847],
       [1802,  770, 1919,  883],
       [ 103,  493,  275,  636],
       [ 398,  497,  477,  555],
       [ 494,  518,  567,  591],
       [ 730,  563,  811,  643],
       [ 515,  599,  627,  713],
       [ 696,  447,  753,  488],
       [ 471,  407,  517,  447],
       [1152,  530, 1228,  589],
       [1411,  532, 1502,  591],
       [1209,  403, 1267,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14080., 13452., 24912.,  4720.,  5476.,  6642., 12995.,  2436.,
        1927.,  4620.,  5520.,  2537.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00039.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 128,  970,  336, 1043],
       [ 553,  895,  723, 1045],
       [ 177,  718,  327,  861],
       [ 177,  624,  296,  707],
       [ 605,  547,  688,  611],
       [ 359,  464,  428,  516],
       [1086,  699, 1213,  797],
       [1811,  789, 1919,  898],
       [1459,  561, 1565,  628],
       [1005,  509, 1077,  563],
       [1273,  443, 1330,  484],
       [1073,  441, 1127,  482],
       [ 725,  416,  769,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15466., 25821., 21744., 10080.,  5460.,  3710., 12672., 11990.,
        7276.,  4015.,  2436.,  2310.,  1530.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00040.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 365,  795,  515,  930],
       [ 155,  559,  261,  630],
       [ 667,  486,  732,  543],
       [ 523,  391,  571,  434],
       [ 642,  357,  700,  430],
       [ 727,  407,  773,  439],
       [ 809,  384,  848,  413],
       [1692,  701, 1850,  791],
       [1455,  555, 1550,  614],
       [1007,  495, 1073,  543],
       [1305,  463, 1373,  509],
       [1182,  393, 1232,  424],
       [ 969,  416, 1015,  451],
       [1030,  384, 1069,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([20536.,  7704.,  3828.,  2156.,  4366.,  1551.,  1200., 14469.,
        5760.,  3283.,  3243.,  1632.,  1692.,  1480.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00041.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 515,  634,  627,  724],
       [ 452,  443,  515,  499],
       [ 671,  480,  736,  528],
       [ 582,  397,  665,  488],
       [ 792,  449,  848,  488],
       [ 725,  393,  775,  436],
       [1359,  699, 1503,  824],
       [1411,  526, 1496,  578],
       [1300,  453, 1361,  499],
       [1215,  399, 1257,  432],
       [ 971,  409, 1017,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10283.,  3648.,  3234.,  7728.,  2280.,  2244., 18270.,  4558.,
        2914.,  1462.,  1739.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00042.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1486,  926, 1703, 1043],
       [1119,  751, 1253,  857],
       [1430,  653, 1552,  738],
       [1203,  511, 1280,  572],
       [1278,  438, 1338,  480],
       [ 742,  566,  827,  638],
       [ 538,  605,  632,  686],
       [ 319,  514,  413,  591],
       [ 469,  461,  588,  591],
       [ 680,  445,  748,  503],
       [ 807,  414,  861,  468],
       [ 632,  401,  682,  438],
       [ 557,  399,  607,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([25724., 14445., 10578.,  4836.,  2623.,  6278.,  7790.,  7410.,
       15720.,  4071.,  3025.,  1938.,  2091.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00043.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1548,  693, 1702,  801],
       [1248,  984, 1442, 1043],
       [1586,  605, 1717,  678],
       [1178,  564, 1277,  641],
       [1253,  503, 1332,  564],
       [1021,  513, 1092,  568],
       [ 540,  951,  734, 1047],
       [ 102, 1001,  290, 1041],
       [   9,  664,  177,  799],
       [ 202,  593,  403,  814],
       [ 588,  547,  680,  628],
       [ 761,  522,  840,  603],
       [ 563,  459,  628,  511],
       [ 477,  449,  544,  499],
       [ 798,  443,  855,  501],
       [1132,  416, 1180,  463],
       [ 471,  405,  523,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([16895., 11700.,  9768.,  7800.,  4960.,  4032., 18915.,  7749.,
       22984., 44844.,  7626.,  6560.,  3498.,  3468.,  3422.,  2352.,
        2279.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00044.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1552,  982, 1811, 1047],
       [1748,  716, 1919,  862],
       [1444,  668, 1575,  757],
       [1146,  757, 1288,  886],
       [1050,  570, 1138,  641],
       [1361,  528, 1444,  593],
       [1373,  478, 1446,  526],
       [1084,  443, 1138,  495],
       [1171,  428, 1225,  468],
       [ 980,  418, 1028,  457],
       [ 598,  801,  765,  982],
       [ 330,  779,  515,  954],
       [ 736,  572,  828,  676],
       [ 403,  570,  502,  643],
       [ 321,  545,  409,  605],
       [ 348,  470,  409,  514],
       [ 534,  428,  584,  476],
       [ 707,  395,  767,  441],
       [ 813,  391,  861,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17160., 25284., 11880., 18590.,  6408.,  5544.,  3626.,  2915.,
        2255.,  1960., 30576., 32736.,  9765.,  7400.,  5429.,  2790.,
        2499.,  2867.,  2499.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00045.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  847,  148, 1032],
       [   0,  730,  117,  839],
       [ 102,  580,  217,  659],
       [ 415,  497,  492,  561],
       [ 652,  466,  727,  539],
       [ 786,  463,  855,  530],
       [ 488,  438,  550,  497],
       [ 434,  422,  490,  466],
       [1646,  839, 1842,  959],
       [1053,  626, 1152,  703],
       [1201,  576, 1313,  668],
       [1423,  522, 1553,  611],
       [1253,  514, 1332,  563],
       [1030,  516, 1100,  578],
       [1261,  439, 1323,  497],
       [ 994,  447, 1050,  491]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([27714., 12980.,  9280.,  5070.,  5624.,  4760.,  3780.,  2565.,
       23837.,  7800., 10509., 11790.,  4000.,  4473.,  3717.,  2565.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00046.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1459,  895, 1740, 1041],
       [1530,  588, 1675,  678],
       [1315,  563, 1402,  616],
       [1280,  436, 1365,  491],
       [1161,  430, 1217,  472],
       [1090,  449, 1157,  503],
       [ 992,  466, 1044,  513],
       [ 977,  418, 1023,  457],
       [1200,  393, 1242,  428],
       [ 703,  622,  811,  732],
       [ 502,  599,  630,  709],
       [ 173,  620,  292,  716],
       [ 346,  513,  442,  586],
       [ 302,  493,  382,  547],
       [ 496,  447,  553,  493],
       [ 696,  428,  740,  468],
       [ 463,  416,  511,  451]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([41454., 13286.,  4752.,  4816.,  2451.,  3740.,  2544.,  1880.,
        1548., 12099., 14319., 11640.,  7178.,  4455.,  2726.,  1845.,
        1764.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00047.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 115, 1026,  309, 1047],
       [  69,  647,  221,  772],
       [  25,  609,  152,  697],
       [1778,  911, 1919, 1048],
       [1428,  636, 1561,  728],
       [1175,  561, 1290,  657],
       [1330,  466, 1425,  532],
       [1180,  447, 1238,  489],
       [1194,  378, 1257,  426],
       [ 615,  516,  682,  570],
       [ 353,  524,  440,  584],
       [ 359,  463,  425,  507],
       [ 600,  436,  648,  480],
       [ 798,  407,  834,  447],
       [ 467,  403,  517,  439],
       [1032,  388, 1080,  430],
       [ 955,  393,  992,  428],
       [ 573,  399,  609,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4290., 19278., 11392., 19596., 12462., 11252.,  6432.,  2537.,
        3136.,  3740.,  5368.,  3015.,  2205.,  1517.,  1887.,  2107.,
        1368.,  1665.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00048.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 394,  716,  530,  826],
       [  69,  668,  213,  766],
       [ 178,  551,  275,  609],
       [ 490,  522,  561,  574],
       [ 767,  497,  825,  551],
       [ 488,  453,  546,  491],
       [ 377,  453,  436,  488],
       [1182,  618, 1284,  689],
       [1390,  601, 1505,  691],
       [1844,  772, 1919,  890],
       [1259,  499, 1338,  559],
       [1078,  445, 1153,  503],
       [1227,  405, 1288,  449],
       [ 613,  418,  669,  459]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([15207., 14355.,  5782.,  3816.,  3245.,  2301.,  2160.,  7416.,
       10556.,  9044.,  4880.,  4484.,  2790.,  2394.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00049.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1677,  857, 1919, 1022],
       [ 657,  680,  763,  784],
       [ 234,  693,  371,  793],
       [ 225,  528,  313,  588],
       [ 340,  538,  425,  597],
       [ 452,  470,  525,  516],
       [ 523,  493,  598,  553],
       [ 673,  489,  738,  541],
       [1478,  547, 1584,  620],
       [1238,  482, 1311,  539],
       [1080,  474, 1142,  526],
       [1173,  426, 1227,  484],
       [ 790,  430,  844,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([40338., 11235., 13938.,  5429.,  5160.,  3478.,  4636.,  3498.,
        7918.,  4292.,  3339.,  3245.,  2145.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00050.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 509,  659,  621,  753],
       [ 328,  624,  444,  716],
       [ 275,  568,  371,  641],
       [  28,  703,  180,  803],
       [1736,  724, 1917,  828],
       [1348,  582, 1450,  668],
       [ 753,  523,  826,  591],
       [ 646,  488,  717,  547],
       [ 790,  430,  844,  472],
       [1309,  449, 1378,  501],
       [1150,  413, 1209,  463],
       [1027,  401, 1075,  436],
       [ 550,  405,  596,  445],
       [1105,  384, 1153,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([10735., 10881.,  7178., 15453., 19110.,  8961.,  5106.,  4320.,
        2365.,  3710.,  3060.,  1764.,  1927.,  2107.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00051.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  786,   48,  889],
       [ 634,  747,  767,  870],
       [ 484,  659,  600,  755],
       [ 736,  524,  817,  582],
       [ 463,  453,  525,  501],
       [ 553,  405,  602,  447],
       [ 621,  411,  675,  459],
       [ 709,  411,  757,  449],
       [1850,  997, 1919, 1048],
       [1432,  534, 1525,  593],
       [1209,  470, 1278,  524],
       [1211,  393, 1263,  434],
       [1096,  374, 1144,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 5096., 16616., 11349.,  4838.,  3087.,  2150.,  2695.,  1911.,
        3640.,  5640.,  3850.,  2226.,  1666.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00052.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1796,  766, 1919,  902],
       [1382,  616, 1505,  699],
       [ 600,  749,  748,  878],
       [ 311,  545,  390,  611],
       [ 540,  478,  607,  545],
       [ 652,  480,  719,  528],
       [1286,  438, 1344,  482],
       [1136,  411, 1186,  451],
       [ 480,  457,  540,  499]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16988., 10416., 19370.,  5360.,  4624.,  3332.,  2655.,  2091.,
        2623.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00053.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  709,  136,  843],
       [ 346,  614,  473,  713],
       [ 527,  624,  632,  716],
       [ 327,  539,  423,  611],
       [ 436,  413,  488,  463],
       [ 548,  405,  602,  459],
       [1436,  663, 1559,  751],
       [1444,  541, 1552,  618],
       [1223,  484, 1298,  539],
       [1196,  388, 1248,  422],
       [ 794,  413,  842,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18225., 12800.,  9858.,  7081.,  2703.,  3025., 11036.,  8502.,
        4256.,  1855.,  1715.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00054.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  714,  163,  839],
       [ 315,  472,  384,  532],
       [ 442,  468,  521,  538],
       [ 767,  497,  828,  553],
       [ 600,  445,  659,  486],
       [1434,  636, 1605,  772],
       [1546,  595, 1663,  682],
       [1269,  505, 1346,  564],
       [1284,  445, 1357,  507],
       [1138,  416, 1194,  451],
       [ 557,  405,  611,  447],
       [ 469,  414,  519,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20412.,  4270.,  5680.,  3534.,  2520., 23564., 10384.,  4680.,
        4662.,  2052.,  2365.,  2142.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00055.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 665,  676,  777,  778],
       [ 244,  572,  361,  668],
       [  90,  570,  202,  657],
       [ 478,  541,  565,  599],
       [1382,  841, 1557,  966],
       [1427,  653, 1548,  741],
       [1261,  484, 1363,  576],
       [1346,  474, 1419,  524],
       [ 342,  474,  417,  522],
       [ 484,  455,  538,  507],
       [ 784,  451,  825,  489],
       [1196,  422, 1248,  468],
       [ 634,  409,  682,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11639., 11446.,  9944.,  5192., 22176., 10858.,  9579.,  3774.,
        3724.,  2915.,  1638.,  2491.,  1715.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00056.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 203,  722,  353,  836],
       [ 103,  586,  211,  657],
       [ 328,  541,  417,  618],
       [ 727,  557,  802,  622],
       [ 569,  472,  632,  509],
       [ 673,  461,  734,  511],
       [ 796,  468,  861,  514],
       [1153,  564, 1252,  624],
       [1261,  513, 1330,  561],
       [1186,  418, 1252,  480],
       [ 477,  413,  525,  449],
       [ 628,  416,  673,  457],
       [1250,  407, 1296,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17365.,  7848.,  7020.,  5016.,  2432.,  3162.,  3102.,  6100.,
        3430.,  4221.,  1813.,  1932.,  2209.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00057.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 546,  838,  698,  978],
       [   2,  711,  142,  863],
       [ 503,  630,  617,  732],
       [ 728,  607,  819,  691],
       [ 438,  572,  534,  632],
       [ 342,  476,  405,  528],
       [ 552,  480,  615,  532],
       [ 719,  426,  767,  472],
       [1075,  447, 1125,  501],
       [1169,  434, 1227,  478],
       [1075,  691, 1188,  784],
       [1292,  732, 1434,  834],
       [1540,  741, 1709,  878],
       [1527,  605, 1642,  688]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([21573., 21573., 11845.,  7820.,  5917.,  3392.,  3392.,  2303.,
        2805.,  2655., 10716., 14729., 23460.,  9744.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00058.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 123,  789,  292,  916],
       [1109,  730, 1278,  905],
       [1552,  784, 1728,  889],
       [1573,  603, 1723,  714],
       [1292,  539, 1382,  611],
       [1342,  484, 1409,  538],
       [1128,  522, 1209,  578],
       [1000,  507, 1071,  561],
       [  77,  599,  188,  678],
       [ 395,  580,  488,  657],
       [ 650,  513,  719,  572],
       [ 486,  426,  559,  484],
       [ 613,  466,  678,  516],
       [ 613,  426,  678,  466]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([21760., 29920., 18762., 16912.,  6643.,  3740.,  4674.,  3960.,
        8960.,  7332.,  4200.,  4366.,  3366.,  2706.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00059.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1409,  861, 1625, 1032],
       [1767,  930, 1919, 1047],
       [1292,  543, 1371,  611],
       [1375,  489, 1465,  555],
       [1007,  514, 1094,  572],
       [1182,  441, 1236,  497],
       [1063,  428, 1113,  468],
       [ 973,  420, 1017,  461],
       [1236,  414, 1292,  457],
       [ 475,  695,  588,  795],
       [   9,  824,  196,  961],
       [ 417,  593,  517,  678],
       [ 355,  501,  453,  570],
       [ 365,  451,  423,  491],
       [ 511,  516,  584,  570],
       [ 688,  451,  746,  491],
       [ 630,  413,  678,  451]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([37324., 18054.,  5520.,  6097.,  5192.,  3135.,  2091.,  1890.,
        2508., 11514., 25944.,  8686.,  6930.,  2419.,  4070.,  2419.,
        1911.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00060.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1413,  884, 1602, 1024],
       [1753,  905, 1915, 1047],
       [1590,  624, 1723,  718],
       [1380,  601, 1490,  674],
       [1177,  568, 1275,  655],
       [   2,  943,  115, 1041],
       [ 263,  684,  405,  780],
       [  90,  626,  267,  738],
       [ 146,  549,  252,  614],
       [ 571,  574,  667,  643],
       [ 550,  478,  607,  530],
       [ 696,  443,  746,  478],
       [1171,  449, 1225,  489],
       [ 973,  416, 1025,  472],
       [1263,  420, 1327,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([26790., 23309., 12730.,  8214.,  8712., 11286., 13871., 20114.,
        7062.,  6790.,  3074.,  1836.,  2255.,  3021.,  3185.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}]
/home/ad/tensorflow-r1.6/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Loading initial model weights from data/imagenet_weights/res101.ckpt
resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma
resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/logits/biases
resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights
resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean
resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights
resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights
resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/beta
resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance
resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights
resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean
resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights
resnet_v1_101/logits/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights
resnet_v1_101/conv1/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights
resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/beta
resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma
resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights
resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights
resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights
resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance
resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/mean_rgb
resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights
resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma
resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights
resnet_v1_101/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights
resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/beta
resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights
resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights
resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights
resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/beta
resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights
resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/conv1/BatchNorm/moving_mean
resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights
resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights
resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights
resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights
resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights
resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights
resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights
resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/beta
global_step
resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance
resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights
resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance
resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_mean
Variables restored: resnet_v1_101/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Loaded.
Fix Resnet V1 layers..
Fixed.
0
go shuffle
0 1
[]
[]
0
Traceback (most recent call last):
  File "./tools/trainval_net.py", line 142, in <module>
    max_iters=args.max_iters)
  File "/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tools/../lib/model/train_val.py", line 381, in train_net
    sw.train_model(sess, max_iters)
  File "/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tools/../lib/model/train_val.py", line 282, in train_model
    blobs = self.data_layer.forward()
  File "/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tools/../lib/roi_data_layer/layer.py", line 91, in forward
    blobs = self._get_next_minibatch()
  File "/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tools/../lib/roi_data_layer/layer.py", line 87, in _get_next_minibatch
    return get_minibatch(minibatch_db, self._num_classes)
  File "/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tools/../lib/roi_data_layer/minibatch.py", line 26, in get_minibatch
    assert(cfg.TRAIN.BATCH_SIZE % num_images == 0), \
ZeroDivisionError: integer division or modulo by zero
Command exited with non-zero status 1
7.34user 1.23system 0:07.86elapsed 109%CPU (0avgtext+0avgdata 1298660maxresident)k
0inputs+0outputs (0major+356640minor)pagefaults 0swaps
