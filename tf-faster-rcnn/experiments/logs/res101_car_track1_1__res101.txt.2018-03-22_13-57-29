+ echo Logging output to experiments/logs/res101_car_track1_1__res101.txt.2018-03-22_13-57-29
Logging output to experiments/logs/res101_car_track1_1__res101.txt.2018-03-22_13-57-29
+ set +x
+ '[' '!' -f output/res101/car_track1_1/default/res101_faster_rcnn_iter_1000.ckpt.index ']'
+ [[ ! -z '' ]]
+ CUDA_VISIBLE_DEVICES=0
+ time python ./tools/trainval_net.py --weight data/imagenet_weights/res101.ckpt --imdb car_track1_1 --imdbval car_track1_4 --iters 1000 --cfg experiments/cfgs/res101.yml --net res101 --set ANCHOR_SCALES '[4,8,16,32]' ANCHOR_RATIOS '[0.5,1,2]' TRAIN.STEPSIZE '[1000]'
Called with args:
Namespace(cfg_file='experiments/cfgs/res101.yml', imdb_name='car_track1_1', imdbval_name='car_track1_4', max_iters=1000, net='res101', set_cfgs=['ANCHOR_SCALES', '[4,8,16,32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'TRAIN.STEPSIZE', '[1000]'], tag=None, weight='data/imagenet_weights/res101.ckpt')
Using config:
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [4, 8, 16, 32],
 'DATA_DIR': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data',
 'EXP_DIR': 'res101',
 'MATLAB': 'matlab',
 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,
               'FIXED_LAYERS': 5,
               'REGU_DEPTH': False,
               'WEIGHT_DECAY': 4e-05},
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},
 'RNG_SEED': 3,
 'ROOT_DIR': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn',
 'RPN_CHANNELS': 512,
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'MODE': 'nms',
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'gt',
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'RPN_TOP_N': 5000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': False,
           'BATCH_SIZE': 256,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'BIAS_DECAY': False,
           'DISPLAY': 20,
           'DOUBLE_BIAS': False,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'GAMMA': 0.1,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'LEARNING_RATE': 0.001,
           'MAX_SIZE': 1000,
           'MOMENTUM': 0.9,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_ITERS': 5000,
           'SNAPSHOT_KEPT': 3,
           'SNAPSHOT_PREFIX': 'res101_faster_rcnn',
           'STEPSIZE': [1000],
           'SUMMARY_INTERVAL': 180,
           'TRUNCATED': False,
           'USE_ALL_GT': True,
           'USE_FLIPPED': True,
           'USE_GT': False,
           'WEIGHT_DECAY': 0.0001},
 'USE_GPU_NMS': True}
Loaded dataset `car_track1_1` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
car_track1_1 gt roidb loaded from /media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/cache/car_track1_1_gt_roidb.pkl
done
Preparing training data...
done
600 roidb entries
Output will be saved to `/media/ad/DATA/aicitychallenge/tf-faster-rcnn/output/res101/car_track1_1/default`
TensorFlow summaries will be saved to `/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tensorboard/res101/car_track1_1/default`
Loaded dataset `car_track1_4` for training
Set proposal method: gt
Preparing training data...
car_track1_4 gt roidb loaded from /media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/cache/car_track1_4_gt_roidb.pkl
done
0 validation roidb entries
Filtered 0 roidb entries: 600 -> 600
Filtered 0 roidb entries: 0 -> 0
2018-03-22 13:57:30.708528: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-03-22 13:57:30.809434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-03-22 13:57:30.809679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6575
pciBusID: 0000:01:00.0
totalMemory: 10.91GiB freeMemory: 10.38GiB
2018-03-22 13:57:30.809691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0
2018-03-22 13:57:30.957834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10049 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
Solving...
/home/ad/tensorflow-r1.6/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Loading initial model weights from data/imagenet_weights/res101.ckpt
resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma
resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/logits/biases
resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights
resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean
resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights
resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights
resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/beta
resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance
resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights
resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean
resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights
resnet_v1_101/logits/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights
resnet_v1_101/conv1/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights
resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/beta
resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma
resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights
resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights
resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights
resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance
resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/mean_rgb
resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights
resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma
resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights
resnet_v1_101/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights
resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/beta
resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights
resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights
resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights
resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/beta
resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights
resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights
resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/conv1/BatchNorm/moving_mean
resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights
resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights
resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights
resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights
resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights
resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights
resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights
resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights
resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_variance
resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights
resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights
resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_variance
resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/beta
global_step
resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance
resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/gamma
resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance
resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights
resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean
resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance
resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/gamma
resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/gamma
resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean
resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/beta
resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/beta
resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights
resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/beta
resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_mean
resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_mean
Variables restored: resnet_v1_101/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/beta:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean:0
Variables restored: resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance:0
Loaded.
Fix Resnet V1 layers..
Fixed.
[{'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00001.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1115,  911, 1244, 1024],
       [1427, 1018, 1573, 1045],
       [1528,  922, 1682, 1022],
       [1682,  886, 1823,  968],
       [1484,  728, 1600,  811],
       [1327,  718, 1407,  782],
       [1171,  676, 1286,  789],
       [ 432,  647,  540,  749],
       [ 738,  641,  798,  684],
       [ 609,  603,  653,  639],
       [ 663,  580,  702,  614],
       [1238,  595, 1290,  634],
       [1121,  547, 1184,  609],
       [1205,  574, 1246,  614],
       [1025,  543, 1059,  574],
       [1065,  538, 1103,  563],
       [ 688,  541,  721,  568],
       [ 740,  532,  777,  564]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([14820.,  4116., 15655., 11786.,  9828.,  5265., 13224., 11227.,
        2684.,  1665.,  1400.,  2120.,  4032.,  1722.,  1120.,  1014.,
         952.,  1254.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00002.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1136,  939, 1271, 1045],
       [1742,  901, 1919, 1024],
       [1213,  759, 1305,  838],
       [1307,  732, 1398,  797],
       [1438,  726, 1523,  784],
       [1046,  711, 1117,  774],
       [1103,  603, 1186,  686],
       [1223,  634, 1282,  684],
       [1340,  639, 1417,  699],
       [ 634,  753,  719,  826],
       [ 209,  732,  377,  884],
       [ 536,  645,  598,  695],
       [ 598,  613,  653,  657],
       [ 667,  564,  702,  591],
       [ 727,  530,  773,  584],
       [1073,  526, 1130,  580],
       [1173,  561, 1219,  593],
       [ 632,  524,  665,  555],
       [ 678,  524,  717,  555]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14552., 22072.,  7440.,  6072.,  5074.,  4608.,  7056.,  3060.,
        4758.,  6364., 25857.,  3213.,  2520.,  1008.,  2585.,  3190.,
        1551.,  1088.,  1280.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00003.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1121,  882, 1238,  978],
       [1473,  732, 1575,  803],
       [1050,  720, 1123,  780],
       [1130,  655, 1196,  711],
       [1207,  643, 1269,  689],
       [1315,  643, 1373,  684],
       [1255,  589, 1311,  639],
       [1161,  588, 1209,  624],
       [1009,  626, 1061,  670],
       [1067,  561, 1132,  624],
       [1125,  538, 1155,  564],
       [1036,  509, 1084,  553],
       [ 417,  718,  496,  784],
       [ 507,  659,  578,  722],
       [ 565,  636,  621,  684],
       [ 630,  591,  677,  628],
       [ 702,  555,  757,  626],
       [ 659,  541,  702,  580],
       [ 615,  538,  648,  568]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11446.,  7416.,  4514.,  3819.,  2961.,  2478.,  2907.,  1813.,
        2385.,  4224.,   837.,  2205.,  5360.,  4608.,  2793.,  1824.,
        4032.,  1760.,  1054.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00004.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1173, 1016, 1315, 1047],
       [1840,  976, 1919, 1044],
       [ 152,  845,  288,  953],
       [ 348,  738,  448,  820],
       [ 459,  693,  538,  751],
       [1050,  701, 1119,  759],
       [1336,  643, 1405,  697],
       [ 644,  601,  711,  686],
       [1015,  626, 1067,  666],
       [1082,  599, 1130,  638],
       [1144,  589, 1190,  626],
       [1232,  586, 1277,  626],
       [ 984,  576, 1021,  605],
       [1036,  532, 1088,  584],
       [1109,  555, 1148,  582],
       [ 569,  632,  628,  674],
       [ 577,  559,  619,  599],
       [ 632,  564,  688,  601],
       [ 794,  534,  827,  557]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4576.,  5520., 14933.,  8383.,  4720.,  4130.,  3850.,  5848.,
        2173.,  1960.,  1786.,  1886.,  1140.,  2809.,  1120.,  2580.,
        1763.,  2166.,   816.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00005.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1678, 1007, 1859, 1047],
       [1269,  807, 1384,  913],
       [1453,  764, 1648,  955],
       [1069,  739, 1146,  807],
       [  42,  880,  198, 1009],
       [ 280,  788,  390,  868],
       [ 530,  663,  630,  782],
       [ 471,  688,  540,  743],
       [1017,  618, 1065,  655],
       [1248,  595, 1298,  636],
       [ 992,  576, 1030,  609],
       [1046,  561, 1082,  591],
       [1096,  561, 1138,  588],
       [1169,  559, 1205,  588],
       [ 588,  576,  655,  647],
       [ 523,  584,  575,  636],
       [ 790,  563,  825,  597],
       [ 648,  555,  692,  591],
       [ 588,  559,  630,  593],
       [ 955,  543,  988,  568],
       [1005,  514, 1044,  559],
       [1069,  534, 1098,  559],
       [1134,  532, 1169,  566]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 7462., 12412., 37632.,  5382., 20410.,  8991., 12120.,  3920.,
        1862.,  2142.,  1326.,  1147.,  1204.,  1110.,  4896.,  2809.,
        1260.,  1665.,  1505.,   884.,  1840.,   780.,  1260.],
      dtype=float32), 'gt_overlaps': <23x16 sparse matrix of type '<type 'numpy.float32'>'
	with 23 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00006.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1092,  820, 1207,  932],
       [1290,  853, 1413,  953],
       [1717,  897, 1878,  993],
       [1394,  778, 1500,  859],
       [1159,  682, 1230,  747],
       [1290,  655, 1411,  772],
       [   2,  970,   86, 1047],
       [ 278,  795,  467,  982],
       [ 515,  616,  607,  705],
       [ 444,  624,  505,  684],
       [1023,  636, 1078,  678],
       [ 761,  607,  807,  643],
       [ 613,  584,  665,  632],
       [ 542,  588,  590,  626],
       [1184,  563, 1232,  599],
       [ 990,  568, 1028,  601],
       [1119,  536, 1152,  564],
       [ 659,  538,  694,  561]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([13108., 12524., 15714.,  8774.,  4752., 14396.,  6630., 35720.,
        8370.,  3782.,  2408.,  1739.,  2597.,  1911.,  1813.,  1326.,
         986.,   864.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00007.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1117,  978, 1255, 1047],
       [1323,  886, 1459,  980],
       [1478,  859, 1617,  972],
       [1457,  730, 1550,  788],
       [1165,  699, 1240,  763],
       [1263,  672, 1336,  730],
       [1034,  672, 1105,  741],
       [1102,  611, 1159,  663],
       [1200,  595, 1290,  682],
       [   0,  961,   99, 1053],
       [ 705,  678,  771,  738],
       [ 394,  676,  519,  784],
       [ 328,  678,  405,  751],
       [ 563,  622,  628,  674],
       [ 463,  632,  521,  676],
       [ 578,  597,  628,  624],
       [ 619,  559,  655,  589],
       [ 996,  580, 1036,  613],
       [1132,  538, 1173,  572],
       [ 696,  543,  728,  576],
       [ 959,  541,  990,  568]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9730., 13015., 15960.,  5546.,  4940.,  4366.,  5040.,  3074.,
        8008.,  9300.,  4087., 13734.,  5772.,  3498.,  2655.,  1428.,
        1147.,  1394.,  1470.,  1122.,   896.], dtype=float32), 'gt_overlaps': <21x16 sparse matrix of type '<type 'numpy.float32'>'
	with 21 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00008.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1152,  963, 1290, 1045],
       [1498,  876, 1634,  966],
       [1046,  739, 1119,  799],
       [1177,  714, 1257,  774],
       [1307,  716, 1394,  786],
       [1317,  645, 1380,  686],
       [1105,  628, 1159,  672],
       [1190,  611, 1244,  655],
       [1005,  603, 1059,  649],
       [1063,  572, 1107,  613],
       [1142,  557, 1217,  626],
       [ 548,  845,  661,  941],
       [ 148,  776,  350,  938],
       [ 330,  693,  407,  751],
       [ 471,  672,  557,  738],
       [ 482,  638,  542,  680],
       [ 555,  591,  602,  626],
       [ 652,  574,  692,  607],
       [ 694,  547,  730,  582],
       [ 800,  551,  830,  586],
       [ 859,  555,  894,  582],
       [ 619,  543,  646,  568],
       [ 969,  547, 1002,  574]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11537., 12467.,  4514.,  4941.,  6248.,  2688.,  2475.,  2475.,
        2585.,  1890.,  5320., 11058., 33089.,  4602.,  5829.,  2623.,
        1728.,  1394.,  1332.,  1116.,  1008.,   728.,   952.],
      dtype=float32), 'gt_overlaps': <23x16 sparse matrix of type '<type 'numpy.float32'>'
	with 23 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00009.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1821,  997, 1919, 1045],
       [1267,  830, 1384,  918],
       [1467,  828, 1590,  926],
       [1059,  732, 1134,  795],
       [1319,  726, 1402,  788],
       [1019,  643, 1069,  684],
       [1115,  630, 1163,  676],
       [1219,  636, 1284,  689],
       [1232,  595, 1282,  628],
       [ 311,  751,  434,  849],
       [ 119,  788,  232,  866],
       [ 327,  707,  417,  755],
       [ 471,  636,  528,  672],
       [ 582,  613,  632,  653],
       [ 644,  574,  688,  626],
       [ 782,  595,  825,  628],
       [ 853,  591,  900,  634],
       [ 588,  561,  627,  593],
       [1065,  578, 1105,  614],
       [1138,  574, 1180,  609],
       [ 980,  561, 1023,  595],
       [ 728,  563,  763,  593],
       [ 861,  553,  894,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4851., 10502., 12276.,  4864.,  5292.,  2142.,  2303.,  3564.,
        1734., 12276.,  9006.,  4459.,  2146.,  2091.,  2385.,  1496.,
        2112.,  1320.,  1517.,  1548.,  1540.,  1116.,   884.],
      dtype=float32), 'gt_overlaps': <23x16 sparse matrix of type '<type 'numpy.float32'>'
	with 23 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00010.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1107,  838, 1228,  949],
       [1490,  753, 1594,  834],
       [1305,  699, 1384,  759],
       [1161,  693, 1234,  747],
       [1230,  647, 1288,  691],
       [1027,  638, 1078,  680],
       [1161,  593, 1207,  632],
       [1071,  582, 1111,  614],
       [1171,  559, 1211,  591],
       [ 996,  586, 1036,  620],
       [1028,  547, 1067,  578],
       [1096,  545, 1132,  576],
       [   0,  907,  186, 1043],
       [  75,  813,  203,  895],
       [ 342,  693,  419,  747],
       [ 477,  674,  544,  728],
       [ 571,  618,  628,  670],
       [ 738,  659,  796,  711],
       [ 834,  655,  894,  709],
       [ 773,  613,  819,  651],
       [ 690,  603,  736,  639],
       [ 542,  589,  592,  632],
       [ 628,  591,  673,  624],
       [ 861,  588,  900,  628],
       [ 794,  520,  832,  570]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([13664.,  8610.,  4880.,  4070.,  2655.,  2236.,  1880.,  1353.,
        1353.,  1435.,  1280.,  1184., 25619., 10707.,  4290.,  3740.,
        3074.,  3127.,  3355.,  1833.,  1739.,  2244.,  1564.,  1640.,
        1989.], dtype=float32), 'gt_overlaps': <25x16 sparse matrix of type '<type 'numpy.float32'>'
	with 25 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00011.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1600,  961, 1796, 1045],
       [1052,  686, 1127,  751],
       [1342,  651, 1411,  705],
       [1217,  626, 1271,  676],
       [1103,  616, 1157,  661],
       [1173,  595, 1219,  632],
       [1002,  582, 1042,  614],
       [1113,  559, 1155,  593],
       [1036,  549, 1073,  576],
       [ 969,  553, 1007,  580],
       [ 773,  782,  865,  870],
       [ 611,  793,  709,  874],
       [ 275,  776,  382,  855],
       [ 121,  791,  230,  870],
       [ 450,  686,  532,  759],
       [ 702,  693,  771,  749],
       [ 836,  653,  890,  705],
       [ 607,  666,  675,  722],
       [ 465,  632,  521,  676],
       [ 565,  636,  623,  678],
       [ 536,  588,  582,  626],
       [ 609,  595,  661,  639],
       [ 846,  593,  909,  653],
       [ 778,  549,  827,  605],
       [ 734,  545,  765,  578],
       [ 684,  538,  713,  561]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16745.,  5016.,  3850.,  2805.,  2530.,  1786.,  1353.,  1505.,
        1064.,  1092.,  8277.,  8118.,  8640.,  8800.,  6142.,  3990.,
        2915.,  3933.,  2565.,  2537.,  1833.,  2385.,  3904.,  2850.,
        1088.,   720.], dtype=float32), 'gt_overlaps': <26x16 sparse matrix of type '<type 'numpy.float32'>'
	with 26 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00012.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1594,  816, 1753,  939],
       [1359,  757, 1473,  839],
       [1067,  776, 1163,  851],
       [ 523,  863,  646,  963],
       [ 773,  778,  861,  863],
       [ 200,  799,  342,  905],
       [ 427,  797,  534,  880],
       [ 811,  659,  898,  757],
       [ 453,  699,  536,  755],
       [ 530,  641,  602,  695],
       [ 336,  691,  411,  749],
       [ 459,  630,  528,  674],
       [ 748,  572,  811,  664],
       [ 717,  578,  752,  607],
       [1025,  614, 1075,  659],
       [1252,  589, 1305,  634],
       [1165,  586, 1203,  620],
       [1065,  572, 1107,  611],
       [1125,  564, 1163,  591]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19840.,  9545.,  7372., 12524.,  7654., 15301.,  9072.,  8712.,
        4788.,  4015.,  4484.,  3150.,  5952.,  1080.,  2346.,  2484.,
        1365.,  1720.,  1092.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00013.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 721,  807,  857,  986],
       [ 242,  813,  363,  895],
       [ 105,  791,  223,  866],
       [ 394,  709,  484,  789],
       [ 665,  632,  773,  757],
       [ 332,  682,  413,  749],
       [1027,  661, 1088,  709],
       [1248,  664, 1323,  722],
       [1403,  682, 1503,  759],
       [ 992,  570, 1027,  607],
       [1117,  559, 1157,  588],
       [1186,  557, 1228,  589],
       [ 794,  570,  830,  601],
       [ 713,  572,  750,  611],
       [ 640,  576,  675,  607]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([24660., 10126.,  9044.,  7371., 13734.,  5576.,  3038.,  4484.,
        7878.,  1368.,  1230.,  1419.,  1184.,  1520.,  1152.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00014.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 119,  841,  273,  966],
       [ 102,  776,  221,  868],
       [ 494,  754,  683,  979],
       [ 663,  741,  738,  807],
       [ 584,  684,  648,  736],
       [ 657,  616,  717,  682],
       [ 763,  613,  815,  663],
       [ 594,  607,  634,  651],
       [ 634,  572,  680,  613],
       [ 577,  564,  619,  603],
       [1565,  797, 1678,  870],
       [1296,  609, 1365,  666],
       [1177,  605, 1234,  651],
       [1000,  599, 1048,  638],
       [1128,  532, 1165,  559],
       [ 967,  539, 1000,  563]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([19530., 11160., 42940.,  5092.,  3445.,  4087.,  2703.,  1845.,
        1974.,  1720.,  8436.,  4060.,  2726.,  1960.,  1064.,   850.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00015.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 415,  980,  573, 1045],
       [ 405,  795,  513,  874],
       [1403, 1014, 1555, 1047],
       [1444,  847, 1561,  924],
       [1536,  772, 1644,  847],
       [1234,  786, 1327,  863],
       [1384,  680, 1453,  730],
       [ 692,  693,  763,  766],
       [ 555,  680,  644,  770],
       [ 527,  659,  586,  709],
       [ 590,  605,  642,  651],
       [ 519,  601,  567,  639],
       [ 578,  564,  623,  601],
       [1221,  568, 1271,  611],
       [1132,  572, 1175,  607],
       [ 980,  561, 1017,  588]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([10494.,  8720.,  5202.,  9204.,  8284.,  7332.,  3570.,  5328.,
        8190.,  3060.,  2491.,  1911.,  1748.,  2244.,  1584.,  1064.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00016.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 500,  859,  630,  974],
       [ 334,  809,  486,  957],
       [ 400,  726,  484,  793],
       [ 515,  653,  584,  707],
       [ 428,  645,  488,  699],
       [ 505,  603,  567,  649],
       [1321,  918, 1467, 1038],
       [1425,  801, 1529,  880],
       [1084,  799, 1178,  876],
       [1213,  761, 1303,  832],
       [1290,  707, 1365,  764],
       [1369,  664, 1438,  716],
       [1140,  670, 1202,  713],
       [1275,  609, 1327,  657],
       [1152,  536, 1198,  572],
       [1088,  543, 1128,  574],
       [ 853,  547,  900,  605],
       [ 725,  561,  759,  591],
       [ 625,  532,  667,  564]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15196., 22797.,  5780.,  3850.,  3355.,  2961., 17787.,  8400.,
        7410.,  6552.,  4408.,  3710.,  2772.,  2597.,  1739.,  1312.,
        2832.,  1085.,  1419.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00017.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 157,  855,  292,  957],
       [ 382,  716,  473,  801],
       [ 265,  724,  353,  789],
       [ 390,  655,  475,  714],
       [1382,  974, 1573, 1045],
       [1584,  966, 1753, 1039],
       [1638,  861, 1777,  941],
       [1405,  795, 1513,  876],
       [1182,  730, 1265,  799],
       [1277,  684, 1352,  739],
       [1132,  659, 1190,  703],
       [1209,  638, 1261,  680],
       [1271,  601, 1325,  645],
       [1032,  655, 1094,  701],
       [1080,  607, 1134,  641],
       [1202,  574, 1248,  605],
       [ 844,  589,  903,  664],
       [ 688,  607,  734,  643],
       [ 598,  549,  640,  589],
       [ 667,  557,  692,  591],
       [ 792,  547,  832,  576],
       [1100,  520, 1136,  549]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14008.,  7912.,  5874.,  5160., 13824., 12580., 11340.,  8938.,
        5880.,  4256.,  2655.,  2279.,  2475.,  2961.,  1925.,  1504.,
        4560.,  1739.,  1763.,   910.,  1230.,  1110.], dtype=float32), 'gt_overlaps': <22x16 sparse matrix of type '<type 'numpy.float32'>'
	with 22 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00018.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 111,  857,  259,  978],
       [   0,  857,  100,  955],
       [ 175,  741,  311,  832],
       [ 605,  678,  675,  728],
       [ 809,  664,  892,  768],
       [1200,  743, 1303,  832],
       [1515,  897, 1648,  993],
       [1369,  768, 1461,  839],
       [1402,  705, 1478,  755],
       [1277,  688, 1348,  738],
       [1113,  638, 1167,  689],
       [1200,  628, 1255,  661],
       [1155,  597, 1198,  620],
       [1198,  570, 1252,  603],
       [1090,  601, 1128,  636],
       [1009,  591, 1049,  622],
       [1046,  566, 1084,  591],
       [ 552,  572,  605,  630],
       [ 623,  588,  669,  616],
       [ 661,  557,  703,  599],
       [ 784,  570,  827,  614]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18178.,  9999., 12604.,  3621.,  8820.,  9360., 12998.,  6696.,
        3927.,  3672.,  2860.,  1904.,  1056.,  1870.,  1404.,  1312.,
        1014.,  3186.,  1363.,  1849.,  1980.], dtype=float32), 'gt_overlaps': <21x16 sparse matrix of type '<type 'numpy.float32'>'
	with 21 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00019.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 705,  826,  850, 1018],
       [ 421,  809,  532,  891],
       [1515,  761, 1636,  838],
       [1325,  736, 1402,  801],
       [1252,  674, 1321,  724],
       [1278,  622, 1338,  659],
       [1200,  624, 1252,  668],
       [1123,  643, 1192,  703],
       [1071,  589, 1113,  628],
       [1144,  582, 1182,  616],
       [ 855,  609,  900,  641],
       [ 742,  613,  802,  663],
       [ 552,  632,  617,  678],
       [ 482,  607,  544,  668],
       [ 617,  597,  667,  632],
       [ 725,  563,  767,  595],
       [ 855,  549,  892,  586],
       [ 598,  566,  625,  593],
       [1040,  561, 1077,  588],
       [1111,  563, 1146,  591],
       [ 975,  553, 1013,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28178.,  9296.,  9516.,  5148.,  3570.,  2318.,  2385.,  4270.,
        1720.,  1365.,  1518.,  3111.,  3102.,  3906.,  1836.,  1419.,
        1444.,   784.,  1064.,  1044.,  1014.], dtype=float32), 'gt_overlaps': <21x16 sparse matrix of type '<type 'numpy.float32'>'
	with 21 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00020.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 425,  705,  511,  764],
       [ 363,  657,  448,  728],
       [ 536,  643,  600,  695],
       [ 669,  678,  755,  751],
       [ 825,  693,  888,  749],
       [1361,  657, 1432,  716],
       [1227,  657, 1282,  699],
       [1080,  586, 1128,  628],
       [1177,  614, 1230,  653],
       [1146,  578, 1188,  616],
       [1202,  576, 1250,  607],
       [ 686,  599,  734,  643],
       [ 861,  589,  902,  624],
       [ 546,  593,  582,  626],
       [ 603,  557,  634,  588],
       [1032,  553, 1071,  588],
       [1100,  553, 1136,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([5220., 6192., 3445., 6438., 3648., 4320., 2408., 2107., 2160.,
       1677., 1568., 2205., 1512., 1258., 1024., 1440.,  962.],
      dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00021.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1148,  955, 1315, 1041],
       [1669,  874, 1809,  963],
       [ 728,  866,  838,  970],
       [ 528,  799,  659,  918],
       [ 165,  838,  302,  932],
       [ 390,  720,  492,  797],
       [ 602,  664,  667,  728],
       [ 842,  655,  896,  707],
       [ 144,  741,  277,  847],
       [ 465,  639,  517,  678],
       [ 553,  576,  592,  618],
       [1267,  603, 1315,  643],
       [1167,  605, 1213,  647],
       [1115,  580, 1159,  609],
       [1038,  551, 1090,  582],
       [1146,  549, 1182,  580],
       [ 663,  566,  698,  597]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([14616., 12690., 11655., 15840., 13110.,  8034.,  4290.,  2915.,
       14338.,  2120.,  1720.,  2009.,  2021.,  1350.,  1696.,  1184.,
        1152.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00022.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  84,  868,  252,  989],
       [ 423,  784,  530,  882],
       [ 773,  788,  859,  864],
       [1061,  718, 1150,  795],
       [1396,  697, 1463,  747],
       [1196,  566, 1240,  595],
       [1121,  566, 1157,  597],
       [ 323,  705,  396,  761],
       [ 477,  620,  528,  659],
       [ 613,  607,  665,  638],
       [ 719,  563,  744,  589],
       [ 794,  547,  834,  589],
       [1053,  549, 1088,  576]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20618., 10692.,  6699.,  7020.,  3468.,  1350.,  1184.,  4218.,
        2080.,  1696.,   702.,  1763.,  1008.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00023.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  34,  824,  159,  911],
       [ 357,  674,  427,  728],
       [ 534,  659,  598,  701],
       [ 680,  605,  727,  639],
       [ 761,  582,  823,  641],
       [ 582,  572,  628,  611],
       [ 655,  547,  692,  584],
       [1032,  620, 1086,  674],
       [1261,  613, 1315,  653],
       [1248,  793, 1348,  872],
       [1469,  838, 1600,  938],
       [1090,  545, 1125,  572],
       [1144,  547, 1182,  574]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11088.,  3905.,  2795.,  1680.,  3780.,  1880.,  1444.,  3025.,
        2255.,  8080., 13332.,  1008.,  1092.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00024.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 132,  776,  242,  845],
       [ 375,  747,  467,  813],
       [1228,  778, 1321,  845],
       [1284,  689, 1363,  747],
       [1150,  674, 1211,  720],
       [ 717,  636,  794,  720],
       [ 613,  661,  673,  714],
       [ 515,  605,  569,  647],
       [ 623,  561,  673,  616],
       [1009,  568, 1053,  603],
       [1184,  568, 1227,  597],
       [ 738,  549,  777,  578],
       [ 819,  551,  848,  580],
       [ 673,  557,  705,  595]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([7770., 6231., 6392., 4720., 2914., 6630., 3294., 2365., 2856.,
       1620., 1320., 1200.,  900., 1287.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00025.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  19,  926,  188, 1043],
       [ 473,  764,  565,  838],
       [ 619,  734,  727,  843],
       [ 411,  655,  478,  711],
       [ 567,  609,  628,  672],
       [ 634,  588,  675,  632],
       [ 713,  576,  757,  609],
       [ 798,  588,  840,  618],
       [ 659,  551,  694,  586],
       [1138,  663, 1200,  711],
       [1200,  614, 1252,  663],
       [1092,  609, 1142,  645],
       [ 994,  532, 1028,  570]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20060.,  6975., 11990.,  3876.,  3968.,  1890.,  1530.,  1333.,
        1296.,  3087.,  2650.,  1887.,  1365.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00026.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 219,  747,  315,  807],
       [ 455,  663,  540,  738],
       [ 134,  964,  530, 1045],
       [1327,  895, 1459,  993],
       [1728,  911, 1892, 1003],
       [1082,  793, 1165,  861],
       [1092,  607, 1132,  641],
       [1140,  564, 1182,  599],
       [1052,  568, 1090,  595],
       [ 755,  647,  813,  699],
       [ 667,  624,  719,  666],
       [ 557,  639,  625,  684],
       [ 615,  584,  663,  636],
       [ 784,  564,  825,  611],
       [ 717,  570,  753,  605]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 5917.,  6536., 32554., 13167., 15345.,  5796.,  1435.,  1548.,
        1092.,  3127.,  2279.,  3174.,  2597.,  2016.,  1332.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00027.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1421,  805, 1544,  893],
       [1453,  732, 1544,  789],
       [1182,  718, 1253,  766],
       [1027,  651, 1078,  691],
       [1048,  564, 1096,  597],
       [ 654,  759,  735,  830],
       [ 238,  766,  378,  889],
       [ 423,  709,  511,  782],
       [ 578,  699,  648,  757],
       [ 538,  639,  594,  688],
       [ 686,  613,  728,  643],
       [ 757,  597,  811,  655],
       [ 717,  561,  757,  603],
       [ 796,  547,  827,  583]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([11036.,  5336.,  3528.,  2132.,  1666.,  5904., 17484.,  6586.,
        4189.,  2850.,  1333.,  3245.,  1763.,  1184.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00028.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 148,  845,  296,  963],
       [ 369,  838,  498,  939],
       [ 384,  716,  469,  782],
       [ 611,  666,  677,  718],
       [ 705,  657,  773,  732],
       [ 677,  599,  734,  657],
       [ 778,  588,  823,  624],
       [1325,  905, 1467, 1009],
       [1465,  805, 1567,  876],
       [1277,  674, 1350,  739],
       [1319,  647, 1384,  688],
       [1107,  626, 1163,  668],
       [1002,  586, 1040,  626]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17731., 13260.,  5762.,  3551.,  5244.,  3422.,  1702., 15015.,
        7416.,  4884.,  2772.,  2451.,  1599.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00029.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  48,  868,  203,  999],
       [ 473,  764,  565,  843],
       [ 596,  761,  696,  857],
       [ 594,  657,  688,  734],
       [ 744,  632,  803,  686],
       [ 527,  599,  573,  638],
       [ 625,  599,  667,  634],
       [ 577,  561,  619,  597],
       [1128,  959, 1275, 1045],
       [1411,  986, 1573, 1045],
       [1715,  905, 1865,  995],
       [1175,  709, 1252,  766],
       [1332,  680, 1400,  732],
       [1188,  609, 1250,  659],
       [1238,  593, 1280,  630],
       [1075,  578, 1113,  607],
       [ 790,  569,  823,  598]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([20592.,  7440.,  9797.,  7410.,  3300.,  1880.,  1548.,  1591.,
       12876.,  9780., 13741.,  4524.,  3657.,  3213.,  1634.,  1170.,
        1020.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00030.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 340, 1003,  503, 1039],
       [ 136, 1013,  275, 1043],
       [ 427,  759,  580,  864],
       [ 665,  714,  744,  786],
       [1052,  716, 1128,  788],
       [1202,  738, 1286,  807],
       [1427,  713, 1507,  766],
       [1109,  620, 1155,  657],
       [1248,  618, 1300,  645],
       [ 530,  657,  590,  699],
       [ 421,  653,  484,  701],
       [ 517,  599,  571,  639],
       [ 767,  607,  821,  643],
       [1130,  570, 1184,  618],
       [ 573,  561,  628,  605],
       [ 853,  582,  898,  620]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 6068.,  4340., 16324.,  5840.,  5621.,  5950.,  4374.,  1786.,
        1484.,  2623.,  3136.,  2255.,  2035.,  2695.,  2520.,  1794.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00031.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  40,  993,  311, 1051],
       [ 488,  876,  623, 1001],
       [ 332,  766,  427,  836],
       [ 221,  747,  313,  813],
       [ 417,  645,  488,  701],
       [ 500,  599,  567,  651],
       [ 719,  670,  777,  720],
       [ 846,  641,  892,  691],
       [1759,  832, 1919, 1047],
       [1452,  828, 1573,  918],
       [1123,  638, 1177,  688],
       [1294,  624, 1344,  664],
       [1017,  622, 1069,  663],
       [ 757,  603,  807,  636],
       [ 627,  605,  669,  636],
       [1194,  578, 1236,  601],
       [1061,  574, 1096,  603]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([16048., 17136.,  6816.,  6231.,  4104.,  3604.,  3009.,  2397.,
       34776., 11102.,  2805.,  2091.,  2226.,  1734.,  1376.,  1032.,
        1080.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00032.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1234,  803, 1334,  882],
       [1478,  672, 1773,  914],
       [1275,  676, 1344,  736],
       [ 794,  757,  869,  838],
       [ 588,  789,  686,  874],
       [ 236,  726,  332,  799],
       [ 377,  655,  463,  726],
       [ 519,  664,  584,  718],
       [ 707,  666,  773,  718],
       [ 477,  624,  530,  670],
       [ 848,  603,  890,  638],
       [ 773,  593,  815,  626],
       [1071,  582, 1121,  618],
       [1209,  576, 1255,  613],
       [ 984,  566, 1017,  601],
       [ 719,  564,  757,  599]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 8080., 71928.,  4270.,  6232.,  8514.,  7178.,  6264.,  3630.,
        3551.,  2538.,  1548.,  1462.,  1887.,  1786.,  1224.,  1404.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00033.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1236,  955, 1390, 1041],
       [1127,  663, 1194,  713],
       [1332,  601, 1511,  753],
       [1257,  670, 1327,  716],
       [1186,  601, 1240,  641],
       [ 577,  784,  680,  864],
       [ 311,  782,  411,  857],
       [ 142,  749,  278,  845],
       [ 328,  695,  405,  751],
       [ 817,  682,  880,  734],
       [ 727,  661,  782,  701],
       [ 675,  609,  728,  655],
       [ 527,  603,  575,  641]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([13485.,  3468., 27540.,  3337.,  2255.,  8424.,  7676., 13289.,
        4446.,  3392.,  2296.,  2538.,  1911.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00034.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 719,  855,  834,  953],
       [  32,  824,  171,  913],
       [ 609,  776,  694,  845],
       [ 586,  678,  663,  751],
       [ 415,  657,  478,  709],
       [ 600,  607,  650,  649],
       [ 707,  588,  748,  618],
       [1098,  728, 1173,  807],
       [1677,  859, 1819,  943],
       [1242,  559, 1363,  664],
       [1167,  599, 1225,  641],
       [1080,  595, 1119,  638],
       [1136,  564, 1178,  601]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11484., 12600.,  6020.,  5772.,  3392.,  2193.,  1302.,  6080.,
       12155., 12932.,  2537.,  1760.,  1634.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00035.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 386,  805,  505,  909],
       [ 211,  751,  315,  820],
       [ 502,  663,  567,  707],
       [ 657,  636,  711,  676],
       [1548,  901, 1707, 1020],
       [1436,  709, 1523,  761],
       [1044,  636, 1096,  684],
       [1177,  536, 1277,  609],
       [1111,  561, 1152,  591],
       [ 627,  584,  673,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12600.,  7350.,  2970.,  2255., 19200.,  4664.,  2597.,  7474.,
        1302.,  1927.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00036.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 309,  768,  407,  847],
       [ 555,  720,  634,  776],
       [1321,  886, 1457, 1001],
       [1327,  724, 1415,  793],
       [1315,  636, 1367,  670],
       [ 555,  628,  607,  670],
       [ 542,  597,  582,  632],
       [ 771,  578,  823,  626],
       [1013,  582, 1052,  626]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 7920.,  4560., 15892.,  6230.,  1855.,  2279.,  1476.,  2597.,
        1800.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00037.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 313,  884,  455,  995],
       [1521,  895, 1671,  995],
       [1175,  700, 1244,  771],
       [1217,  636, 1275,  688],
       [ 727,  639,  794,  707],
       [ 852,  624,  902,  655],
       [1219,  580, 1271,  614],
       [ 432,  705,  503,  764],
       [ 438,  643,  500,  686],
       [ 530,  597,  575,  634]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16016., 15251.,  5040.,  3127.,  4692.,  1632.,  1855.,  4320.,
        2772.,  1748.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00038.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1530,  886, 1680,  993],
       [ 588,  770,  694,  872],
       [ 153,  849,  282,  945],
       [ 248,  732,  338,  797],
       [ 815,  726,  884,  782],
       [1311,  713, 1388,  770],
       [1102,  618, 1150,  661],
       [1150,  582, 1190,  628],
       [ 430,  649,  496,  688],
       [ 544,  591,  594,  636],
       [ 861,  561,  903,  597]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16308., 11021., 12610.,  6006.,  3990.,  4524.,  2156.,  1927.,
        2680.,  2346.,  1591.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00039.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 682, 1001,  815, 1047],
       [ 253,  726,  346,  786],
       [ 450,  649,  517,  695],
       [ 525,  582,  592,  634],
       [ 640,  528,  700,  599],
       [ 848,  613,  903,  651],
       [1309,  709, 1398,  774],
       [1498,  745, 1590,  805],
       [1205,  630, 1257,  668],
       [1059,  574, 1096,  609]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([6298., 5734., 3196., 3604., 4392., 2184., 5940., 5673., 2067.,
       1368.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00040.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1377,  928, 1571, 1043],
       [1465,  859, 1592,  945],
       [1334,  639, 1398,  689],
       [ 809,  707,  886,  780],
       [ 284,  732,  373,  801],
       [ 430,  622,  519,  693],
       [ 586,  563,  665,  647],
       [ 742,  624,  800,  663],
       [1205,  626, 1267,  676],
       [1142,  578, 1184,  611],
       [ 780,  568,  823,  622],
       [ 717,  563,  759,  603],
       [   0,  891,   38,  982]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22620., 11136.,  3315.,  5772.,  6300.,  6480.,  6800.,  2360.,
        3213.,  1462.,  2420.,  1763.,  3588.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00041.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 648,  961,  802, 1045],
       [1190,  718, 1282,  805],
       [1290,  703, 1363,  755],
       [ 673,  711,  742,  766],
       [   3,  903,   71, 1028],
       [ 252,  688,  377,  789],
       [ 496,  603,  605,  714],
       [ 736,  618,  800,  691],
       [ 671,  601,  730,  659],
       [1238,  589, 1282,  624],
       [1140,  576, 1186,  614],
       [1090,  551, 1125,  574],
       [ 669,  530,  713,  576]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([13175.,  8184.,  3922.,  3920.,  8694., 12852., 12320.,  4810.,
        3540.,  1620.,  1833.,   864.,  2115.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00042.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  811,   94,  955],
       [ 475,  901,  609, 1003],
       [1496,  843, 1634,  943],
       [1115,  620, 1178,  680],
       [1192,  624, 1250,  668],
       [ 636,  724,  730,  826],
       [ 321,  672,  475,  830],
       [ 575,  674,  659,  747],
       [ 638,  549,  694,  607],
       [ 782,  578,  832,  609],
       [1086,  547, 1123,  576],
       [1165,  551, 1203,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([13485., 13905., 14039.,  3904.,  2655.,  9785., 24645.,  6290.,
        3363.,  1632.,  1140.,  1092.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00043.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  834,  203, 1047],
       [ 369,  934,  553, 1045],
       [ 361,  811,  505,  932],
       [ 173,  768,  275,  836],
       [1425,  801, 1536,  882],
       [1513,  759, 1621,  839],
       [1336,  691, 1415,  753],
       [1065,  570, 1117,  618],
       [1134,  578, 1178,  614],
       [ 759,  620,  809,  664],
       [ 588,  576,  657,  651],
       [ 707,  574,  753,  614]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([43014., 20720., 17690.,  7107.,  9184.,  8829.,  5040.,  2597.,
        1665.,  2295.,  5320.,  1927.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00044.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 690,  699,  761,  757],
       [1367,  772, 1463,  845],
       [1263,  672, 1332,  724],
       [1342,  653, 1421,  709],
       [1248,  611, 1313,  661],
       [ 657,  624,  711,  674],
       [ 490,  630,  596,  718],
       [1030,  541, 1073,  578],
       [1082,  547, 1113,  576],
       [ 678,  543,  713,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([4248., 7178., 3710., 4560., 3366., 2805., 9523., 1672.,  960.,
       1296.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00045.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 527,  859,  648,  959],
       [ 309,  709,  446,  832],
       [ 550,  697,  628,  772],
       [1102,  789, 1207,  888],
       [1290,  822, 1396,  913],
       [1517,  884, 1663,  989],
       [1230,  659, 1298,  703],
       [1177,  603, 1227,  639],
       [1246,  597, 1300,  639],
       [1190,  570, 1234,  607],
       [ 650,  570,  688,  609]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12322., 17112.,  6004., 10600.,  9844., 15582.,  3105.,  1887.,
        2365.,  1710.,  1560.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00046.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  876,  161, 1045],
       [ 309,  845,  448,  963],
       [  71,  786,  203,  872],
       [1596,  789, 1792,  930],
       [1302,  703, 1380,  763],
       [1163,  678, 1225,  741],
       [1042,  655, 1103,  713],
       [ 592,  611,  646,  659],
       [1159,  597, 1202,  632],
       [1178,  564, 1227,  601],
       [1111,  561, 1157,  593]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27030., 16660., 11571., 27974.,  4819.,  4032.,  3658.,  2695.,
        1584.,  1900.,  1551.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00047.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1271,  834, 1402,  936],
       [1384,  663, 1503,  755],
       [1192,  618, 1252,  666],
       [1098,  609, 1142,  653],
       [1013,  593, 1057,  632],
       [ 488,  678,  553,  730]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([13596., 11160.,  2989.,  2025.,  1800.,  3498.], dtype=float32), 'gt_overlaps': <6x16 sparse matrix of type '<type 'numpy.float32'>'
	with 6 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00048.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1538,  916, 1742, 1047],
       [ 271,  791,  378,  872],
       [1152,  688, 1228,  753],
       [1277,  601, 1357,  666],
       [ 567,  566,  627,  607],
       [1128,  570, 1175,  605],
       [1052,  566, 1088,  601],
       [ 988,  553, 1021,  588]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27060.,  8856.,  5082.,  5346.,  2562.,  1728.,  1332.,  1224.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00049.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1302,  714, 1403,  803],
       [1092,  616, 1150,  664],
       [1202,  563, 1267,  614],
       [ 500,  601,  573,  645],
       [ 775,  572,  805,  613],
       [ 732,  543,  761,  570]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([9180., 2891., 3432., 3330., 1302.,  840.], dtype=float32), 'gt_overlaps': <6x16 sparse matrix of type '<type 'numpy.float32'>'
	with 6 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00050.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1628,  884, 1919, 1043],
       [1282,  822, 1386,  897],
       [1198,  628, 1269,  689],
       [1057,  572, 1102,  611],
       [ 373,  647,  480,  713],
       [ 744,  620,  790,  661],
       [ 848,  557,  890,  591],
       [ 715,  566,  748,  601],
       [1142,  532, 1200,  580]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([46720.,  7980.,  4464.,  1840.,  7236.,  1974.,  1505.,  1224.,
        2891.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00051.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1132,  928, 1271, 1045],
       [1363,  953, 1530, 1045],
       [1761,  924, 1919, 1021],
       [1369,  707, 1540,  870],
       [1190,  682, 1255,  732],
       [ 142,  730,  309,  841],
       [ 673,  701,  742,  755],
       [ 850,  597,  902,  639],
       [ 684,  601,  727,  643],
       [ 634,  580,  673,  611],
       [ 786,  561,  825,  597],
       [ 719,  572,  757,  613],
       [1138,  572, 1190,  622]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16520., 15624., 15582., 28208.,  3366., 18816.,  3850.,  2279.,
        1892.,  1280.,  1480.,  1638.,  2703.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00052.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 511,  855,  623,  951],
       [ 830,  664,  894,  730],
       [ 623,  651,  682,  705],
       [ 573,  622,  625,  666],
       [ 680,  605,  736,  651],
       [ 767,  601,  815,  638],
       [ 532,  589,  586,  645],
       [1050,  716, 1134,  788],
       [1196,  736, 1284,  807],
       [1469,  736, 1565,  789],
       [1669,  845, 1867,  980],
       [1255,  618, 1357,  736],
       [1144,  609, 1184,  649]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10961.,  4355.,  3300.,  2385.,  2679.,  1862.,  3135.,  6205.,
        6408.,  5238., 27064., 12257.,  1681.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00053.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 740,  809,  853,  939],
       [ 511,  736,  592,  809],
       [ 453,  693,  530,  753],
       [ 436,  639,  503,  699],
       [ 619,  661,  686,  718],
       [ 707,  657,  784,  730],
       [ 598,  607,  640,  641],
       [ 788,  574,  828,  614],
       [1077,  776, 1192,  878],
       [1219,  772, 1309,  845],
       [1428,  813, 1538,  888],
       [1673,  876, 1813,  959],
       [1421,  695, 1532,  780],
       [1332,  641, 1394,  684],
       [1119,  639, 1184,  689],
       [1186,  576, 1265,  657],
       [1019,  630, 1069,  678],
       [1109,  570, 1146,  603],
       [ 657,  568,  688,  603]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14934.,  6068.,  4758.,  4148.,  3944.,  5772.,  1505.,  1681.,
       11948.,  6734.,  8436., 11844.,  9632.,  2772.,  3366.,  6560.,
        2499.,  1292.,  1152.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00054.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 253,  897,  400, 1026],
       [ 582,  774,  698,  891],
       [ 219,  811,  338,  905],
       [ 492,  749,  598,  836],
       [ 269,  724,  375,  813],
       [ 494,  664,  559,  720],
       [ 602,  607,  655,  647],
       [ 755,  616,  813,  676],
       [1036,  657, 1100,  722],
       [1134,  661, 1192,  713],
       [1284,  693, 1355,  745],
       [1432,  720, 1511,  778],
       [1296,  614, 1371,  678],
       [1073,  586, 1123,  622],
       [1138,  545, 1198,  611],
       [ 988,  576, 1034,  614],
       [1238,  589, 1288,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([19240., 13806., 11400.,  9416.,  9630.,  3762.,  2214.,  3599.,
        4290.,  3127.,  3816.,  4720.,  4940.,  1887.,  4087.,  1833.,
        1836.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00055.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 223,  924,  396, 1045],
       [   0,  880,   96, 1039],
       [ 284,  772,  394,  851],
       [ 678,  695,  757,  778],
       [ 507,  664,  569,  711],
       [ 532,  597,  577,  634],
       [1119,  882, 1240,  978],
       [1307,  632, 1365,  676],
       [1202,  626, 1257,  664],
       [1078,  603, 1127,  636],
       [1000,  589, 1055,  630],
       [1217,  570, 1273,  618]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21228., 15520.,  8880.,  6720.,  3024.,  1748., 11834.,  2655.,
        2184.,  1700.,  2352.,  2793.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00056.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1442,  759, 1819, 1039],
       [1228,  784, 1323,  857],
       [1055,  701, 1127,  757],
       [ 484,  861,  617, 1003],
       [ 330,  759,  427,  832],
       [ 427,  645,  492,  695],
       [ 613,  609,  665,  647],
       [ 538,  597,  584,  632],
       [1146,  584, 1186,  611],
       [1225,  584, 1277,  613],
       [ 778,  586,  821,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([106218.,   7104.,   4161.,  19162.,   7252.,   3366.,   2067.,
         1692.,   1148.,   1590.,   1716.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00057.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  964,   84, 1045],
       [1834,  972, 1919, 1045],
       [1252,  843, 1359,  924],
       [1292,  653, 1494,  851],
       [1138,  668, 1202,  714],
       [1027,  620, 1075,  657],
       [ 242,  730,  336,  801],
       [ 500,  676,  569,  726],
       [ 450,  641,  505,  688],
       [ 736,  643,  792,  689],
       [ 557,  582,  603,  622],
       [ 863,  570,  900,  605]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 6724.,  6364.,  8856., 40397.,  3055.,  1862.,  6840.,  3570.,
        2688.,  2679.,  1927.,  1368.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00058.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 259,  801,  375,  886],
       [ 277,  720,  367,  776],
       [ 642,  741,  725,  809],
       [ 480,  624,  542,  672],
       [ 532,  584,  578,  620],
       [ 615,  603,  655,  638],
       [ 848,  634,  896,  668],
       [1077,  768, 1167,  843],
       [1146,  695, 1211,  751],
       [1661,  853, 1786,  938],
       [1511,  766, 1619,  822],
       [1211,  591, 1342,  726],
       [1096,  607, 1140,  639],
       [1000,  572, 1038,  605]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([10062.,  5187.,  5796.,  3087.,  1739.,  1476.,  1715.,  6916.,
        3762., 10836.,  6213., 17952.,  1485.,  1326.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00059.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 398,  984,  561, 1053],
       [   2,  855,   84,  957],
       [ 348,  684,  428,  753],
       [ 525,  661,  586,  711],
       [ 800,  747,  873,  811],
       [ 452,  626,  511,  674],
       [1028,  645, 1082,  688],
       [1436,  709, 1509,  768],
       [1361,  666, 1427,  709],
       [1096,  622, 1138,  661],
       [1150,  563, 1250,  657],
       [ 777,  588,  821,  614],
       [ 709,  557,  750,  601],
       [ 592,  557,  627,  595]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([11480.,  8549.,  5670.,  3162.,  4810.,  2940.,  2420.,  4440.,
        2948.,  1720.,  9595.,  1215.,  1890.,  1404.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00060.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1615,  974, 1784, 1045],
       [1088,  759, 1169,  818],
       [1317,  632, 1371,  678],
       [1267,  603, 1317,  638],
       [1109,  534, 1190,  609],
       [1000,  582, 1042,  618],
       [1063,  576, 1103,  605],
       [  86,  801,  221,  903],
       [ 353,  755,  446,  818],
       [ 321,  688,  400,  755],
       [ 744,  632,  794,  678],
       [ 852,  607,  903,  655],
       [ 669,  595,  725,  647],
       [ 538,  588,  590,  626],
       [ 775,  584,  813,  616],
       [ 628,  586,  677,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([12240.,  4920.,  2585.,  1836.,  6232.,  1591.,  1230., 14008.,
        6016.,  5440.,  2397.,  2548.,  3021.,  2067.,  1287.,  1950.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00001.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  884,  150, 1043],
       [1630,  891, 1919, 1040],
       [1125,  688, 1248,  795],
       [1427,  647, 1553,  730],
       [1134,  497, 1205,  549],
       [1190,  413, 1246,  470],
       [ 975,  401, 1021,  436],
       [ 321,  545,  415,  613],
       [ 515,  324,  584,  407],
       [ 738,  361,  773,  393]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([23680., 43500., 13392., 10668.,  3816.,  3306.,  1692.,  6555.,
        5880.,  1188.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00002.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1842,  991, 1919, 1044],
       [   0,  778,   75,  909],
       [1340,  768, 1492,  884],
       [1246,  576, 1367,  664],
       [1019,  495, 1090,  557],
       [1246,  491, 1323,  547],
       [ 702,  409,  750,  449],
       [1065,  413, 1113,  457],
       [1130,  364, 1180,  411],
       [ 440,  349,  527,  455],
       [ 584,  380,  623,  411],
       [ 661,  382,  702,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4212., 10032., 17901., 10858.,  4536.,  4446.,  2009.,  2205.,
        2448.,  9416.,  1280.,  1344.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00003.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 311,  389,  434,  530],
       [ 632,  493,  702,  553],
       [ 507,  422,  569,  470],
       [ 609,  439,  663,  472],
       [1819,  943, 1919, 1046],
       [1644,  647, 1796,  751],
       [1392,  616, 1509,  691],
       [1153,  538, 1234,  599],
       [1105,  461, 1182,  514],
       [ 973,  411, 1023,  451],
       [1150,  416, 1203,  459]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17608.,  4331.,  3087.,  1870., 10504., 16065.,  8968.,  5084.,
        4212.,  2091.,  2376.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00004.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1440,  878, 1644, 1020],
       [ 442,  684,  571,  793],
       [1384,  595, 1509,  688],
       [1388,  488, 1477,  547],
       [1227,  478, 1303,  530],
       [1078,  439, 1130,  480],
       [1044,  393, 1086,  439],
       [ 507,  522,  582,  582],
       [ 692,  438,  742,  484],
       [ 355,  520,  440,  584],
       [  75,  457,  271,  659],
       [ 577,  401,  625,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([29315., 14300., 11844.,  5400.,  4081.,  2226.,  2021.,  4636.,
        2397.,  5590., 39991.,  1764.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00005.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1473,  897, 1721, 1045],
       [1575,  613, 1698,  691],
       [1190,  570, 1282,  638],
       [1221,  468, 1292,  526],
       [ 238,  718,  386,  834],
       [   0,  730,  113,  864],
       [ 582,  561,  675,  630],
       [ 473,  461,  542,  509],
       [1255,  413, 1317,  459],
       [1144,  409, 1192,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([37101.,  9796.,  6417.,  4248., 17433., 15390.,  6580.,  3430.,
        2961.,  1911.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00006.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 211,  918,  425, 1043],
       [1202,  891, 1392, 1034],
       [1194,  566, 1305,  655],
       [1344,  472, 1413,  522],
       [ 252,  591,  361,  666],
       [ 621,  397,  665,  434],
       [ 796,  411,  844,  453],
       [1096,  457, 1153,  499],
       [1142,  401, 1196,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27090., 27504., 10080.,  3570.,  8360.,  1710.,  2107.,  2494.,
        2255.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00007.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1561,  607, 1686,  693],
       [1048,  566, 1130,  636],
       [1092,  449, 1161,  503],
       [1223,  401, 1275,  443],
       [ 767,  489,  838,  549],
       [ 513,  464,  580,  511],
       [ 503,  351,  571,  411],
       [1036,  391, 1078,  426],
       [1094,  353, 1132,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10962.,  5893.,  3850.,  2279.,  4392.,  3264.,  4209.,  1548.,
        1833.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00008.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 686,  657,  805,  763],
       [1484,  568, 1603,  647],
       [1336,  470, 1413,  524],
       [ 444,  366,  527,  449],
       [ 611,  380,  653,  413],
       [ 986,  449, 1042,  493],
       [1040,  389, 1088,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12840.,  9600.,  4290.,  7056.,  1462.,  2565.,  2254.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00009.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 721,  403,  769,  445],
       [ 344,  409,  455,  514],
       [ 530,  436,  594,  480],
       [ 498,  388,  538,  422],
       [1298,  453, 1369,  509],
       [1221,  401, 1271,  445],
       [ 961,  391,  998,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 2107., 11872.,  2925.,  1435.,  4104.,  2295.,  1140.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00010.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 171,  466,  323,  613],
       [ 373,  530,  461,  595],
       [ 652,  486,  727,  549],
       [ 428,  422,  478,  466],
       [1198,  388, 1248,  434],
       [ 602,  359,  650,  397],
       [1146,  361, 1186,  393],
       [ 550,  355,  592,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22644.,  5874.,  4864.,  2295.,  2397.,  1911.,  1353.,  1763.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00011.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  732,  159,  855],
       [ 467,  668,  598,  791],
       [   2,  572,   96,  722],
       [ 315,  484,  386,  532],
       [ 546,  397,  602,  447],
       [ 517,  388,  550,  434],
       [1131,  359, 1179,  394]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19468., 16368., 14345.,  3528.,  2907.,  1598.,  1764.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00012.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1119,  782, 1257,  901],
       [ 125,  566,  223,  636],
       [ 453,  453,  523,  514],
       [ 463,  418,  513,  459],
       [ 505,  384,  546,  413],
       [ 732,  374,  769,  407],
       [ 815,  364,  853,  393],
       [ 677,  355,  715,  389]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16680.,  7029.,  4402.,  2142.,  1260.,  1292.,  1170.,  1365.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00013.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 255,  549,  373,  649],
       [1023,  538, 1098,  603],
       [ 817,  414,  861,  461],
       [ 380,  472,  450,  536],
       [ 432,  420,  484,  468],
       [ 694,  428,  750,  476],
       [ 634,  409,  678,  445],
       [ 521,  370,  563,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12019.,  5016.,  2160.,  4615.,  2597.,  2793.,  1665.,  1548.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00014.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 213,  572,  317,  655],
       [ 611,  520,  684,  595],
       [ 773,  505,  842,  564],
       [ 527,  501,  598,  557],
       [ 298,  488,  375,  543],
       [ 453,  401,  509,  443],
       [ 638,  399,  680,  430],
       [ 809,  401,  852,  430],
       [ 546,  366,  582,  401],
       [ 980,  434, 1034,  480]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([8820., 5624., 4200., 4104., 4368., 2451., 1376., 1320., 1332.,
       2585.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00015.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1480,  588, 1834,  893],
       [1111,  693, 1259,  816],
       [ 650,  716,  773,  834],
       [ 350,  749,  513,  899],
       [ 182,  722,  344,  843],
       [  32,  609,  159,  695],
       [ 350,  453,  423,  505],
       [ 563,  459,  628,  507],
       [ 784,  468,  844,  509],
       [ 482,  399,  534,  441],
       [ 728,  376,  777,  416],
       [ 959,  380,  992,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([108630.,  18476.,  14756.,  24764.,  19886.,  11136.,   3922.,
         3234.,   2562.,   2279.,   2050.,   1088.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00016.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1273,  447, 1444,  611],
       [ 703,  628,  803,  709],
       [1011,  495, 1086,  559],
       [ 411,  568,  500,  641],
       [ 167,  534,  269,  611],
       [ 377,  453,  450,  509],
       [ 686,  436,  744,  489],
       [ 732,  363,  775,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28380.,  8282.,  4940.,  6660.,  8034.,  4218.,  3186.,  1628.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00017.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  868,  161, 1028],
       [ 192,  539,  294,  609],
       [ 596,  541,  678,  622],
       [ 700,  413,  748,  461],
       [1161,  816, 1315,  951],
       [1328,  741, 1496,  891],
       [1532,  722, 1696,  824],
       [1169,  380, 1282,  501],
       [ 973,  407, 1025,  451],
       [ 663,  366,  700,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([25760.,  7313.,  6806.,  2401., 21080., 25519., 16995., 13908.,
        2385.,  1292.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00018.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 303,  809,  503,  989],
       [1302,  711, 1438,  816],
       [1469,  688, 1600,  766],
       [1878,  807, 1919,  889],
       [1296,  526, 1384,  589],
       [1144,  518, 1227,  591],
       [1034,  541, 1103,  599],
       [1105,  343, 1188,  434],
       [ 615,  493,  696,  561],
       [ 605,  403,  659,  449],
       [ 565,  393,  609,  437],
       [ 944,  361,  990,  391],
       [ 523,  366,  569,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([36381., 14522., 10428.,  3486.,  5696.,  6216.,  4130.,  7728.,
        5658.,  2585.,  2025.,  1457.,  1974.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00019.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 423,  666,  563,  797],
       [ 484,  478,  571,  543],
       [ 463,  399,  519,  439],
       [1127,  509, 1198,  568],
       [1457,  538, 1567,  622],
       [1255,  507, 1328,  564],
       [1178,  441, 1240,  480],
       [1069,  420, 1119,  468],
       [ 986,  432, 1030,  468],
       [1052,  320, 1127,  393],
       [ 671,  363,  711,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18612.,  5808.,  2337.,  4320.,  9435.,  4292.,  2520.,  2499.,
        1665.,  5624.,  1845.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00020.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 200,  632,  346,  747],
       [ 317,  549,  407,  613],
       [ 363,  447,  440,  507],
       [ 628,  409,  677,  449],
       [ 559,  401,  603,  432],
       [1369,  611, 1477,  693],
       [1290,  436, 1353,  495],
       [1150,  430, 1205,  470],
       [1057,  420, 1102,  455],
       [1109,  382, 1148,  416],
       [1013,  372, 1057,  399],
       [ 959,  366,  990,  412],
       [1017,  303, 1078,  366]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17052.,  5915.,  4758.,  2050.,  1440.,  9047.,  3840.,  2296.,
        1656.,  1400.,  1260.,  1504.,  3968.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00021.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1752,  716, 1919,  850],
       [   2,  770,   94,  889],
       [ 184,  520,  294,  611],
       [ 544,  466,  611,  534],
       [ 475,  455,  532,  501],
       [ 563,  403,  603,  436],
       [1200,  468, 1263,  518],
       [1186,  378, 1236,  420],
       [1092,  378, 1132,  409],
       [1011,  374, 1046,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22680., 11160., 10212.,  4692.,  2726.,  1394.,  3264.,  2193.,
        1312.,  1008.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00022.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 382,  576,  486,  678],
       [ 303,  555,  398,  620],
       [1275,  659, 1436,  784],
       [1436,  532, 1540,  609],
       [ 484,  449,  540,  499],
       [ 478,  384,  532,  436],
       [1113,  399, 1153,  434],
       [1115,  345, 1157,  380]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10815.,  6336., 20412.,  8190.,  2907.,  2915.,  1476.,  1548.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00023.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1417,  843, 1603,  980],
       [1028,  588, 1111,  653],
       [1132,  488, 1217,  563],
       [1292,  443, 1355,  497],
       [   0,  851,  159, 1043],
       [   0,  764,   75,  851],
       [ 325,  539,  415,  601],
       [ 373,  441,  442,  501]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([25806.,  5544.,  6536.,  3520., 30880.,  6688.,  5733.,  4270.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00024.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  728,  130,  847],
       [ 169,  526,  273,  620],
       [1180,  561, 1273,  630],
       [ 978,  447, 1036,  493],
       [1059,  409, 1123,  459],
       [1200,  388, 1255,  430],
       [ 577,  376,  619,  413],
       [ 665,  355,  703,  386]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15480.,  9975.,  6580.,  2773.,  3315.,  2408.,  1634.,  1248.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00025.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 503,  432,  559,  480],
       [ 638,  391,  677,  434],
       [ 728,  382,  769,  418],
       [ 594,  374,  628,  399],
       [1090,  451, 1152,  493],
       [ 952,  386,  986,  414],
       [1017,  366, 1059,  399],
       [1132,  355, 1173,  386],
       [ 807,  353,  848,  386]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([2793., 1760., 1554.,  910., 2709., 1015., 1462., 1344., 1428.],
      dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00026.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1294,  699, 1428,  791],
       [ 350,  522,  434,  584],
       [ 569,  445,  627,  499],
       [ 692,  426,  744,  482],
       [ 528,  422,  578,  455],
       [ 807,  397,  853,  439],
       [1040,  397, 1088,  434],
       [ 744,  353,  782,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12555.,  5355.,  3245.,  3021.,  1734.,  2021.,  1862.,  1833.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00027.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  732,  128,  857],
       [1342,  770, 1544,  930],
       [1044,  624, 1155,  711],
       [1484,  551, 1602,  636],
       [1140,  513, 1207,  563],
       [ 442,  534,  530,  611],
       [ 598,  518,  682,  591],
       [ 392,  501,  469,  555],
       [ 769,  476,  842,  539],
       [ 673,  468,  734,  511],
       [ 722,  392,  774,  450],
       [ 488,  403,  532,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16002., 32683.,  9856., 10234.,  3468.,  6942.,  6290.,  4290.,
        4736.,  2728.,  3127.,  1755.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00028.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 384,  713,  532,  859],
       [ 115,  736,  282,  876],
       [  65,  666,  209,  770],
       [ 680,  639,  798,  772],
       [ 569,  576,  661,  661],
       [ 298,  499,  371,  549],
       [ 678,  464,  761,  553],
       [1148,  532, 1244,  613],
       [ 994,  474, 1053,  522],
       [1305,  447, 1382,  501],
       [1065,  424, 1121,  466]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21903., 23688., 15225., 15946.,  7998.,  3774.,  7560.,  7954.,
        2940.,  4290.,  2451.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00029.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 236,  876,  442, 1043],
       [ 584,  624,  721,  795],
       [1640,  695, 1790,  780],
       [ 419,  418,  486,  470],
       [1069,  432, 1138,  488],
       [1205,  391, 1263,  432],
       [ 957,  399, 1009,  445],
       [1015,  372, 1061,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([34776., 23736., 12986.,  3604.,  3990.,  2478.,  2491.,  1692.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00030.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 234,  501,  325,  570],
       [1236,  655, 1359,  738],
       [1471,  657, 1655,  791],
       [1403,  528, 1488,  582],
       [1019,  382, 1071,  414],
       [ 738,  388,  773,  420],
       [ 650,  361,  692,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 6440., 10416., 24975.,  4730.,  1749.,  1188.,  2322.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00031.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1665,  795, 1919, 1011],
       [1650,  663, 1803,  757],
       [1273,  501, 1377,  591],
       [1094,  478, 1159,  532],
       [1280,  443, 1340,  484],
       [ 588,  411,  652,  480],
       [ 703,  439,  755,  480],
       [ 555,  363,  628,  428],
       [ 648,  395,  694,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([55335., 14630.,  9555.,  3630.,  2562.,  4550.,  2226.,  4884.,
        1974.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00032.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1355,  555, 1484,  672],
       [1396,  501, 1486,  557],
       [1171,  424, 1242,  486],
       [1203,  393, 1248,  430],
       [1025,  397, 1073,  434],
       [ 740,  378,  780,  411],
       [ 632,  526,  707,  582],
       [ 455,  503,  548,  593],
       [ 567,  459,  636,  518],
       [ 463,  409,  580,  491],
       [ 580,  370,  627,  422],
       [ 644,  395,  698,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15340.,  5187.,  4536.,  1748.,  1862.,  1394.,  4332.,  8554.,
        4200.,  9794.,  2544.,  2200.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00033.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  96,  688,  302,  880],
       [ 455,  705,  582,  813],
       [ 384,  580,  494,  678],
       [ 307,  457,  477,  605],
       [ 511,  413,  577,  476],
       [ 578,  451,  642,  511],
       [ 711,  438,  763,  482],
       [1500,  591, 1611,  663],
       [1215,  459, 1302,  532],
       [1267,  428, 1327,  474],
       [1105,  380, 1161,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([39951., 13952., 10989., 25479.,  4288.,  3965.,  2385.,  8176.,
        6512.,  2867.,  2907.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00034.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1490,  974, 1711, 1045],
       [1113,  789, 1248,  895],
       [1328,  476, 1403,  534],
       [1140,  397, 1203,  455],
       [   0,  564,  265,  838],
       [ 436,  551,  534,  636],
       [ 627,  545,  711,  613],
       [ 384,  484,  475,  566]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15984., 14552.,  4484.,  3776., 73150.,  8514.,  5865.,  7636.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00035.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 346,  822,  528,  972],
       [  69,  772,  255,  918],
       [ 100,  607,  261,  755],
       [1057,  664, 1188,  774],
       [1475,  672, 1657,  809],
       [1211,  607, 1311,  682],
       [1005,  522, 1073,  576],
       [1230,  414, 1284,  449],
       [1086,  363, 1138,  407],
       [ 505,  374,  550,  416],
       [ 584,  370,  634,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27633., 27489., 24138., 14652., 25254.,  7676.,  3795.,  1980.,
        2385.,  1978.,  2142.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00036.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1150,  853, 1371, 1045],
       [1442,  878, 1646, 1018],
       [1477,  691, 1628,  784],
       [1496,  507, 1671,  659],
       [1269,  507, 1367,  586],
       [ 994,  489, 1065,  553],
       [1100,  474, 1169,  528],
       [ 959,  422, 1005,  455],
       [ 411,  426,  475,  474],
       [ 534,  407,  600,  451],
       [ 805,  361,  846,  399],
       [1161,  376, 1207,  405],
       [1042,  336, 1088,  374],
       [ 544,  320,  598,  386]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([42846., 28905., 14288., 26928.,  7920.,  4680.,  3850.,  1598.,
        3185.,  3015.,  1638.,  1410.,  1833.,  3685.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00037.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1021,  543, 1121,  632],
       [1192,  574, 1288,  641],
       [1263,  520, 1346,  570],
       [1315,  422, 1430,  526],
       [1169,  420, 1234,  476],
       [ 963,  413, 1015,  459],
       [1046,  409, 1096,  447],
       [ 794,  416,  848,  461],
       [ 230,  505,  327,  572],
       [ 444,  455,  527,  518],
       [ 486,  341,  559,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9090.,  6596.,  4284., 12180.,  3762.,  2491.,  1989.,  2530.,
        6664.,  5376.,  6068.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00038.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1157,  861, 1327,  999],
       [1605,  807, 1792,  930],
       [1536,  599, 1661,  676],
       [1315,  736, 1453,  843],
       [ 748,  514,  827,  586],
       [ 294,  530,  411,  620],
       [ 388,  376,  488,  480],
       [1090,  459, 1155,  509],
       [ 986,  436, 1040,  488],
       [1167,  428, 1217,  476],
       [1232,  370, 1300,  449],
       [1113,  376, 1165,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([23769., 23312.,  9828., 15012.,  5840., 10738., 10605.,  3366.,
        2915.,  2499.,  5520.,  2385.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00039.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 603,  772,  765,  945],
       [   0,  613,  223,  828],
       [ 213,  434,  363,  582],
       [1390,  861, 1582, 1005],
       [1650,  826, 1853,  968],
       [1659,  661, 1848,  788],
       [1332,  578, 1434,  649],
       [1148,  532, 1225,  593],
       [1038,  555, 1115,  620],
       [1342,  476, 1409,  514]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28362., 48384., 22499., 27985., 29172., 24320.,  7416.,  4836.,
        5148.,  2652.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00040.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  538,  107,  749],
       [1563,  618, 1688,  695],
       [1361,  584, 1465,  661],
       [1163,  574, 1259,  641],
       [1388,  505, 1496,  580],
       [1207,  472, 1275,  520],
       [1075,  445, 1132,  489],
       [ 984,  445, 1042,  488],
       [1230,  413, 1286,  449],
       [ 528,  413,  580,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22896.,  9828.,  8190.,  6596.,  8284.,  3381.,  2610.,  2596.,
        2109.,  2756.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00041.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 421,  472,  494,  522],
       [ 461,  399,  517,  447],
       [ 575,  378,  621,  413],
       [ 734,  376,  773,  413],
       [1077,  455, 1148,  503],
       [1223,  476, 1294,  534],
       [1350,  480, 1430,  528],
       [1252,  420, 1327,  470],
       [1127,  413, 1180,  449],
       [ 953,  386,  992,  414],
       [1028,  391, 1071,  424],
       [1159,  370, 1202,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([3774., 2793., 1692., 1520., 3528., 4248., 3969., 3876., 1998.,
       1160., 1496., 1672.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00042.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 225,  580,  334,  668],
       [1509,  574, 1619,  655],
       [1238,  413, 1288,  455],
       [1148,  414, 1198,  453],
       [1038,  401, 1077,  438],
       [1165,  374, 1221,  414],
       [ 693,  428,  741,  472],
       [ 346,  451,  427,  513],
       [ 494,  416,  548,  463],
       [ 602,  370,  642,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([9790., 9102., 2193., 2040., 1520., 2337., 2205., 5166., 2640.,
       1394.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00043.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 150,  536,  265,  626],
       [ 613,  532,  690,  589],
       [ 359,  476,  434,  541],
       [ 413,  432,  469,  474],
       [ 555,  409,  605,  441],
       [1292,  705, 1436,  818],
       [1517,  572, 1621,  645],
       [1338,  470, 1411,  524],
       [ 800,  374,  838,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10556.,  4524.,  5016.,  2451.,  1683., 16530.,  7770.,  4070.,
        1404.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00044.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 375,  772,  527,  897],
       [  96,  582,  213,  674],
       [ 275,  493,  359,  557],
       [ 469,  466,  530,  511],
       [ 790,  424,  838,  472],
       [1140,  514, 1223,  586],
       [1521,  568, 1640,  657],
       [1342,  466, 1409,  518],
       [1228,  414, 1290,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19278., 10974.,  5525.,  2852.,  2401.,  6132., 10800.,  3604.,
        2520.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00045.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  25,  597,  150,  693],
       [ 311,  557,  400,  624],
       [ 742,  522,  819,  588],
       [ 478,  380,  532,  438],
       [1590,  782, 1786,  920],
       [1342,  463, 1417,  522],
       [1067,  430, 1130,  478],
       [1244,  403, 1288,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12222.,  6120.,  5226.,  3245., 27383.,  4560.,  3136.,  2115.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00046.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 611,  743,  753,  889],
       [   2,  753,  119,  864],
       [ 380,  422,  452,  495],
       [ 525,  380,  567,  413],
       [ 736,  372,  775,  409],
       [1644,  807, 1838,  926],
       [1313,  553, 1413,  628],
       [1236,  397, 1290,  441],
       [1021,  376, 1067,  418],
       [1173,  370, 1215,  405],
       [ 602,  359,  644,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21021., 13216.,  5402.,  1462.,  1520., 23400.,  7676.,  2475.,
        2021.,  1548.,  1763.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00047.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 202,  491,  315,  603],
       [ 700,  418,  755,  463],
       [ 467,  413,  513,  451],
       [ 555,  399,  605,  434],
       [1273,  678, 1392,  766],
       [1340,  570, 1434,  630],
       [1188,  453, 1255,  501],
       [1165,  361, 1213,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12882.,  2576.,  1833.,  1836., 10680.,  5795.,  3332.,  2107.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00048.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1857,  814, 1919,  907],
       [1442,  678, 1586,  770],
       [1132,  513, 1200,  566],
       [1207,  461, 1277,  507],
       [ 621,  507,  703,  570],
       [ 473,  443,  544,  499],
       [ 369,  463,  428,  507],
       [ 638,  411,  682,  447],
       [ 584,  386,  630,  426],
       [1121,  399, 1169,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 5922., 13485.,  3726.,  3337.,  5312.,  4104.,  2700.,  1665.,
        1927.,  2107.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00049.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 411,  714,  567,  845],
       [ 225,  528,  302,  593],
       [ 327,  522,  419,  599],
       [ 571,  468,  628,  518],
       [ 509,  436,  569,  489],
       [1555,  751, 1725,  853],
       [1480,  578, 1592,  645],
       [1252,  511, 1336,  570],
       [1067,  430, 1115,  470],
       [1134,  399, 1182,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20724.,  5148.,  7254.,  2958.,  3294., 17613.,  7684.,  5100.,
        2009.,  2009.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00050.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1661,  807, 1907,  989],
       [1267,  664, 1403,  788],
       [1609,  641, 1752,  730],
       [1303,  549, 1398,  613],
       [1317,  470, 1386,  512],
       [1152,  428, 1213,  474],
       [   5,  668,  175,  793],
       [ 425,  572,  519,  645],
       [ 355,  520,  440,  593],
       [ 607,  403,  667,  463],
       [ 734,  401,  777,  439],
       [1021,  384, 1059,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([45201., 17125., 12960.,  6240.,  3010.,  2914., 21546.,  7030.,
        6364.,  3721.,  1716.,  1170.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00051.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  78,  801,  255,  938],
       [  25,  682,  177,  813],
       [ 511,  464,  596,  543],
       [ 680,  464,  742,  516],
       [ 652,  389,  694,  424],
       [1282,  711, 1407,  795],
       [1342,  566, 1461,  653],
       [1521,  599, 1634,  674],
       [1123,  503, 1209,  570],
       [1378,  499, 1465,  553],
       [1190,  455, 1257,  499],
       [1211,  405, 1269,  447],
       [1092,  384, 1140,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24564., 20196.,  6880.,  3339.,  1548., 10710., 10560.,  8664.,
        5916.,  4840.,  3060.,  2537.,  1813.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00052.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1250,  668, 1375,  763],
       [1136,  530, 1209,  580],
       [1205,  459, 1284,  518],
       [1334,  482, 1402,  530],
       [1259,  426, 1321,  464],
       [1055,  424, 1113,  468],
       [1117,  393, 1173,  430],
       [ 315,  586,  453,  716],
       [ 559,  578,  661,  661],
       [ 588,  445,  648,  488]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12096.,  3774.,  4800.,  3381.,  2457.,  2655.,  2166., 18209.,
        8652.,  2684.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00053.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 244,  878,  450, 1043],
       [ 455,  536,  548,  597],
       [1830,  961, 1919, 1048],
       [1415,  651, 1542,  732],
       [1127,  509, 1200,  564],
       [1065,  443, 1119,  480],
       [1230,  411, 1282,  455],
       [1128,  399, 1186,  441],
       [ 805,  397,  859,  443],
       [ 627,  395,  675,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([34362.,  5828.,  7920., 10496.,  4144.,  2090.,  2385.,  2537.,
        2585.,  2058.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00054.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 167,  724,  327,  839],
       [1594,  780, 1778,  905],
       [1400,  616, 1513,  697],
       [1234,  497, 1311,  547],
       [ 780,  461,  855,  528],
       [ 686,  455,  748,  505],
       [ 548,  457,  619,  511],
       [ 532,  413,  582,  463],
       [ 713,  411,  757,  449],
       [1063,  428, 1117,  472]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18676., 23310.,  9348.,  3978.,  5168.,  3213.,  3960.,  2601.,
        1755.,  2475.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00055.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 713,  603,  830,  705],
       [ 592,  564,  678,  634],
       [ 375,  561,  486,  661],
       [ 417,  484,  494,  545],
       [ 657,  484,  723,  538],
       [1855,  774, 1919,  887],
       [1325,  555, 1421,  630],
       [1230,  484, 1305,  541],
       [1144,  424, 1196,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12154.,  6177., 11312.,  4836.,  3685.,  7410.,  7372.,  4408.,
        1802.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00056.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  828,  146, 1045],
       [ 325,  828,  498,  988],
       [ 528,  624,  632,  713],
       [ 186,  605,  311,  709],
       [1346,  759, 1494,  880],
       [1513,  716, 1665,  820],
       [1480,  503, 1636,  649],
       [1200,  453, 1263,  505],
       [1144,  411, 1202,  457],
       [ 448,  418,  505,  463]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([32046., 28014.,  9450., 13230., 18178., 16065., 23079.,  3392.,
        2773.,  2668.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00057.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1802,  970, 1919, 1044],
       [1302,  763, 1452,  870],
       [1486,  713, 1648,  826],
       [1584,  616, 1734,  720],
       [1305,  543, 1388,  601],
       [1163,  549, 1246,  603],
       [1313,  416, 1411,  514],
       [1130,  401, 1182,  439],
       [ 311,  482,  390,  541],
       [ 490,  391,  536,  426],
       [1086,  370, 1132,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 8850., 16308., 18582., 15855.,  4956.,  4620.,  9801.,  2067.,
        4800.,  1692.,  1692.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00058.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1330,  764, 1496,  893],
       [1428,  653, 1540,  738],
       [1298,  553, 1396,  622],
       [1384,  499, 1478,  563],
       [1144,  543, 1230,  605],
       [1194,  454, 1265,  500],
       [1084,  445, 1138,  489],
       [1213,  363, 1288,  441],
       [  40,  607,  167,  686],
       [ 405,  438,  463,  476],
       [ 580,  380,  627,  418],
       [ 502,  391,  542,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21710.,  9718.,  6930.,  6175.,  5481.,  3384.,  2475.,  6004.,
       10240.,  2301.,  1872.,  1312.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00059.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1157,  874, 1405, 1043],
       [1840,  970, 1919, 1043],
       [1571,  614, 1711,  714],
       [1146,  545, 1238,  614],
       [1271,  522, 1350,  574],
       [1205,  468, 1273,  522],
       [1265,  428, 1328,  476],
       [1073,  449, 1127,  497],
       [1130,  403, 1177,  441],
       [ 244,  516,  328,  568],
       [ 417,  430,  471,  476],
       [ 494,  436,  553,  478],
       [1036,  388, 1077,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([42330.,  5920., 14241.,  6510.,  4240.,  3795.,  3136.,  2695.,
        1872.,  4505.,  2585.,  2580.,  1890.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00060.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1600,  645, 1725,  732],
       [1442,  641, 1571,  732],
       [1013,  536, 1121,  649],
       [1373,  497, 1461,  563],
       [1190,  453, 1248,  497],
       [1073,  449, 1138,  499],
       [1146,  413, 1198,  457],
       [ 327,  528,  421,  603],
       [   0,  661,   53,  759],
       [ 284,  503,  355,  555],
       [ 455,  403,  511,  449],
       [1027,  395, 1069,  434],
       [1194,  388, 1236,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11088., 11960., 12426.,  5963.,  2655.,  3366.,  2385.,  7220.,
        5346.,  3816.,  2679.,  1720.,  1763.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00001.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1457,  909, 1682, 1041],
       [1717,  709, 1882,  811],
       [1250,  641, 1359,  716],
       [1148,  464, 1211,  511],
       [ 686,  622,  798,  709],
       [ 596,  522,  688,  622],
       [ 480,  528,  563,  586],
       [ 384,  503,  461,  568],
       [ 544,  397,  596,  439],
       [ 723,  405,  765,  441],
       [1138,  403, 1177,  441],
       [1227,  405, 1284,  447],
       [1182,  432, 1234,  474],
       [ 663,  382,  705,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([30058., 17098.,  8360.,  3072.,  9944.,  9393.,  4956.,  5148.,
        2279.,  1591.,  1560.,  2494.,  2279.,  1591.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00002.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1509,  978, 1763, 1038],
       [ 344,  738,  534,  951],
       [ 129,  767,  297,  892],
       [  59,  666,  211,  778],
       [ 661,  480,  725,  536],
       [ 442,  461,  513,  522],
       [ 600,  438,  659,  489],
       [ 796,  441,  852,  482],
       [1202,  591, 1305,  676],
       [1419,  522, 1503,  582],
       [1125,  488, 1190,  534],
       [1067,  401, 1111,  439],
       [ 802,  378,  846,  413],
       [1128,  389, 1169,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([15555., 40874., 21294., 17289.,  3705.,  4464.,  3120.,  2394.,
        8944.,  5185.,  3102.,  1755.,  1620.,  1428.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00003.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 503,  638,  609,  738],
       [ 215,  582,  334,  666],
       [ 453,  541,  550,  622],
       [ 750,  559,  827,  634],
       [1203,  599, 1327,  699],
       [1104,  470, 1173,  528],
       [1269,  428, 1334,  470],
       [ 778,  434,  842,  495],
       [1065,  416, 1111,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10807., 10200.,  8036.,  5928., 12625.,  4130.,  2838.,  4030.,
        1880.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00004.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  40,  799,  244,  980],
       [ 552,  922,  734, 1045],
       [1392,  866, 1586, 1001],
       [1842,  803, 1919,  914],
       [ 707,  559,  805,  655],
       [1100,  472, 1175,  534],
       [ 440,  424,  492,  464],
       [1046,  409, 1094,  445],
       [ 723,  393,  763,  432],
       [1177,  380, 1227,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([37310., 22692., 26520.,  8736.,  9603.,  4788.,  2173.,  1813.,
        1640.,  1887.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00005.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 473,  939,  694, 1047],
       [ 315,  491,  386,  547],
       [1486,  934, 1748, 1043],
       [1807,  963, 1919, 1045],
       [1461,  559, 1561,  626],
       [ 673,  463,  730,  509],
       [1163,  559, 1250,  628],
       [1044,  409, 1098,  451],
       [ 721,  407,  769,  443],
       [ 540,  374,  586,  407],
       [1007,  366, 1046,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24198.,  4104., 28930.,  9379.,  6868.,  2726.,  6160.,  2365.,
        1813.,  1598.,  1200.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00006.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  92,  595,  205,  676],
       [ 571,  580,  653,  651],
       [ 667,  474,  736,  528],
       [ 471,  409,  523,  449],
       [1513,  995, 1707, 1047],
       [1423,  638, 1552,  714],
       [1507,  568, 1636,  664],
       [1203,  586, 1317,  672],
       [1298,  457, 1359,  503],
       [ 717,  389,  769,  428],
       [1078,  455, 1140,  499],
       [1009,  364, 1057,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9348.,  5976.,  3850.,  2173., 10335., 10010., 12610., 10005.,
        2914.,  2120.,  2835.,  2058.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00007.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 223,  916,  415, 1047],
       [ 536,  614,  648,  707],
       [ 353,  472,  423,  524],
       [ 640,  453,  709,  505],
       [ 723,  372,  767,  414],
       [1473,  668, 1615,  774],
       [1200,  599, 1294,  672],
       [1273,  503, 1350,  557],
       [1311,  451, 1392,  514],
       [1100,  457, 1175,  514],
       [1194,  397, 1242,  432],
       [1030,  395, 1073,  424]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([25476., 10622.,  3763.,  3710.,  1935., 15301.,  7030.,  4290.,
        5248.,  4408.,  1764.,  1320.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00008.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1330,  761, 1492,  893],
       [1538,  601, 1659,  678],
       [ 448,  580,  563,  678],
       [ 136,  572,  248,  638],
       [1278,  514, 1363,  580],
       [1098,  466, 1157,  511],
       [1192,  430, 1248,  468],
       [ 688,  422,  746,  472],
       [ 640,  405,  684,  443],
       [1044,  391, 1096,  438],
       [ 575,  374,  621,  418],
       [1203,  391, 1261,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21679.,  9516., 11484.,  7571.,  5762.,  2760.,  2223.,  3009.,
        1755.,  2544.,  2115.,  2478.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00009.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1148,  528, 1228,  601],
       [1644,  628, 1823,  757],
       [ 609,  511,  694,  582],
       [ 542,  482,  607,  538],
       [ 492,  420,  561,  482],
       [ 425,  424,  480,  461],
       [1342,  480, 1415,  530],
       [1173,  432, 1234,  482],
       [ 719,  399,  765,  434],
       [1042,  403, 1080,  430],
       [1144,  380, 1190,  414],
       [ 659,  351,  711,  403],
       [   0,  989,   86, 1045]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 5994., 23400.,  6192.,  3762.,  4410.,  2128.,  3774.,  3162.,
        1692.,  1092.,  1645.,  2809.,  4959.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00010.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 394,  713,  552,  853],
       [ 284,  647,  409,  749],
       [1311,  751, 1461,  857],
       [1396,  489, 1655,  722],
       [1069,  428, 1123,  476],
       [1232,  413, 1288,  451],
       [1105,  382, 1152,  418],
       [ 661,  480,  723,  522],
       [ 328,  505,  432,  597],
       [ 252,  514,  330,  564],
       [ 623,  384,  688,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22419., 12978., 16157., 60840.,  2695.,  2223.,  1776.,  2709.,
        9765.,  4029.,  4356.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00011.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  668,  144,  820],
       [ 498,  632,  611,  724],
       [ 552,  432,  644,  516],
       [1103,  788, 1252,  905],
       [1428,  895, 1636, 1038],
       [1140,  530, 1215,  589],
       [1205,  407, 1334,  530]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22185., 10602.,  7905., 17700., 30096.,  4560., 16120.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00012.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 415,  503,  552,  622],
       [1178,  570, 1271,  638],
       [1003,  526, 1077,  580],
       [1071,  432, 1121,  478],
       [1109,  347, 1188,  439],
       [1198,  376, 1248,  424],
       [ 467,  403,  515,  438],
       [ 571,  378,  613,  422],
       [ 653,  368,  698,  413],
       [ 736,  388,  771,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16560.,  6486.,  4125.,  2397.,  7440.,  2499.,  1764.,  1935.,
        2116.,  1044.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00013.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 123,  663,  352,  855],
       [ 353,  459,  419,  514],
       [ 494,  434,  557,  482],
       [ 602,  413,  659,  474],
       [ 694,  443,  748,  488],
       [ 969,  424, 1017,  463],
       [1084,  447, 1136,  488],
       [1050,  320, 1113,  384],
       [1130,  349, 1177,  382],
       [1023,  384, 1059,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([44390.,  3752.,  3136.,  3596.,  2530.,  1960.,  2226.,  4160.,
        1632.,  1036.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00014.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 136,  559,  240,  639],
       [ 342,  514,  438,  593],
       [ 494,  484,  586,  574],
       [ 600,  551,  684,  620],
       [1027,  593, 1111,  651],
       [1202,  597, 1303,  670],
       [1536,  611, 1655,  686],
       [ 492,  389,  542,  424],
       [1028,  389, 1067,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([8505., 7760., 8463., 5950., 5015., 7548., 9120., 1836., 1360.],
      dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00015.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 336,  826,  509,  976],
       [ 263,  628,  413,  776],
       [   2,  686,  169,  830],
       [ 255,  576,  355,  649],
       [ 402,  441,  463,  486],
       [ 621,  420,  677,  461],
       [ 553,  384,  607,  422],
       [1478,  664, 1621,  774],
       [1338,  478, 1407,  524],
       [1094,  463, 1153,  511],
       [ 978,  461, 1034,  497]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([26274., 22499., 24360.,  7474.,  2852.,  2394.,  2145., 15984.,
        3290.,  2940.,  2109.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00016.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1473,  909, 1711, 1041],
       [1552,  757, 1725,  866],
       [1744,  724, 1913,  818],
       [1517,  582, 1619,  649],
       [1269,  501, 1346,  557],
       [1227,  409, 1271,  449],
       [1036,  393, 1078,  424],
       [ 950,  389,  990,  420],
       [ 530,  491,  602,  545],
       [ 467,  439,  538,  499],
       [ 238,  518,  323,  576],
       [ 586,  380,  628,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([31787., 19140., 16150.,  7004.,  4446.,  1845.,  1376.,  1312.,
        4015.,  4392.,  5074.,  1462.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00017.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   1,  668,   42,  778],
       [ 323,  636,  442,  726],
       [ 284,  532,  398,  618],
       [ 519,  428,  580,  468],
       [ 471,  399,  517,  436],
       [1194,  576, 1294,  655],
       [1459,  547, 1552,  611],
       [1288,  538, 1377,  601],
       [1344,  476, 1411,  522],
       [1163,  418, 1221,  461]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4662., 10920., 10005.,  2542.,  1786.,  8080.,  6110.,  5760.,
        3196.,  2596.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00018.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  745,   77,  884],
       [1155,  813, 1652, 1045],
       [1225,  630, 1338,  711],
       [1088,  453, 1152,  509],
       [1169,  439, 1232,  486],
       [1315,  461, 1384,  505],
       [ 390,  507,  482,  572],
       [ 355,  459,  421,  505],
       [ 498,  391,  538,  420],
       [ 665,  378,  703,  407],
       [1096,  370, 1136,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 10920., 116034.,   9348.,   3705.,   3072.,   3150.,   6138.,
         3149.,   1230.,   1170.,   1312.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00019.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  90,  659,  242,  768],
       [ 125,  564,  228,  630],
       [1444,  897, 1653, 1036],
       [1021,  505, 1196,  722],
       [1205,  589, 1323,  684],
       [1228,  399, 1282,  441],
       [ 398,  436,  463,  476],
       [ 615,  422,  665,  463],
       [1032,  389, 1077,  430],
       [1100,  386, 1146,  418],
       [1178,  376, 1223,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16830.,  6968., 29400., 38368., 11424.,  2365.,  2706.,  2142.,
        1932.,  1551.,  1564.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00020.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1638,  788, 1825,  916],
       [1182,  572, 1280,  649],
       [ 977,  405, 1084,  547],
       [1107,  464, 1175,  522],
       [ 527,  497,  596,  547],
       [ 232,  518,  317,  564],
       [ 715,  374,  763,  426],
       [ 602,  357,  650,  397],
       [1167,  372, 1207,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24252.,  7722., 15444.,  4071.,  3570.,  4042.,  2597.,  2009.,
        1312.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00021.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1473,  922, 1703, 1043],
       [1363,  570, 1457,  647],
       [1084,  450, 1148,  504],
       [ 953,  353, 1028,  457],
       [1048,  395, 1102,  436],
       [ 661,  426,  732,  511],
       [ 317,  636,  434,  724],
       [ 542,  395,  605,  445],
       [ 805,  353,  850,  401],
       [ 592,  376,  630,  403],
       [   0,  659,   36,  749],
       [ 540,  363,  580,  393]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28182.,  7410.,  3575.,  7980.,  2310.,  6192., 10502.,  3264.,
        2254.,  1092.,  3367.,  1271.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00022.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1630,  826, 1832,  955],
       [1182,  572, 1284,  651],
       [1228,  470, 1294,  524],
       [1036,  393, 1077,  426],
       [ 927,  322,  990,  403],
       [1011,  359, 1046,  388],
       [ 532,  532,  655,  674],
       [ 792,  403,  853,  470],
       [ 442,  447,  538,  520],
       [ 530,  416,  582,  455],
       [ 480,  397,  527,  438],
       [ 550,  355,  592,  391],
       [ 690,  345,  725,  374]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([26390.,  8240.,  3685.,  1428.,  5248.,  1080., 17732.,  4216.,
        7178.,  2120.,  2016.,  1591.,  1080.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00023.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1111,  770, 1271,  922],
       [1502,  695, 1652,  793],
       [1521,  591, 1630,  666],
       [1328,  576, 1427,  638],
       [1088,  451, 1148,  503],
       [1146,  411, 1198,  453],
       [ 123,  855,  398, 1045],
       [ 244,  545,  398,  655],
       [ 748,  493,  838,  599],
       [ 428,  482,  496,  536],
       [ 367,  457,  427,  511],
       [ 498,  384,  548,  434],
       [ 657,  386,  700,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24633., 14949.,  8360.,  6300.,  3233.,  2279., 52716., 17205.,
        9737.,  3795.,  3355.,  2601.,  1628.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00024.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 598,  732,  778,  968],
       [   0,  747,   98,  922],
       [ 212,  607,  325,  695],
       [ 128,  572,  234,  645],
       [ 398,  432,  471,  489],
       [ 575,  461,  636,  509],
       [1011,  516, 1094,  589],
       [1827,  791, 1919,  902],
       [1432,  647, 1563,  738],
       [1284,  524, 1367,  580],
       [1344,  482, 1413,  530],
       [1196,  464, 1263,  513],
       [1094,  374, 1136,  411],
       [1030,  388, 1077,  426],
       [ 509,  389,  555,  418],
       [ 594,  338,  644,  407],
       [ 732,  368,  773,  397],
       [ 805,  372,  842,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([42897., 17424., 10146.,  7918.,  4292.,  3038.,  6216., 10416.,
       12144.,  4788.,  3430.,  3400.,  1634.,  1872.,  1410.,  3570.,
        1260.,  1520.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00025.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1609,  834, 1790,  938],
       [1478,  574, 1586,  641],
       [1255,  503, 1340,  563],
       [1167,  441, 1230,  484],
       [ 969,  418, 1021,  466],
       [1246,  418, 1296,  459],
       [1125,  405, 1175,  439],
       [ 348,  626,  469,  718],
       [ 213,  518,  325,  599],
       [ 423,  434,  484,  478],
       [ 530,  370,  603,  457],
       [ 694,  420,  748,  468],
       [ 790,  428,  840,  474]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19110.,  7412.,  5246.,  2816.,  2597.,  2142.,  1785., 11346.,
        9266.,  2790.,  6512.,  2695.,  2397.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00026.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1532,  732, 1698,  838],
       [1523,  553, 1723,  707],
       [1317,  574, 1411,  638],
       [1323,  468, 1390,  518],
       [1165,  428, 1221,  466],
       [ 748,  528,  825,  595],
       [ 594,  532,  678,  607],
       [ 398,  426,  511,  549],
       [ 263,  516,  344,  570],
       [1092,  391, 1138,  426],
       [1169,  380, 1219,  413],
       [ 536,  366,  580,  405],
       [ 936,  368,  977,  405],
       [1073,  372, 1111,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([17869., 31155.,  6175.,  3468.,  2223.,  5304.,  6460., 14136.,
        4510.,  1692.,  1734.,  1800.,  1596.,  1092.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00027.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1665,  851, 1886, 1014],
       [1294,  534, 1386,  603],
       [1338,  451, 1465,  557],
       [1196,  466, 1255,  505],
       [1221,  411, 1275,  443],
       [1103,  378, 1148,  411],
       [ 619,  766,  769,  909],
       [ 227,  861,  428, 1041],
       [ 119,  532,  323,  724],
       [   2,  664,   52,  774],
       [ 463,  407,  521,  453],
       [ 798,  389,  842,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([36408.,  6510., 13696.,  2400.,  1815.,  1564., 21744., 36562.,
       39565.,  5661.,  2773.,  1440.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00028.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1832,  795, 1919,  910],
       [1544,  588, 1665,  672],
       [1344,  574, 1444,  661],
       [1177,  443, 1240,  491],
       [1238,  391, 1328,  468],
       [1128,  403, 1171,  436],
       [ 780,  453,  838,  495],
       [ 332,  470,  413,  536],
       [ 644,  397,  690,  432],
       [ 807,  386,  848,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10208., 10370.,  8888.,  3136.,  7098.,  1496.,  2537.,  5494.,
        1692.,  1554.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00029.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  67,  584,  196,  676],
       [ 705,  578,  798,  653],
       [ 786,  451,  846,  511],
       [ 573,  445,  634,  505],
       [ 657,  384,  698,  424],
       [ 727,  399,  769,  432],
       [1803,  768, 1919,  878],
       [1488,  574, 1588,  645],
       [1361,  472, 1436,  534],
       [1207,  466, 1275,  516],
       [1171,  357, 1238,  420],
       [1107,  389, 1150,  426],
       [ 819,  374,  857,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12090.,  7144.,  3721.,  3782.,  1722.,  1462., 12987.,  7272.,
        4788.,  3519.,  4352.,  1672.,  1248.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00030.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 453,  991,  642, 1045],
       [ 728,  580,  823,  674],
       [ 430,  547,  525,  624],
       [ 678,  459,  734,  511],
       [ 600,  439,  653,  491],
       [ 813,  422,  859,  464],
       [1482,  566, 1584,  632],
       [1328,  470, 1390,  520],
       [1248,  413, 1313,  459],
       [1127,  401, 1173,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10450.,  9120.,  7488.,  3021.,  2862.,  2021.,  6901.,  3213.,
        3102.,  2021.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00031.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  67,  757,  257,  914],
       [ 552,  993,  715, 1049],
       [1555,  607, 1688,  693],
       [1323,  468, 1390,  516],
       [1230,  411, 1284,  445],
       [ 561,  586,  653,  664],
       [ 482,  526,  563,  597],
       [ 778,  518,  852,  580],
       [ 800,  424,  850,  472],
       [ 648,  413,  688,  443],
       [1182,  372, 1228,  407],
       [1075,  363, 1115,  395],
       [ 744,  345,  778,  378]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([30178.,  9348., 11658.,  3332.,  1925.,  7347.,  5904.,  4725.,
        2499.,  1271.,  1692.,  1353.,  1190.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00032.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 178,  961,  392, 1043],
       [ 659,  745,  794,  868],
       [ 198,  711,  357,  843],
       [ 759,  520,  834,  591],
       [ 559,  480,  625,  532],
       [1730,  861, 1917, 1043],
       [1361,  484, 1440,  545],
       [1232,  411, 1280,  447],
       [ 728,  382,  775,  426],
       [ 569,  395,  619,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17845., 16864., 21280.,  5472.,  3551., 34404.,  4960.,  1813.,
        2160.,  1632.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00033.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 630,  759,  771,  895],
       [ 377,  611,  486,  699],
       [ 484,  453,  546,  488],
       [ 678,  439,  744,  501],
       [ 803,  428,  848,  466],
       [ 817,  368,  855,  401],
       [1357,  568, 1467,  664],
       [1248,  413, 1307,  461],
       [1163,  374, 1207,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19454.,  9790.,  2268.,  4221.,  1794.,  1326., 10767.,  2940.,
        1530.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00034.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  995,   65, 1047],
       [ 311,  551,  407,  613],
       [ 571,  547,  671,  639],
       [ 771,  522,  846,  589],
       [ 803,  420,  859,  463],
       [1538,  764, 1717,  882],
       [1588,  634, 1723,  713],
       [1211,  455, 1280,  514],
       [1180,  374, 1230,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 3498.,  6111.,  9393.,  5168.,  2508., 21420., 10880.,  4200.,
        1938.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00035.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  786,   67,  907],
       [ 234,  834,  455, 1045],
       [ 657,  759,  794,  905],
       [1269, 1026, 1436, 1045],
       [1367,  811, 1528,  930],
       [1786,  968, 1919, 1044],
       [1857,  797, 1915,  889],
       [1234,  524, 1319,  582],
       [1382,  505, 1467,  559],
       [ 767,  518,  838,  580],
       [1127,  389, 1180,  436],
       [1127,  349, 1163,  376],
       [ 744,  374,  777,  405],
       [ 817,  370,  848,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 8296., 47064., 20286.,  3360., 19440., 10318.,  5487.,  5074.,
        4730.,  4536.,  2592.,  1036.,  1088.,  1024.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00036.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 640,  755,  777,  891],
       [1030,  584, 1142,  684],
       [ 709,  424,  757,  463],
       [ 803,  420,  850,  455],
       [1363,  607, 1469,  676],
       [1507,  576, 1611,  643],
       [1275,  430, 1336,  476],
       [1105,  424, 1163,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18906., 11413.,  1960.,  1728.,  7490.,  7140.,  2914.,  2419.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00037.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1567,  747, 1742,  855],
       [1498,  568, 1607,  643],
       [1338,  476, 1405,  520],
       [1209,  472, 1273,  518],
       [ 980,  453, 1050,  511],
       [1075,  434, 1123,  478],
       [ 767,  509,  834,  566],
       [ 638,  499,  702,  561],
       [ 792,  407,  848,  461],
       [1196,  388, 1242,  422],
       [1025,  368, 1071,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19184.,  8360.,  3060.,  3055.,  4189.,  2205.,  3944.,  4095.,
        3135.,  1645.,  1786.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00038.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 655,  724,  782,  843],
       [ 473,  661,  582,  763],
       [ 746,  489,  821,  566],
       [1305,  536, 1394,  599],
       [1319,  457, 1394,  514],
       [1234,  416, 1288,  453],
       [1123,  403, 1169,  438],
       [ 640,  395,  692,  443],
       [ 721,  382,  765,  420],
       [ 959,  391, 1002,  432],
       [1027,  376, 1067,  413],
       [1136,  357, 1173,  388],
       [ 805,  347,  846,  382]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15360., 11330.,  5928.,  5760.,  4408.,  2090.,  1692.,  2597.,
        1755.,  1848.,  1558.,  1216.,  1512.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00039.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 628,  666,  757,  814],
       [1302,  695, 1480,  841],
       [1546,  607, 1663,  684],
       [1188,  447, 1252,  493],
       [1223,  401, 1277,  443],
       [ 567,  457,  636,  520],
       [ 667,  432,  723,  482],
       [ 803,  384,  850,  426],
       [1167,  378, 1205,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19370., 26313.,  9204.,  3055.,  2365.,  4480.,  2907.,  2064.,
        1248.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00040.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 382,  576,  502,  682],
       [ 552,  511,  628,  578],
       [ 778,  445,  840,  516],
       [1125,  493, 1217,  578],
       [1338,  474, 1402,  524],
       [ 582,  368,  638,  416],
       [ 732,  382,  775,  422],
       [1113,  389, 1155,  424],
       [1157,  364, 1203,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12947.,  5236.,  4536.,  7998.,  3315.,  2793.,  1804.,  1548.,
        1880.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00041.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  941,   69, 1045],
       [ 278,  676,  421,  814],
       [ 702,  584,  809,  705],
       [ 696,  438,  753,  488],
       [ 519,  411,  596,  470],
       [ 653,  372,  703,  420],
       [ 740,  395,  782,  428],
       [1271,  689, 1442,  818],
       [1530,  728, 1700,  845],
       [1505,  557, 1638,  659],
       [1052,  409, 1111,  464],
       [1230,  403, 1282,  451],
       [1055,  355, 1098,  388]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 7350., 20016., 13176.,  2958.,  4680.,  2499.,  1462., 22360.,
       20178., 13802.,  3360.,  2597.,  1496.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00042.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 417,  466,  521,  541],
       [ 605,  526,  690,  607],
       [ 609,  407,  671,  480],
       [ 703,  445,  750,  499],
       [ 769,  399,  807,  432],
       [ 517,  389,  557,  420],
       [1273,  520, 1357,  582],
       [1634,  643, 1782,  745],
       [1327,  457, 1411,  526],
       [1115,  493, 1196,  563],
       [1005,  366, 1050,  407],
       [1152,  366, 1192,  407],
       [ 675,  314,  725,  388],
       [ 817,  378,  852,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 7980.,  7052.,  4662.,  2640.,  1326.,  1312.,  5355., 15347.,
        5950.,  5822.,  1932.,  1722.,  3825.,  1224.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00043.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 373,  741,  527,  897],
       [ 223,  549,  390,  666],
       [ 605,  551,  688,  620],
       [ 515,  470,  617,  559],
       [ 434,  428,  492,  470],
       [ 719,  457,  778,  507],
       [ 815,  434,  861,  466],
       [ 640,  334,  705,  426],
       [ 734,  334,  788,  399],
       [1750,  714, 1919,  829],
       [1394,  505, 1490,  572],
       [1046,  407, 1107,  457],
       [1151,  418, 1213,  476],
       [1221,  395, 1286,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([24335., 19824.,  5880.,  9270.,  2537.,  3060.,  1551.,  6138.,
        3630., 19720.,  6596.,  3162.,  3717.,  3234.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00044.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  722,  125,  870],
       [ 344,  803,  509,  947],
       [ 327,  582,  509,  734],
       [ 300,  499,  382,  555],
       [ 615,  574,  711,  647],
       [ 794,  539,  859,  601],
       [ 578,  366,  669,  488],
       [ 713,  363,  780,  445],
       [ 502,  393,  542,  426],
       [1440,  526, 1536,  603],
       [1273,  430, 1334,  474],
       [ 998,  357, 1050,  395],
       [1082,  374, 1127,  414],
       [1152,  359, 1205,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([18774., 24070., 27999.,  4731.,  7178.,  4158., 11316.,  5644.,
        1394.,  7566.,  2790.,  2067.,  1886.,  2214.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00045.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  843,  209, 1045],
       [ 294,  884,  498, 1043],
       [ 652,  845,  802,  993],
       [  42,  632,  173,  722],
       [ 467,  422,  602,  593],
       [ 657,  418,  746,  528],
       [ 415,  441,  463,  476],
       [1286,  441, 1352,  493],
       [1190,  382, 1244,  426],
       [ 807,  388,  850,  426],
       [ 578,  380,  625,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([42630., 32800., 22499., 12012., 23392.,  9990.,  1764.,  3551.,
        2475.,  1716.,  1872.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00046.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 202,  520,  444,  811],
       [ 525,  514,  673,  689],
       [ 571,  459,  636,  495],
       [ 790,  445,  844,  486],
       [ 515,  426,  569,  474],
       [ 571,  386,  627,  426],
       [ 494,  384,  534,  426],
       [1198,  389, 1248,  434],
       [1130,  349, 1169,  380],
       [ 811,  355,  850,  389],
       [ 642,  347,  686,  395],
       [ 742,  357,  786,  389]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([70956., 26224.,  2442.,  2310.,  2695.,  2337.,  1763.,  2346.,
        1280.,  1400.,  2205.,  1485.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00047.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  92,  772,  446, 1049],
       [   2,  655,   80,  749],
       [ 734,  559,  819,  626],
       [ 448,  549,  542,  616],
       [ 390,  495,  471,  557],
       [ 403,  434,  463,  480],
       [ 494,  432,  567,  491],
       [1378,  763, 1550,  897],
       [ 592,  382,  640,  434],
       [ 807,  399,  852,  438],
       [ 730,  395,  769,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([98690.,  7505.,  5848.,  6460.,  5166.,  2867.,  4440., 23355.,
        2597.,  1840.,  1600.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00048.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 594,  832,  750,  988],
       [ 163,  741,  321,  864],
       [ 136,  622,  267,  730],
       [ 236,  509,  327,  574],
       [ 352,  511,  455,  589],
       [ 498,  430,  571,  497],
       [ 686,  453,  742,  503],
       [ 788,  466,  846,  526],
       [1172,  540, 1263,  618],
       [ 794,  391,  840,  434],
       [ 598,  370,  638,  409],
       [ 734,  366,  773,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24649., 19716., 14388.,  6072.,  8216.,  5032.,  2907.,  3599.,
        7268.,  2068.,  1640.,  1440.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00049.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  645,   49,  770],
       [  52,  659,  232,  795],
       [ 702,  613,  805,  718],
       [ 586,  566,  665,  641],
       [ 327,  511,  428,  614],
       [ 448,  476,  507,  526],
       [ 775,  459,  832,  520],
       [ 542,  401,  602,  453],
       [ 705,  405,  755,  453],
       [1494,  705, 1646,  818],
       [1584,  578, 1746,  709],
       [1194,  589, 1288,  672],
       [1084,  439, 1146,  495]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 6300., 24797., 11024.,  6080., 10608.,  3060.,  3596.,  3233.,
        2499., 17442., 21516.,  7980.,  3591.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00050.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  682,  140,  853],
       [ 294,  843,  469,  995],
       [ 705,  599,  802,  701],
       [ 246,  582,  350,  659],
       [ 442,  457,  532,  526],
       [ 650,  470,  721,  536],
       [1261,  511, 1346,  578],
       [1380,  470, 1475,  547],
       [1065,  453, 1123,  505],
       [ 796,  418,  838,  459],
       [ 575,  403,  615,  438],
       [1032,  389, 1080,  418],
       [ 650,  380,  692,  409],
       [ 813,  374,  850,  409],
       [ 732,  374,  771,  413],
       [ 532,  368,  571,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([24252., 26928., 10094.,  8190.,  6370.,  4824.,  5848.,  7488.,
        3127.,  1806.,  1476.,  1470.,  1290.,  1368.,  1600.,  1120.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00051.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1730,  901, 1919, 1044],
       [ 515,  603,  623,  711],
       [ 252,  563,  377,  668],
       [1517,  584, 1628,  655],
       [ 494,  451,  550,  495],
       [ 761,  505,  827,  563],
       [ 459,  407,  511,  441],
       [ 605,  424,  653,  461],
       [ 702,  428,  755,  472],
       [ 794,  428,  850,  470],
       [1150,  420, 1205,  464],
       [1261,  403, 1330,  463],
       [ 984,  382, 1034,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27360., 11881., 13356.,  8064.,  2565.,  3953.,  1855.,  1862.,
        2430.,  2451.,  2520.,  4270.,  2091.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00052.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 134, 1003,  325, 1047],
       [ 673,  678,  782,  791],
       [1342,  805, 1513,  932],
       [1350,  584, 1453,  668],
       [1332,  474, 1402,  526],
       [1182,  364, 1234,  409],
       [1082,  370, 1125,  405],
       [ 748,  520,  827,  582],
       [ 636,  507,  707,  578],
       [ 505,  497,  584,  551],
       [ 350,  539,  430,  605],
       [ 327,  468,  398,  530],
       [ 467,  384,  525,  443],
       [ 577,  474,  634,  522]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 8640., 12540., 22016.,  8840.,  3763.,  2438.,  1584.,  5040.,
        5184.,  4400.,  5427.,  4536.,  3540.,  2842.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00053.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   7,  714,  155,  824],
       [  48,  586,  165,  680],
       [ 311,  618,  430,  714],
       [ 448,  686,  578,  809],
       [ 632,  716,  761,  841],
       [ 346,  434,  425,  516],
       [ 473,  395,  521,  432],
       [1723,  713, 1903,  834],
       [1148,  549, 1221,  605],
       [1202,  464, 1269,  518],
       [1223,  411, 1275,  451]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16539., 11210., 11640., 16244., 16380.,  6640.,  1862., 22082.,
        4218.,  3740.,  2173.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00054.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  96,  799,  282,  939],
       [ 113,  526,  236,  649],
       [1392,  597, 1513,  668],
       [1413,  524, 1503,  589],
       [1065,  434, 1113,  480],
       [1119,  399, 1167,  438],
       [ 382,  439,  442,  491]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([26367., 15376.,  8784.,  6006.,  2303.,  1960.,  3233.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00055.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1207,  618, 1317,  699],
       [1202,  457, 1269,  507],
       [1267,  428, 1321,  484],
       [ 219,  520,  305,  584],
       [ 455,  411,  503,  449],
       [ 644,  376,  690,  422],
       [1009,  382, 1050,  414],
       [1063,  359, 1105,  391],
       [ 632,  326,  684,  380]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([9102., 3468., 3135., 5655., 1911., 2209., 1386., 1419., 2915.],
      dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00056.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 348,  468,  413,  511],
       [ 586,  434,  657,  488],
       [ 494,  388,  538,  422],
       [ 592,  343,  661,  414],
       [ 742,  374,  780,  407],
       [1765,  891, 1919, 1049],
       [1067,  684, 1178,  784],
       [1586,  605, 1744,  726],
       [1098,  474, 1169,  528],
       [1109,  395, 1161,  434],
       [1178,  380, 1223,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 2904.,  3960.,  1575.,  5040.,  1326., 24645., 11312., 19398.,
        3960.,  2120.,  1794.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00057.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 163,  551,  255,  622],
       [ 465,  518,  565,  599],
       [ 392,  439,  448,  486],
       [ 527,  364,  623,  464],
       [ 711,  416,  759,  472],
       [ 992,  489, 1048,  534],
       [1227,  616, 1340,  716],
       [1340,  568, 1459,  659],
       [1603,  636, 1732,  726],
       [1350,  468, 1434,  530],
       [1046,  403, 1092,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 6696.,  8282.,  2736.,  9797.,  2793.,  2622., 11514., 11040.,
       11830.,  5355.,  1927.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00058.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 157,  651,  353,  861],
       [ 207,  534,  296,  586],
       [ 405,  424,  550,  543],
       [ 634,  507,  707,  582],
       [1386,  841, 1567,  963],
       [1105,  484, 1177,  532],
       [1369,  486, 1446,  543],
       [1188,  447, 1265,  501],
       [1225,  397, 1284,  447],
       [ 953,  399,  998,  438],
       [ 650,  384,  698,  430],
       [ 505,  380,  548,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([41567.,  4770., 17520.,  5624., 22386.,  3577.,  4524.,  4290.,
        3060.,  1840.,  2303.,  1628.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00059.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 409,  716,  553,  859],
       [ 186,  503,  421,  682],
       [ 584,  428,  652,  495],
       [ 413,  436,  471,  476],
       [1627,  795, 1805,  914],
       [1144,  541, 1221,  595],
       [1048,  401, 1098,  451],
       [1246,  413, 1296,  447],
       [1109,  382, 1165,  424],
       [ 661,  386,  707,  420],
       [ 538,  364,  577,  395],
       [1146,  357, 1194,  397]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20880., 42480.,  4692.,  2419., 21480.,  4290.,  2601.,  1785.,
        2451.,  1645.,  1280.,  2009.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00060.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  649,  152,  903],
       [ 244,  513,  328,  568],
       [ 461,  507,  561,  613],
       [1307,  538, 1390,  599],
       [1040,  424, 1096,  468],
       [1161,  372, 1211,  401],
       [ 603,  428,  659,  484],
       [ 480,  399,  528,  436],
       [ 711,  413,  759,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([39015.,  4760., 10807.,  5208.,  2565.,  1530.,  3249.,  1862.,
        1813.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00001.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  605,   98,  726],
       [ 353,  591,  461,  699],
       [ 405,  476,  478,  536],
       [ 553,  397,  598,  432],
       [ 702,  434,  750,  472],
       [ 809,  384,  850,  416],
       [1282,  663, 1413,  782],
       [1128,  516, 1200,  566],
       [1198,  426, 1307,  536],
       [1038,  403, 1086,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11834., 11881.,  4514.,  1656.,  1911.,  1386., 15840.,  3723.,
       12210.,  1813.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00002.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  884,   90, 1045],
       [ 138,  628,  263,  722],
       [ 615,  528,  696,  591],
       [ 478,  443,  540,  491],
       [ 791,  436,  841,  482],
       [1177,  922, 1363, 1043],
       [1534,  745, 1707,  857],
       [1127,  620, 1236,  705],
       [1140,  507, 1221,  582],
       [1055,  424, 1107,  470],
       [1125,  376, 1202,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14742., 11970.,  5248.,  3087.,  2397., 22814., 19662.,  9460.,
        6232.,  2491.,  6396.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00003.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 363,  770,  521,  905],
       [ 342,  526,  425,  586],
       [ 746,  539,  819,  603],
       [ 671,  366,  707,  414],
       [1036,  578, 1121,  657],
       [1294,  547, 1382,  613],
       [1503,  578, 1607,  647],
       [1007,  466, 1067,  513],
       [1071,  422, 1123,  474],
       [1073,  345, 1136,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21624.,  5124.,  4810.,  1813.,  6880.,  5963.,  7350.,  2928.,
        2809.,  3904.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00004.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 605,  795,  752,  941],
       [  36,  688,  188,  805],
       [ 621,  409,  675,  463],
       [1223,  609, 1336,  701],
       [1525,  516, 1873,  797],
       [1313,  457, 1373,  503],
       [1182,  455, 1242,  497],
       [ 986,  455, 1042,  497],
       [ 950,  389,  998,  430],
       [1023,  376, 1067,  414],
       [ 728,  370,  769,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21756., 18054.,  3025., 10602., 98418.,  2867.,  2623.,  2451.,
        2058.,  1755.,  1512.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00005.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1805,  916, 1919, 1048],
       [1327,  414, 1503,  580],
       [1098,  472, 1171,  530],
       [ 525,  476,  609,  559],
       [ 705,  416,  748,  455],
       [ 648,  389,  678,  424],
       [ 959,  395, 1002,  432],
       [1119,  397, 1163,  432],
       [1205,  395, 1253,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15295., 29559.,  4366.,  7140.,  1760.,  1116.,  1672.,  1620.,
        1764.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00006.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 317,  605,  457,  749],
       [ 642,  488,  707,  538],
       [ 582,  441,  636,  482],
       [ 713,  399,  759,  443],
       [ 573,  378,  623,  424],
       [ 648,  386,  688,  424],
       [1044,  403, 1092,  445],
       [1219,  361, 1336,  478],
       [1130,  355, 1169,  388],
       [1063,  359, 1109,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20445.,  3366.,  2310.,  2115.,  2397.,  1599.,  2107., 13924.,
        1360.,  1739.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00007.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 509,  624,  617,  713],
       [ 471,  526,  550,  586],
       [ 663,  455,  732,  524],
       [ 602,  428,  652,  472],
       [ 492,  426,  561,  486],
       [1278,  697, 1413,  803],
       [1117,  466, 1196,  543],
       [1221,  470, 1294,  526],
       [1146,  332, 1230,  414],
       [ 730,  403,  773,  436],
       [ 659,  370,  700,  413],
       [1005,  357, 1046,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9810.,  4880.,  4900.,  2295.,  4270., 14552.,  6240.,  4218.,
        7055.,  1496.,  1848.,  1638.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00008.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 213,  701,  357,  813],
       [ 548,  574,  650,  664],
       [ 334,  507,  438,  597],
       [ 505,  499,  577,  561],
       [ 682,  463,  736,  509],
       [ 615,  414,  665,  459],
       [1125,  501, 1200,  572],
       [1053,  397, 1109,  453],
       [1136,  403, 1192,  447],
       [1082,  318, 1157,  380],
       [ 488,  397,  536,  436],
       [ 663,  382,  709,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16385.,  9373.,  9555.,  4599.,  2585.,  2346.,  5472.,  3249.,
        2565.,  4788.,  1960.,  1833.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00009.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 221,  866,  440, 1043],
       [   2,  674,  173,  830],
       [ 296,  626,  417,  718],
       [ 573,  578,  667,  647],
       [ 527,  482,  609,  547],
       [ 369,  459,  428,  507],
       [ 611,  426,  677,  478],
       [ 717,  389,  767,  426],
       [1065,  638, 1177,  728],
       [1055,  418, 1109,  459],
       [1009,  355, 1052,  399],
       [1075,  366, 1123,  399],
       [ 815,  384,  842,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([39160., 27004., 11346.,  6650.,  5478.,  2940.,  3551.,  1938.,
       10283.,  2310.,  1980.,  1666.,   840.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00010.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 265,  878,  444, 1038],
       [ 109,  572,  219,  639],
       [ 355,  595,  471,  693],
       [ 513,  509,  594,  584],
       [1411,  866, 1615, 1030],
       [1690,  691, 1850,  782],
       [ 998,  474, 1059,  520],
       [ 673,  443,  734,  497],
       [ 800,  438,  844,  474]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28980.,  7548., 11583.,  6232., 33825., 14812.,  2914.,  3410.,
        1665.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00011.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  895,  130, 1059],
       [ 278,  659,  423,  786],
       [ 567,  549,  671,  632],
       [ 759,  539,  832,  595],
       [ 494,  338,  580,  424],
       [ 652,  391,  698,  428],
       [ 728,  401,  771,  434],
       [1157,  545, 1242,  614],
       [1400,  632, 1517,  707],
       [1577,  611, 1711,  709],
       [1394,  507, 1484,  561],
       [ 961,  399, 1005,  432],
       [ 825,  384,  861,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21615., 18688.,  8820.,  4218.,  7569.,  1786.,  1496.,  6020.,
        8968., 13365.,  5005.,  1530.,  1591.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00012.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 627,  784,  767,  914],
       [ 280,  797,  482,  986],
       [ 805,  459,  859,  499],
       [ 676,  466,  738,  511],
       [ 584,  449,  640,  495],
       [ 402,  366,  527,  478],
       [ 721,  378,  775,  443],
       [ 648,  353,  686,  389],
       [1225,  486, 1296,  532],
       [1348,  474, 1425,  532],
       [1069,  436, 1125,  478],
       [1255,  422, 1313,  459]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18471., 38570.,  2255.,  2898.,  2679., 14238.,  3630.,  1443.,
        3384.,  4602.,  2451.,  2242.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00013.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 227,  414,  423,  572],
       [ 434,  563,  523,  634],
       [ 571,  578,  657,  651],
       [ 738,  599,  825,  678],
       [ 667,  434,  738,  528],
       [ 578,  393,  628,  432],
       [1046,  618, 1144,  697],
       [1715,  891, 1919, 1045],
       [1727,  649, 1919,  869],
       [1227,  399, 1280,  445],
       [1130,  409, 1180,  447],
       [1167,  374, 1219,  401],
       [1015,  376, 1059,  409],
       [ 615,  349,  652,  391]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([31323.,  6480.,  6438.,  7040.,  6840.,  2040.,  7920., 31775.,
       42653.,  2538.,  1989.,  1484.,  1530.,  1634.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00014.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  857,  194, 1005],
       [ 236,  882,  432, 1041],
       [ 530,  541,  653,  699],
       [1315,  555, 1411,  636],
       [1409,  478, 1578,  609],
       [ 988,  464, 1046,  516],
       [   0,  503,  234,  763],
       [ 446,  468,  523,  534],
       [ 565,  376,  615,  432],
       [ 498,  380,  546,  418],
       [1146,  361, 1190,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([28608., 31520., 19716.,  7954., 22440.,  3127., 61335.,  5226.,
        2907.,  1911.,  1575.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00015.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 136,  861,  405, 1045],
       [ 123,  630,  265,  747],
       [ 490,  420,  555,  486],
       [ 400,  422,  465,  478],
       [1403,  791, 1632,  999],
       [1259,  401, 1365,  489],
       [1163,  436, 1227,  491],
       [ 957,  393, 1002,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([49950., 16874.,  4422.,  3762., 48070.,  9523.,  3640.,  1840.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00016.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 334,  499,  440,  591],
       [ 213,  507,  311,  586],
       [1159,  530, 1261,  622],
       [1171,  355, 1246,  420],
       [1086,  380, 1136,  413],
       [ 469,  409,  515,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([9951., 7920., 9579., 5016., 1734., 2115.], dtype=float32), 'gt_overlaps': <6x16 sparse matrix of type '<type 'numpy.float32'>'
	with 6 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00017.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  657,  177,  826],
       [ 340,  478,  409,  530],
       [ 555,  303,  609,  384],
       [1061,  672, 1184,  788],
       [1300,  713, 1438,  809],
       [1457,  668, 1588,  757],
       [1498,  486, 1698,  672],
       [1073,  426, 1132,  488],
       [1109,  328, 1163,  382]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([29920.,  3710.,  4510., 14508., 13483., 11880., 37587.,  3780.,
        3025.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00018.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  71,  599,  186,  686],
       [ 519,  324,  584,  414],
       [1325,  714, 1453,  811],
       [ 996,  486, 1063,  549],
       [1132,  513, 1209,  568],
       [1238,  497, 1311,  547],
       [1321,  401, 1436,  522],
       [1023,  372, 1065,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10208.,  6006., 12642.,  4352.,  4368.,  3774., 14152.,  1849.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00019.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 444,  347,  538,  459],
       [1146,  513, 1215,  572],
       [1211,  347, 1294,  453],
       [1136,  413, 1184,  451],
       [1061,  422, 1111,  463],
       [ 959,  403, 1003,  441],
       [ 530,  334,  586,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10735.,  4200.,  8988.,  1911.,  2142.,  1755.,  4104.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00020.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 309,  388,  436,  536],
       [ 463,  361,  538,  443],
       [1425,  628, 1586,  749],
       [1067,  424, 1115,  463],
       [1138,  322, 1205,  399],
       [1073,  368, 1107,  395],
       [1013,  372, 1052,  405],
       [ 932,  355,  969,  384]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([19072.,  6308., 19764.,  1960.,  5304.,   980.,  1360.,  1140.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00021.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  53,  459,  259,  672],
       [ 344,  407,  444,  520],
       [1148,  874, 1334, 1034],
       [1359,  761, 1503,  859],
       [1242,  480, 1330,  549],
       [ 530,  361,  573,  405],
       [1084,  303, 1136,  363],
       [1019,  378, 1053,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([44298., 11514., 30107., 14355.,  6230.,  1980.,  3233.,  1050.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00022.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 123,  480,  277,  638],
       [1344,  801, 1500,  913],
       [1550,  759, 1732,  872],
       [1240,  651, 1357,  728],
       [1169,  543, 1246,  597],
       [1025,  549, 1109,  613],
       [1140,  405, 1205,  457],
       [ 469,  395,  525,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24645., 17741., 20862.,  9204.,  4290.,  5525.,  3498.,  2907.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00023.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1515,  574, 1640,  655],
       [1294,  541, 1382,  603],
       [1148,  553, 1227,  609],
       [1111,  493, 1184,  547],
       [1084,  447, 1142,  484],
       [ 980,  436, 1036,  480],
       [ 371,  445,  442,  505],
       [ 471,  403,  528,  447],
       [ 594,  309,  663,  413],
       [1080,  361, 1132,  401],
       [ 682,  374,  721,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10332.,  5607.,  4560.,  4070.,  2242.,  2565.,  4392.,  2610.,
        7350.,  2173.,  1280.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00024.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 194,  524,  294,  611],
       [1734,  903, 1919, 1042],
       [1317,  463, 1398,  518],
       [1184,  447, 1240,  491],
       [1077,  451, 1130,  501],
       [ 384,  449,  452,  499],
       [ 625,  420,  678,  464],
       [ 546,  330,  634,  451],
       [1053,  420, 1102,  463]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 8888., 26040.,  4592.,  2565.,  2754.,  3519.,  2430., 10858.,
        2200.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00025.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 209,  528,  309,  597],
       [ 513,  505,  590,  564],
       [1359,  591, 1467,  661],
       [ 452,  355,  590,  526],
       [ 796,  405,  842,  451],
       [1028,  395, 1069,  432],
       [1115,  391, 1157,  430],
       [1205,  397, 1259,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 7070.,  4680.,  7739., 23908.,  2209.,  1596.,  1720.,  2585.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00026.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 248,  684,  382,  789],
       [   2,  666,   36,  749],
       [ 271,  409,  505,  655],
       [ 759,  472,  825,  547],
       [1453,  670, 1594,  770],
       [1602,  624, 1730,  709],
       [1213,  470, 1282,  518],
       [ 707,  428,  753,  468],
       [ 642,  418,  686,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14310.,  2940., 58045.,  5092., 14342., 11094.,  3430.,  1927.,
        1710.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00027.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  501,  328,  968],
       [ 659,  626,  778,  745],
       [ 644,  511,  713,  570],
       [ 542,  499,  607,  555],
       [1294,  713, 1425,  807],
       [1253,  501, 1330,  563],
       [1359,  476, 1436,  528],
       [1128,  401, 1186,  443],
       [ 615,  407,  671,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([153972.,  14400.,   4200.,   3762.,  12540.,   4914.,   4134.,
         2537.,   3306.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00028.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 488,  672,  604,  762],
       [ 334,  649,  440,  730],
       [ 525,  476,  603,  543],
       [ 427,  430,  477,  470],
       [ 527,  411,  582,  461],
       [1292,  705, 1427,  803],
       [1132,  520, 1202,  574],
       [1153,  422, 1205,  470],
       [1230,  405, 1286,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10647.,  8774.,  5372.,  2091.,  2856., 13464.,  3905.,  2597.,
        2223.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00029.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1134,  893, 1313, 1043],
       [1446,  582, 1709,  791],
       [1094,  661, 1203,  747],
       [1132,  509, 1207,  564],
       [1067,  430, 1111,  470],
       [ 332,  593,  463,  713],
       [ 396,  484,  484,  553],
       [ 286,  503,  357,  559],
       [ 511,  416,  580,  472]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([27180., 55440.,  9570.,  4256.,  1845., 15972.,  6230.,  4104.,
        3990.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00030.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  916,   69, 1045],
       [ 109,  634,  265,  743],
       [  19,  622,  128,  699],
       [ 392,  474,  488,  563],
       [1021,  557, 1103,  634],
       [1211,  613, 1325,  689],
       [1453,  680, 1594,  772],
       [1259,  459, 1400,  586],
       [1007,  482, 1071,  534],
       [1063,  424, 1115,  466],
       [ 423,  416,  484,  474]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9100., 17270.,  8580.,  8730.,  6474.,  8855., 13206., 18176.,
        3445.,  2279.,  3658.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00031.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 123,  597,  292,  741],
       [ 282,  484,  363,  559],
       [ 428,  422,  484,  464],
       [ 527,  418,  580,  457],
       [1255,  513, 1336,  570],
       [1107,  474, 1167,  528],
       [1169,  386, 1263,  482],
       [ 980,  441, 1032,  484]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24650.,  6232.,  2451.,  2160.,  4756.,  3355.,  9215.,  2332.],
      dtype=float32), 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00032.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  603,  123,  719],
       [ 296,  491,  375,  539],
       [ 415,  488,  492,  539],
       [ 702,  416,  753,  451],
       [ 505,  382,  550,  416],
       [ 586,  376,  638,  416],
       [1161,  428, 1217,  474],
       [1044,  405, 1096,  445],
       [1109,  351, 1184,  416],
       [ 952,  380,  994,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14274.,  3920.,  4056.,  1872.,  1610.,  2173.,  2679.,  2173.,
        5016.,  1677.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00033.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 184,  614,  309,  705],
       [  53,  601,  178,  670],
       [ 628,  505,  703,  568],
       [ 517,  418,  578,  474],
       [ 617,  426,  673,  463],
       [ 440,  420,  498,  459],
       [1336,  711, 1475,  839],
       [1719,  597, 1919,  852],
       [1094,  380, 1136,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11592.,  8820.,  4864.,  3534.,  2166.,  2360., 18060., 51456.,
        1505.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00034.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 405,  722,  548,  849],
       [1580,  749, 1773,  889],
       [1738,  720, 1896,  824],
       [1234,  641, 1352,  722],
       [1448,  464, 1630,  628],
       [1157,  516, 1228,  586],
       [ 505,  522,  580,  564],
       [ 380,  491,  477,  570],
       [ 319,  476,  388,  530],
       [ 448,  420,  498,  459],
       [ 565,  395,  617,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18432., 27354., 16695.,  9758., 30195.,  5112.,  3268.,  7840.,
        3850.,  2040.,  2226.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00035.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 186,  738,  338,  845],
       [  84,  641,  246,  772],
       [ 105,  578,  215,  643],
       [ 321,  478,  396,  532],
       [ 484,  441,  544,  503],
       [1503,  974, 1755, 1041],
       [1842,  734, 1919,  912],
       [1469,  553, 1559,  614],
       [1317,  541, 1411,  618],
       [1109,  489, 1178,  541],
       [1298,  403, 1423,  513],
       [1073,  426, 1127,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16524., 21516.,  7326.,  4180.,  3843., 17204., 13962.,  5642.,
        7410.,  3710., 13986.,  2365.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00036.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 100,  572,  209,  657],
       [ 334,  524,  428,  603],
       [ 509,  430,  569,  474],
       [ 428,  414,  488,  463],
       [1194,  591, 1303,  682],
       [1509,  541, 1659,  676],
       [1327,  461, 1394,  507],
       [1186,  447, 1248,  495],
       [1202,  361, 1298,  445],
       [1057,  409, 1100,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9460.,  7600.,  2745.,  3050., 10120., 20536.,  3196.,  3087.,
        8245.,  1980.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00037.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  686,  163,  834],
       [ 367,  514,  448,  574],
       [ 300,  480,  380,  541],
       [1538,  993, 1784, 1043],
       [1394,  618, 1515,  705],
       [1532,  588, 1663,  674],
       [1346,  451, 1446,  549],
       [1092,  461, 1159,  518],
       [ 723,  378,  769,  422],
       [ 496,  386,  540,  432],
       [1232,  407, 1286,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([24138.,  5002.,  5022., 12597., 10736., 11484.,  9999.,  3944.,
        2115.,  2115.,  2365.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00038.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  38,  684,  188,  788],
       [  46,  589,  173,  678],
       [ 403,  436,  463,  482],
       [ 684,  424,  746,  491],
       [1494,  697, 1644,  797],
       [1207,  588, 1336,  691],
       [1525,  586, 1655,  680],
       [1359,  482, 1438,  539],
       [1227,  482, 1303,  539],
       [1248,  397, 1321,  474],
       [1032,  397, 1086,  441],
       [ 732,  389,  773,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15855., 11520.,  2867.,  4284., 15251., 13520., 12445.,  4640.,
        4466.,  5772.,  2475.,  1680.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00039.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 244,  513,  325,  578],
       [ 602,  503,  692,  593],
       [ 444,  363,  525,  449],
       [ 698,  445,  750,  489],
       [1480,  584, 1603,  655],
       [1265,  514, 1350,  576],
       [1092,  453, 1175,  524],
       [1350,  480, 1436,  541],
       [1255,  420, 1321,  466],
       [1142,  411, 1194,  449],
       [ 723,  380,  771,  420],
       [ 653,  391,  700,  424],
       [1180,  361, 1236,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([5412., 8281., 7134., 2385., 8928., 5418., 6048., 5394., 3149.,
       2067., 2009., 1632., 2907.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00040.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 388,  670,  559,  855],
       [1480,  938, 1696, 1045],
       [1727,  884, 1919, 1041],
       [1255,  609, 1402,  753],
       [1717,  697, 1900,  807],
       [   0,  653,   51,  772],
       [ 619,  543,  700,  611],
       [1278,  476, 1353,  522],
       [ 334,  413,  428,  514],
       [ 577,  455,  638,  503],
       [ 686,  438,  746,  495],
       [1163,  428, 1217,  468],
       [1244,  418, 1309,  464],
       [1036,  388, 1086,  436],
       [1188,  382, 1236,  426],
       [ 552,  403,  603,  445],
       [ 452,  414,  498,  455],
       [ 725,  401,  767,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([31992., 23436., 30494., 21460., 20424.,  6240.,  5658.,  3572.,
        9690.,  3038.,  3538.,  2255.,  3102.,  2499.,  2205.,  2236.,
        1974.,  1763.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00041.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 403,  755,  550,  891],
       [ 392,  586,  503,  672],
       [ 584,  534,  688,  622],
       [ 671,  466,  736,  513],
       [ 459,  459,  530,  520],
       [ 325,  474,  396,  524],
       [ 125,  484,  275,  632],
       [ 598,  428,  652,  474],
       [1423,  870, 1625, 1013],
       [1605,  770, 1850,  932],
       [1373,  593, 1498,  678],
       [1205,  591, 1303,  661],
       [1428,  522, 1532,  595],
       [1128,  470, 1215,  553],
       [1157,  409, 1211,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([20276.,  9744.,  9345.,  3168.,  4464.,  3672., 22499.,  2585.,
       29232., 40098., 10836.,  7029.,  7770.,  7392.,  2145.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00042.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  974,   82, 1041],
       [ 327,  766,  528,  949],
       [ 550,  591,  646,  668],
       [ 278,  555,  388,  647],
       [ 105,  574,  202,  647],
       [ 486,  514,  565,  582],
       [ 411,  432,  473,  476],
       [ 536,  414,  594,  459],
       [1082,  726, 1213,  832],
       [1302,  699, 1473,  838],
       [1553,  761, 1719,  864],
       [1527,  595, 1648,  664],
       [1330,  549, 1448,  639],
       [1192,  578, 1286,  653],
       [1225,  474, 1309,  532],
       [1290,  439, 1363,  486],
       [1100,  468, 1161,  513],
       [1065,  391, 1121,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 5508., 37168.,  7566., 10323.,  7252.,  5520.,  2835.,  2714.,
       14124., 24080., 17368.,  8540., 10829.,  7220.,  5015.,  3552.,
        2852.,  3819.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00043.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 184,  939,  402, 1045],
       [ 203,  714,  350,  838],
       [   0,  768,   44,  926],
       [ 448,  478,  525,  545],
       [ 280,  491,  359,  553],
       [ 509,  438,  569,  491],
       [1375,  861, 1578, 1011],
       [1503,  701, 1663,  818],
       [1309,  557, 1394,  613],
       [1136,  516, 1234,  593],
       [ 998,  509, 1069,  566],
       [1094,  463, 1159,  513],
       [1203,  453, 1278,  509],
       [1344,  480, 1417,  526]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([23433., 18500.,  7155.,  5304.,  5040.,  3294., 30804., 18998.,
        4902.,  7722.,  4176.,  3366.,  4332.,  3478.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00044.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 267,  599,  386,  705],
       [  32,  603,  157,  680],
       [ 373,  513,  459,  591],
       [ 452,  461,  517,  511],
       [ 684,  457,  742,  505],
       [ 432,  414,  484,  470],
       [1490,  914, 1752, 1043],
       [1632,  661, 1784,  766],
       [1044,  622, 1134,  699],
       [1169,  578, 1261,  655],
       [1282,  528, 1373,  597],
       [1188,  455, 1250,  497],
       [1238,  414, 1294,  453],
       [1069,  430, 1132,  484],
       [1123,  395, 1184,  439],
       [ 965,  420, 1009,  457],
       [ 807,  418,  855,  455],
       [1042,  397, 1082,  434],
       [ 488,  389,  530,  422],
       [ 715,  391,  752,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12840.,  9828.,  6873.,  3366.,  2891.,  3021., 34190., 16218.,
        7098.,  7254.,  6440.,  2709.,  2280.,  3520.,  2790.,  1710.,
        1862.,  1558.,  1462.,  1216.], dtype=float32), 'gt_overlaps': <20x16 sparse matrix of type '<type 'numpy.float32'>'
	with 20 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00045.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  78,  661,  234,  786],
       [ 253,  551,  353,  622],
       [ 573,  574,  665,  659],
       [ 788,  491,  850,  543],
       [ 302,  482,  377,  541],
       [ 646,  447,  698,  484],
       [ 407,  432,  473,  480],
       [1542,  720, 1725,  851],
       [1559,  639, 1688,  716],
       [1198,  572, 1307,  663],
       [1380,  503, 1471,  564],
       [1180,  438, 1236,  491],
       [1086,  472, 1144,  516],
       [ 980,  470, 1042,  513],
       [1111,  399, 1157,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([19782.,  7272.,  7998.,  3339.,  4560.,  2014.,  3283., 24288.,
       10140., 10120.,  5704.,  3078.,  2655.,  2772.,  1598.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00046.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 202,  930,  413, 1041],
       [  55,  584,  167,  676],
       [ 705,  645,  811,  738],
       [ 503,  547,  588,  605],
       [ 265,  503,  348,  561],
       [1636,  814, 1846,  943],
       [1290,  526, 1384,  599],
       [1102,  451, 1169,  513],
       [1253,  420, 1309,  468],
       [1327,  495, 1392,  543],
       [ 684,  447,  744,  499],
       [ 417,  436,  471,  482],
       [ 553,  401,  615,  445],
       [ 494,  393,  546,  436],
       [1038,  407, 1082,  441],
       [1121,  389, 1161,  432],
       [ 946,  397,  998,  432],
       [ 719,  386,  765,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([23744., 10509., 10058.,  5074.,  4956., 27430.,  7030.,  4284.,
        2793.,  3234.,  3233.,  2585.,  2835.,  2332.,  1575.,  1804.,
        1908.,  2021.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00047.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 152,  772,  317,  901],
       [   3,  628,  115,  720],
       [ 250,  507,  338,  586],
       [ 577,  563,  665,  632],
       [ 461,  449,  538,  511],
       [ 382,  441,  450,  495],
       [ 682,  432,  746,  493],
       [ 715,  391,  757,  438],
       [1246,  636, 1363,  734],
       [1328,  561, 1427,  630],
       [1180,  424, 1240,  491],
       [1048,  386, 1100,  436],
       [1171,  382, 1221,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21580., 10509.,  7120.,  6230.,  4914.,  3795.,  4030.,  2064.,
       11682.,  7000.,  4148.,  2703.,  1632.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00048.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 246,  861,  444, 1020],
       [   2,  651,   50,  789],
       [ 190,  526,  292,  603],
       [ 313,  526,  413,  609],
       [ 594,  526,  682,  611],
       [ 669,  449,  728,  501],
       [ 592,  422,  655,  470],
       [ 796,  422,  848,  463],
       [ 713,  403,  755,  432],
       [1596,  584, 1763,  734],
       [1121,  482, 1182,  545],
       [1196,  455, 1259,  501],
       [1113,  384, 1161,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([31840.,  6811.,  8034.,  8484.,  7654.,  3180.,  3136.,  2226.,
        1290., 25368.,  3968.,  3008.,  2107.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00049.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 346,  730,  519,  895],
       [  38,  655,  200,  782],
       [ 575,  543,  663,  624],
       [ 467,  505,  553,  578],
       [ 765,  509,  828,  563],
       [ 663,  463,  725,  513],
       [ 803,  439,  852,  482],
       [ 532,  420,  588,  463],
       [ 465,  418,  519,  457],
       [1452,  684, 1594,  788],
       [1765,  749, 1919,  856],
       [1369,  457, 1465,  553],
       [1044,  407, 1088,  449],
       [1123,  399, 1173,  438],
       [ 809,  397,  852,  438]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([28884., 20864.,  7298.,  6438.,  3520.,  3213.,  2200.,  2508.,
        2200., 15015., 16740.,  9409.,  1935.,  2040.,  1848.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00050.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 311,  766,  486,  936],
       [ 157,  705,  342,  851],
       [ 675,  693,  780,  793],
       [ 546,  580,  644,  649],
       [ 765,  539,  838,  605],
       [ 394,  499,  475,  559],
       [ 786,  466,  836,  513],
       [ 350,  474,  417,  516],
       [1527,  697, 1678,  807],
       [1448,  545, 1530,  609],
       [1238,  503, 1321,  570],
       [1242,  393, 1315,  459],
       [ 582,  405,  634,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([30096., 27342., 10706.,  6930.,  4958.,  5002.,  2448.,  2924.,
       16872.,  5395.,  5712.,  4958.,  2173.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00051.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 227,  878,  417, 1039],
       [ 642,  780,  780,  926],
       [  88,  655,  228,  774],
       [ 142,  568,  252,  641],
       [ 713,  595,  798,  674],
       [ 455,  478,  527,  532],
       [1088,  741, 1211,  853],
       [1363,  770, 1548,  905],
       [1277,  507, 1361,  570],
       [1292,  453, 1355,  497],
       [1144,  424, 1200,  468],
       [ 552,  403,  600,  443],
       [1169,  349, 1217,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([30942., 20433., 16920.,  8214.,  6880.,  4015., 14012., 25296.,
        5440.,  2880.,  2565.,  2009.,  2891.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00052.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 517,  972,  686, 1043],
       [ 198,  603,  323,  703],
       [ 465,  455,  528,  501],
       [ 428,  418,  488,  463],
       [ 530,  413,  586,  455],
       [ 709,  407,  757,  447],
       [1475,  947, 1700, 1039],
       [1527,  728, 1692,  838],
       [1153,  530, 1253,  614],
       [1000,  507, 1067,  564],
       [1163,  420, 1221,  466]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([12240., 12726.,  3008.,  2806.,  2451.,  2009., 21018., 18426.,
        8585.,  3944.,  2773.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00053.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1119,  716, 1257,  836],
       [1200,  597, 1294,  670],
       [1275,  528, 1357,  589],
       [ 317,  543,  402,  605],
       [ 286,  499,  361,  545],
       [ 432,  474,  507,  532],
       [ 650,  484,  713,  541],
       [1071,  434, 1130,  486],
       [ 957,  414, 1003,  451],
       [ 723,  411,  767,  451],
       [ 809,  384,  848,  418],
       [ 663,  376,  702,  413],
       [ 596,  384,  642,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16819.,  7030.,  5146.,  5418.,  3572.,  4484.,  3712.,  3180.,
        1786.,  1845.,  1400.,  1520.,  1410.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00054.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  732,  138,  845],
       [   0,  632,   98,  726],
       [ 223,  574,  340,  672],
       [ 503,  634,  615,  734],
       [ 661,  484,  717,  539],
       [ 794,  445,  848,  497],
       [ 613,  416,  671,  468],
       [ 542,  418,  592,  459],
       [ 717,  395,  767,  441],
       [1015,  518, 1092,  588],
       [1098,  468, 1157,  516],
       [1161,  430, 1217,  476],
       [1023,  382, 1071,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15618.,  9405., 11682., 11413.,  3192.,  2915.,  3127.,  2142.,
        2397.,  5538.,  2940.,  2679.,  1911.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00055.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 494,  647,  605,  745],
       [ 736,  574,  825,  657],
       [ 498,  493,  586,  572],
       [ 436,  486,  500,  536],
       [ 665,  457,  728,  528],
       [ 461,  411,  513,  441],
       [ 569,  391,  613,  434],
       [1223,  618, 1327,  695],
       [ 977,  432, 1028,  482],
       [1044,  403, 1090,  441],
       [1090,  384, 1138,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11088.,  7560.,  7120.,  3315.,  4608.,  1643.,  1980.,  8190.,
        2652.,  1833.,  1617.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00056.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 534,  982,  713, 1043],
       [1319,  757, 1467,  872],
       [1107,  478, 1169,  532],
       [ 528,  586,  644,  705],
       [ 252,  651,  403,  789],
       [ 317,  472,  388,  528],
       [ 490,  436,  553,  489],
       [ 719,  405,  767,  443],
       [ 577,  397,  617,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11160., 17284.,  3465., 14040., 21128.,  4104.,  3456.,  1911.,
        1476.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00057.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 130,  951,  375, 1047],
       [  40,  601,  161,  682],
       [ 359,  511,  448,  580],
       [ 661,  480,  725,  530],
       [ 496,  447,  552,  493],
       [1138,  536, 1217,  593],
       [1048,  407, 1098,  447],
       [ 555,  401,  602,  441],
       [ 805,  370,  850,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([23862., 10004.,  6300.,  3315.,  2679.,  4640.,  2091.,  1968.,
        1840.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00058.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  59,  657,  221,  786],
       [ 509,  636,  617,  730],
       [ 352,  532,  430,  597],
       [ 463,  461,  532,  509],
       [ 786,  428,  842,  482],
       [ 711,  393,  755,  434],
       [ 450,  416,  492,  463],
       [ 659,  364,  709,  403],
       [1419,  830, 1642, 1011],
       [1690,  693, 1867,  811],
       [1067,  436, 1113,  470],
       [1005,  364, 1048,  397]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([21190., 10355.,  5214.,  3430.,  3135.,  1890.,  2064.,  2040.,
       40768., 21182.,  1645.,  1496.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00059.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  17,  705,  165,  822],
       [ 288,  561,  386,  630],
       [ 311,  484,  382,  538],
       [ 728,  536,  821,  622],
       [ 659,  453,  723,  513],
       [ 615,  403,  671,  459],
       [ 513,  366,  555,  403],
       [1184,  545, 1282,  636],
       [1386,  513, 1475,  578],
       [1017,  382, 1061,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17582.,  6930.,  3960.,  8178.,  3965.,  3249.,  1634.,  9108.,
        5940.,  1755.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00060.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 532,  845,  734, 1043],
       [   2,  772,   57,  891],
       [  32,  607,  144,  691],
       [ 540,  570,  644,  661],
       [ 515,  472,  600,  549],
       [ 438,  413,  494,  463],
       [1740,  818, 1919, 1046],
       [1196,  601, 1307,  703],
       [1465,  572, 1567,  638],
       [1244,  420, 1303,  468],
       [1094,  443, 1155,  491]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([40397.,  6720.,  9605.,  9660.,  6708.,  2907., 41220., 11536.,
        6901.,  2940.,  3038.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00001.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 403,  722,  544,  841],
       [ 134,  572,  252,  641],
       [ 484,  447,  552,  505],
       [ 780,  459,  834,  507],
       [ 452,  409,  502,  449],
       [ 721,  399,  765,  436],
       [1640,  674, 1800,  782],
       [1103,  466, 1163,  509],
       [1065,  411, 1115,  463],
       [1252,  420, 1307,  463]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17040.,  8330.,  4071.,  2695.,  2091.,  1710., 17549.,  2684.,
        2703.,  2464.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00002.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1765,  876, 1919, 1046],
       [1655,  653, 1850,  795],
       [1363,  497, 1446,  561],
       [ 709,  597,  792,  670],
       [ 305,  543,  411,  620],
       [ 365,  457,  430,  503],
       [ 663,  463,  725,  520],
       [ 523,  382,  563,  414],
       [ 725,  393,  769,  434],
       [ 655,  358,  715,  412],
       [1040,  395, 1086,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([26505., 28028.,  5460.,  6216.,  8346.,  3102.,  3654.,  1353.,
        1890.,  3355.,  1786.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00003.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  747,   96,  893],
       [ 538,  586,  640,  682],
       [ 221,  524,  311,  589],
       [ 680,  461,  738,  516],
       [ 617,  399,  680,  463],
       [ 467,  413,  509,  453],
       [ 513,  357,  559,  413],
       [1515,  922, 1753, 1041],
       [1771,  761, 1919,  880],
       [1348,  559, 1471,  668],
       [1367,  484, 1465,  557],
       [1228,  411, 1290,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14259.,  9991.,  6006.,  3304.,  4160.,  1763.,  2679., 28680.,
       17880., 13640.,  7326.,  2961.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00004.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 165,  949,  371, 1047],
       [   0,  628,  111,  714],
       [ 559,  588,  650,  668],
       [ 363,  470,  436,  520],
       [ 534,  466,  625,  539],
       [ 455,  389,  521,  451],
       [ 555,  413,  636,  468],
       [1432,  851, 1686, 1045],
       [1215,  582, 1317,  666],
       [1419,  534, 1509,  601],
       [1194,  443, 1273,  509],
       [1228,  403, 1300,  459],
       [ 809,  405,  850,  443],
       [ 730,  389,  777,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([20493.,  9744.,  7452.,  3774.,  6808.,  4221.,  4592., 49725.,
        8755.,  6188.,  5360.,  4161.,  1638.,  2304.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00005.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 169,  968,  384, 1045],
       [ 382,  563,  515,  661],
       [ 425,  484,  523,  555],
       [ 194,  553,  288,  611],
       [ 373,  428,  444,  507],
       [ 684,  451,  744,  522],
       [ 773,  493,  834,  543],
       [1175,  559, 1298,  649],
       [1494,  707, 1646,  807],
       [1109,  459, 1171,  514],
       [1265,  439, 1325,  480],
       [1113,  380, 1167,  430],
       [ 727,  407,  771,  443],
       [ 815,  384,  855,  418],
       [ 577,  382,  621,  422],
       [ 517,  376,  559,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([16848., 13266.,  7128.,  5605.,  5760.,  4392.,  3162., 11284.,
       15453.,  3528.,  2562.,  2805.,  1665.,  1435.,  1845.,  1634.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00006.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  11,  780,  267,  970],
       [ 128,  626,  294,  755],
       [   0,  695,   23,  786],
       [ 219,  480,  334,  576],
       [ 559,  582,  667,  691],
       [ 678,  672,  794,  774],
       [ 671,  478,  728,  530],
       [ 794,  443,  846,  501],
       [ 505,  432,  559,  482],
       [1461,  695, 1600,  789],
       [1261,  509, 1340,  566],
       [1086,  445, 1157,  505],
       [1046,  395, 1092,  434],
       [1173,  382, 1223,  414],
       [ 471,  399,  519,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([49087., 21710.,  2208., 11252., 11990., 12051.,  3074.,  3127.,
        2805., 13300.,  4640.,  4392.,  1880.,  1683.,  2107.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00007.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 532,  626,  636,  714],
       [ 738,  564,  830,  653],
       [   0,  564,  144,  703],
       [ 175,  978,  377, 1051],
       [ 375,  491,  453,  566],
       [ 400,  436,  459,  484],
       [ 507,  436,  557,  474],
       [ 482,  407,  528,  441],
       [ 719,  397,  775,  438],
       [ 805,  372,  859,  424],
       [1250,  503, 1330,  557],
       [1150,  422, 1205,  464],
       [1034,  388, 1080,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9345.,  8370., 20300., 15022.,  6004.,  2940.,  1989.,  1645.,
        2394.,  2915.,  4455.,  2408.,  2115.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00008.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 561,  943,  748, 1049],
       [ 117,  626,  246,  739],
       [ 288,  489,  367,  549],
       [ 398,  505,  469,  555],
       [ 663,  457,  732,  524],
       [ 788,  436,  853,  511],
       [ 415,  443,  469,  480],
       [1848,  993, 1919, 1047],
       [1461,  664, 1609,  770],
       [1152,  420, 1200,  455],
       [ 467,  407,  519,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20116., 14820.,  4880.,  3672.,  4760.,  5016.,  2090.,  3960.,
       15943.,  1764.,  2173.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00009.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 178,  616,  298,  701],
       [ 109,  561,  223,  653],
       [ 544,  582,  650,  680],
       [ 713,  555,  827,  678],
       [ 302,  497,  377,  545],
       [ 398,  447,  448,  488],
       [1332,  726, 1528,  876],
       [1711,  630, 1919,  860],
       [1415,  618, 1534,  695],
       [1267,  507, 1346,  570],
       [ 503,  401,  550,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10406., 10695., 10593., 14260.,  3724.,  2142., 29747., 48279.,
        9360.,  5120.,  1632.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00010.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 142,  974,  352, 1045],
       [ 457,  949,  711, 1043],
       [ 121,  582,  228,  647],
       [ 275,  509,  353,  566],
       [ 425,  438,  486,  480],
       [1261,  663, 1382,  757],
       [1442,  480, 1742,  713],
       [1146,  511, 1246,  595],
       [1263,  474, 1330,  524],
       [1157,  426, 1219,  472]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15192., 24225.,  7128.,  4582.,  2666., 11590., 70434.,  8585.,
        3468.,  2961.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00011.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  71,  595,  190,  672],
       [ 311,  503,  388,  559],
       [1048,  605, 1138,  678],
       [1592,  782, 1780,  905],
       [1713,  707, 1877,  799],
       [1303,  411, 1486,  559],
       [1119,  499, 1190,  559],
       [1069,  424, 1134,  472],
       [ 542,  409,  590,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9360.,  4446.,  6734., 23436., 15345., 27416.,  4392.,  3234.,
        2009.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00012.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 107,  616,  225,  701],
       [ 557,  491,  621,  534],
       [ 457,  468,  525,  520],
       [ 423,  426,  478,  472],
       [ 709,  405,  763,  453],
       [1090,  697, 1217,  816],
       [1338,  761, 1552,  939],
       [1598,  799, 1809,  949],
       [1630,  639, 1784,  739],
       [1448,  538, 1540,  603],
       [1307,  553, 1405,  618],
       [ 990,  461, 1040,  505],
       [1225,  374, 1340,  472],
       [1050,  420, 1100,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([10234.,  2860.,  3657.,  2632.,  2695., 15360., 38485., 32012.,
       15655.,  6138.,  6534.,  2295., 11484.,  1734.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00013.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 365,  641,  469,  711],
       [ 288,  557,  388,  641],
       [ 311,  474,  388,  538],
       [ 659,  472,  730,  539],
       [ 413,  430,  467,  468],
       [ 798,  422,  848,  468],
       [1005,  505, 1078,  574],
       [1153,  538, 1250,  622],
       [1313,  563, 1417,  645],
       [1402,  495, 1488,  566],
       [1309,  451, 1369,  499],
       [1186,  455, 1250,  488],
       [1153,  341, 1248,  418],
       [ 957,  393,  996,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([7455., 8585., 5070., 4896., 2145., 2397., 5180., 8330., 8715.,
       6264., 2989., 2210., 7488., 1440.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00014.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  747,   92,  901],
       [ 111,  568,  225,  653],
       [ 536,  595,  642,  716],
       [ 752,  511,  827,  586],
       [ 296,  488,  371,  545],
       [ 394,  434,  463,  484],
       [1453,  653, 1588,  757],
       [1767,  739, 1919,  836],
       [1194,  457, 1259,  514],
       [1277,  424, 1346,  470],
       [1077,  438, 1142,  499],
       [ 967,  422, 1019,  463],
       [ 702,  432,  752,  470],
       [ 803,  409,  859,  457],
       [ 618,  399,  668,  457],
       [ 511,  403,  545,  441],
       [1221,  401, 1271,  436],
       [1115,  391, 1159,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([14105.,  9890., 13054.,  5776.,  4408.,  3570., 14280., 14994.,
        3828.,  3290.,  4092.,  2226.,  1989.,  2793.,  3009.,  1365.,
        1836.,  1800.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00015.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 157,  970,  378, 1047],
       [ 607,  732,  763,  874],
       [  77,  586,  188,  666],
       [ 265,  491,  357,  566],
       [ 450,  451,  509,  493],
       [ 550,  461,  615,  524],
       [ 619,  520,  696,  580],
       [ 771,  493,  840,  564],
       [1263,  497, 1340,  566],
       [1446,  545, 1536,  601],
       [ 707,  420,  750,  457],
       [1124,  393, 1174,  445],
       [1025,  382, 1077,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17316., 22451.,  9072.,  7068.,  2580.,  4224.,  4758.,  5040.,
        5460.,  5187.,  1672.,  2703.,  2173.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00016.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[  27,  588,  167,  689],
       [ 398,  720,  540,  836],
       [ 665,  666,  790,  795],
       [ 400,  559,  498,  653],
       [ 332,  526,  403,  586],
       [ 638,  497,  702,  549],
       [ 811,  472,  869,  522],
       [ 482,  455,  548,  493],
       [1655,  672, 1817,  772],
       [1294,  451, 1357,  488],
       [1159,  426, 1221,  472],
       [ 536,  405,  584,  447],
       [ 719,  401,  763,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14382., 16731., 16380.,  9405.,  4392.,  3445.,  3009.,  2613.,
       16463.,  2432.,  2961.,  2107.,  1935.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00017.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  792,  208,  982],
       [  61,  678,  190,  778],
       [ 477,  655,  584,  753],
       [ 748,  622,  840,  711],
       [ 342,  534,  425,  597],
       [ 411,  461,  471,  509],
       [ 665,  464,  730,  522],
       [ 550,  411,  598,  449],
       [ 494,  386,  544,  430],
       [1219,  618, 1350,  728],
       [1423,  659, 1548,  738],
       [1394,  514, 1480,  580],
       [1202,  391, 1255,  430],
       [1096,  378, 1148,  416],
       [ 652,  388,  700,  424]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([39919., 13130., 10692.,  8370.,  5376.,  2989.,  3894.,  1911.,
        2295., 14652., 10080.,  5829.,  2160.,  2067.,  1813.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00018.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1275,  707, 1402,  809],
       [1516,  699, 1656,  809],
       [1844,  972, 1919, 1044],
       [1642,  618, 1823,  766],
       [1244,  507, 1321,  564],
       [1103,  474, 1186,  541],
       [1261,  434, 1327,  478],
       [  50,  688,  198,  795],
       [ 534,  582,  646,  680],
       [ 186,  551,  282,  624],
       [ 457,  461,  525,  511],
       [ 605,  434,  663,  474],
       [ 713,  426,  761,  457],
       [ 411,  422,  478,  478],
       [ 567,  349,  628,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([13184., 15651.,  5548., 27118.,  4524.,  5712.,  3015., 16092.,
       11187.,  7178.,  3519.,  2419.,  1568.,  3876.,  4464.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00019.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 148,  928,  377, 1043],
       [ 300,  545,  394,  614],
       [ 269,  493,  361,  559],
       [ 523,  505,  598,  555],
       [ 650,  509,  715,  557],
       [ 507,  372,  590,  474],
       [ 703,  420,  753,  464],
       [1184,  845, 1346,  988],
       [1317,  741, 1477,  880],
       [1405,  591, 1542,  720],
       [1661,  689, 1796,  768],
       [1390,  482, 1496,  576],
       [1296,  530, 1380,  595],
       [1130,  516, 1202,  570],
       [1053,  409, 1109,  451],
       [1148,  430, 1207,  472],
       [1177,  382, 1228,  424]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([26680.,  6650.,  6231.,  3876.,  3234.,  8652.,  2295., 23472.,
       22540., 17940., 10880., 10165.,  5610.,  4015.,  2451.,  2580.,
        2236.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00020.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1128,  864, 1288, 1014],
       [1621,  759, 1869,  957],
       [1144,  524, 1228,  597],
       [1027,  513, 1098,  568],
       [1411,  526, 1488,  578],
       [1236,  478, 1323,  549],
       [1261,  418, 1336,  478],
       [1190,  443, 1250,  489],
       [1067,  430, 1117,  470],
       [   0,  709,  136,  826],
       [  17,  588,  155,  705],
       [ 340,  632,  459,  724],
       [ 488,  659,  609,  759],
       [ 632,  499,  702,  568],
       [ 394,  422,  511,  541]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([24311., 49551.,  6290.,  4032.,  4134.,  6336.,  4636.,  2867.,
        2091., 16166., 16402., 11160., 12322.,  4970., 14160.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00021.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1540,  939, 1763, 1041],
       [1788,  738, 1919,  856],
       [1328,  547, 1455,  651],
       [1019,  572, 1102,  647],
       [   2,  978,   82, 1045],
       [ 450,  668,  578,  793],
       [ 182,  501,  373,  674],
       [ 436,  426,  488,  461],
       [ 552,  403,  600,  445],
       [ 625,  332,  705,  447],
       [ 723,  384,  767,  418],
       [1069,  430, 1125,  482],
       [1153,  414, 1211,  466],
       [1277,  441, 1338,  482],
       [ 977,  405, 1015,  441],
       [1188,  372, 1240,  422],
       [ 821,  384,  861,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([23072., 15708., 13440.,  6384.,  5508., 16254., 33408.,  1908.,
        2107.,  9396.,  1575.,  3021.,  3127.,  2604.,  1443.,  2703.,
        1230.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00022.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  653,   61,  886],
       [ 288,  497,  369,  545],
       [ 473,  447,  538,  505],
       [ 555,  361,  675,  518],
       [ 686,  443,  740,  491],
       [ 805,  439,  859,  480],
       [1221,  595, 1317,  676],
       [1463,  539, 1553,  609],
       [1205,  449, 1282,  518],
       [ 982,  455, 1034,  505]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14040.,  4018.,  3894., 19118.,  2695.,  2310.,  7954.,  6461.,
        5460.,  2703.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00023.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  630,  117,  713],
       [ 415,  409,  617,  641],
       [ 344,  513,  430,  601],
       [ 588,  549,  675,  634],
       [ 757,  534,  834,  601],
       [1502,  628, 1650,  728],
       [1105,  476, 1167,  518],
       [1305,  447, 1369,  497],
       [1136,  397, 1194,  447],
       [ 725,  403,  777,  445],
       [ 953,  395,  996,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 9744., 47299.,  7743.,  7568.,  5304., 15049.,  2709.,  3315.,
        3009.,  2279.,  1584.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00024.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 280,  816,  475, 1007],
       [ 642,  772,  777,  911],
       [ 107,  486,  486,  893],
       [ 669,  480,  734,  538],
       [1453,  678, 1600,  766],
       [1840,  784, 1919,  895],
       [1265,  482, 1350,  547]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 37632.,  19040., 155040.,   3894.,  13172.,   8960.,   5676.],
      dtype=float32), 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00025.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  674,  178, 1043],
       [ 523,  624,  632,  720],
       [1405,  638, 1528,  713],
       [1453,  547, 1555,  613],
       [1267,  522, 1346,  576],
       [ 792,  432,  838,  478],
       [ 621,  416,  675,  457],
       [ 434,  403,  496,  461],
       [1152,  414, 1211,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([65490., 10670.,  9424.,  6901.,  4400.,  2209.,  2310.,  3717.,
        2520.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00026.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1357,  793, 1515,  924],
       [1528,  695, 1694,  816],
       [1244,  499, 1317,  549],
       [1292,  444, 1352,  485],
       [1173,  438, 1227,  486],
       [ 746,  524,  819,  580],
       [ 542,  478,  607,  539],
       [ 302,  464,  394,  538],
       [ 802,  438,  852,  480],
       [ 713,  395,  759,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20988., 20374.,  3774.,  2562.,  2695.,  4218.,  4092.,  6975.,
        2193.,  1974.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00027.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1388,  828, 1571,  957],
       [1542,  591, 1663,  682],
       [1146,  541, 1227,  607],
       [1315,  509, 1403,  576],
       [ 636,  720,  763,  838],
       [ 363,  597,  473,  688],
       [  55,  561,  192,  678],
       [ 757,  532,  838,  593],
       [ 659,  459,  721,  513],
       [1159,  422, 1213,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([23920., 11224.,  5494.,  6052., 15232., 10212., 16284.,  5084.,
        3465.,  2365.], dtype=float32), 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00028.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   3,  897,  119, 1047],
       [ 646,  747,  782,  880],
       [ 538,  578,  642,  672],
       [1746,  743, 1919,  845],
       [1167,  553, 1252,  618],
       [1352,  476, 1425,  532],
       [1065,  439, 1119,  480],
       [1219,  422, 1277,  466],
       [ 790,  468,  846,  511],
       [ 503,  422,  569,  476],
       [ 627,  420,  677,  461]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17667., 18358.,  9975., 17922.,  5676.,  4218.,  2310.,  2655.,
        2508.,  3685.,  2142.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00029.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1476,  936, 1679, 1045],
       [1452,  555, 1546,  614],
       [1084,  443, 1136,  489],
       [1244,  411, 1302,  453],
       [ 161,  932,  388, 1039],
       [ 727,  591,  817,  670],
       [ 527,  509,  602,  563],
       [ 392,  489,  480,  551],
       [ 786,  459,  840,  505],
       [ 690,  445,  750,  493],
       [ 434,  434,  486,  476],
       [ 628,  422,  673,  466],
       [ 728,  399,  778,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([22440.,  5700.,  2491.,  2537., 24624.,  7280.,  4180.,  5607.,
        2585.,  2989.,  2279.,  2070.,  2397.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00030.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 542,  964,  723, 1045],
       [1828,  999, 1919, 1047],
       [1292,  722, 1423,  811],
       [1580,  634, 1719,  724],
       [1186,  580, 1275,  651],
       [1303,  461, 1371,  503],
       [ 255,  688,  400,  799],
       [ 173,  591,  311,  701],
       [ 563,  566,  665,  655],
       [ 730,  578,  815,  651],
       [ 323,  497,  402,  563],
       [ 521,  513,  598,  568],
       [ 663,  474,  742,  539],
       [ 453,  414,  502,  449],
       [ 802,  426,  853,  470],
       [ 580,  374,  623,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([14924.,  4508., 11880., 12740.,  6480.,  2967., 16352., 15429.,
        9270.,  6364.,  5360.,  4368.,  5280.,  1800.,  2340.,  2156.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00031.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 559,  911,  727, 1041],
       [ 159,  955,  371, 1039],
       [ 273,  684,  407,  788],
       [ 505,  622,  632,  739],
       [  88,  614,  221,  711],
       [ 317,  476,  390,  534],
       [ 761,  514,  834,  591],
       [1390,  626, 1521,  713],
       [1561,  607, 1675,  680],
       [1369,  501, 1453,  557],
       [1136,  526, 1202,  570],
       [1094,  459, 1148,  501],
       [ 784,  468,  838,  516],
       [ 513,  413,  573,  470],
       [ 700,  422,  750,  466],
       [1221,  407, 1269,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([22139., 18105., 14175., 15104., 13132.,  4366.,  5772., 11616.,
        8510.,  4845.,  3015.,  2365.,  2695.,  3538.,  2295.,  1813.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00032.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 628,  743,  780,  909],
       [  11,  616,  134,  701],
       [ 702,  599,  796,  674],
       [ 403,  468,  490,  549],
       [ 621,  503,  692,  566],
       [1400,  691, 1536,  778],
       [1734,  745, 1919,  848],
       [1227,  486, 1309,  547],
       [1355,  478, 1434,  534],
       [ 517,  441,  573,  482],
       [1261,  432, 1321,  474],
       [1061,  432, 1109,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([25551., 10664.,  7220.,  7216.,  4608., 12056., 19344.,  5146.,
        4560.,  2394.,  2623.,  1813.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00033.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 477,  995,  646, 1047],
       [1432,  551, 1530,  611],
       [1886,  822, 1919,  889],
       [ 428,  688,  555,  797],
       [ 200,  564,  336,  689],
       [ 400,  509,  482,  568],
       [ 653,  486,  717,  553],
       [ 555,  480,  619,  526],
       [ 357,  466,  421,  511],
       [1175,  503, 1246,  553],
       [1144,  413, 1209,  463],
       [1250,  414, 1302,  457],
       [ 709,  414,  765,  451],
       [ 544,  405,  592,  438],
       [ 811,  393,  848,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 9010.,  6039.,  2312., 14080., 17262.,  4980.,  4420.,  3055.,
        2990.,  3672.,  3366.,  2332.,  2166.,  1666.,  1520.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00034.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 507,  636,  613,  745],
       [ 394,  595,  490,  676],
       [ 159,  632,  288,  720],
       [ 121,  568,  223,  639],
       [ 649,  497,  717,  549],
       [ 457,  461,  525,  505],
       [ 782,  459,  838,  514],
       [ 617,  420,  667,  461],
       [1227,  622, 1342,  713],
       [1494,  568, 1594,  628],
       [1286,  457, 1353,  501],
       [1073,  413, 1123,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11770.,  7954., 11570.,  7416.,  3657.,  3105.,  3192.,  2142.,
       10672.,  6161.,  3060.,  2091.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00035.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1209,  622, 1307,  695],
       [1827,  857, 1919, 1022],
       [   0,  899,  157, 1045],
       [ 496,  657,  619,  745],
       [ 719,  599,  817,  695],
       [ 292,  549,  384,  618],
       [ 530,  493,  609,  549],
       [ 791,  441,  847,  489],
       [ 502,  439,  561,  478],
       [1105,  476, 1173,  532],
       [1321,  459, 1386,  507],
       [1198,  403, 1252,  434],
       [ 732,  368,  769,  401],
       [ 503,  349,  571,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([ 7326., 15438., 23226., 11036.,  9603.,  6510.,  4560.,  2793.,
        2400.,  3933.,  3234.,  1760.,  1292.,  4554.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00036.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  747,   94,  870],
       [ 346,  624,  467,  716],
       [ 742,  557,  823,  632],
       [ 367,  516,  448,  574],
       [1452,  576, 1571,  661],
       [1094,  480, 1161,  530],
       [ 427,  378,  511,  459],
       [ 580,  388,  621,  420],
       [ 702,  405,  759,  453],
       [1044,  405, 1092,  449],
       [1227,  401, 1273,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11780., 11346.,  6232.,  4838., 10320.,  3468.,  6970.,  1386.,
        2842.,  2205.,  1833.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00037.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  974,   69, 1043],
       [ 563,  876,  738, 1043],
       [  69,  668,  217,  768],
       [ 313,  413,  428,  526],
       [ 646,  478,  719,  539],
       [1315,  738, 1455,  845],
       [1702,  720, 1873,  816],
       [1302,  459, 1378,  516],
       [ 784,  447,  834,  493],
       [ 615,  428,  661,  470],
       [ 517,  432,  573,  470],
       [1040,  405, 1086,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4900., 29568., 15049., 13224.,  4588., 15228., 16684.,  4466.,
        2397.,  2021.,  2223.,  1833.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00038.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1100,  738, 1227,  847],
       [1802,  770, 1919,  883],
       [ 103,  493,  275,  636],
       [ 398,  497,  477,  555],
       [ 494,  518,  567,  591],
       [ 730,  563,  811,  643],
       [ 515,  599,  627,  713],
       [ 696,  447,  753,  488],
       [ 471,  407,  517,  447],
       [1152,  530, 1228,  589],
       [1411,  532, 1502,  591],
       [1209,  403, 1267,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([14080., 13452., 24912.,  4720.,  5476.,  6642., 12995.,  2436.,
        1927.,  4620.,  5520.,  2537.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00039.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 128,  970,  336, 1043],
       [ 553,  895,  723, 1045],
       [ 177,  718,  327,  861],
       [ 177,  624,  296,  707],
       [ 605,  547,  688,  611],
       [ 359,  464,  428,  516],
       [1086,  699, 1213,  797],
       [1811,  789, 1919,  898],
       [1459,  561, 1565,  628],
       [1005,  509, 1077,  563],
       [1273,  443, 1330,  484],
       [1073,  441, 1127,  482],
       [ 725,  416,  769,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([15466., 25821., 21744., 10080.,  5460.,  3710., 12672., 11990.,
        7276.,  4015.,  2436.,  2310.,  1530.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00040.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 365,  795,  515,  930],
       [ 155,  559,  261,  630],
       [ 667,  486,  732,  543],
       [ 523,  391,  571,  434],
       [ 642,  357,  700,  430],
       [ 727,  407,  773,  439],
       [ 809,  384,  848,  413],
       [1692,  701, 1850,  791],
       [1455,  555, 1550,  614],
       [1007,  495, 1073,  543],
       [1305,  463, 1373,  509],
       [1182,  393, 1232,  424],
       [ 969,  416, 1015,  451],
       [1030,  384, 1069,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([20536.,  7704.,  3828.,  2156.,  4366.,  1551.,  1200., 14469.,
        5760.,  3283.,  3243.,  1632.,  1692.,  1480.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00041.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 515,  634,  627,  724],
       [ 452,  443,  515,  499],
       [ 671,  480,  736,  528],
       [ 582,  397,  665,  488],
       [ 792,  449,  848,  488],
       [ 725,  393,  775,  436],
       [1359,  699, 1503,  824],
       [1411,  526, 1496,  578],
       [1300,  453, 1361,  499],
       [1215,  399, 1257,  432],
       [ 971,  409, 1017,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([10283.,  3648.,  3234.,  7728.,  2280.,  2244., 18270.,  4558.,
        2914.,  1462.,  1739.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00042.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1486,  926, 1703, 1043],
       [1119,  751, 1253,  857],
       [1430,  653, 1552,  738],
       [1203,  511, 1280,  572],
       [1278,  438, 1338,  480],
       [ 742,  566,  827,  638],
       [ 538,  605,  632,  686],
       [ 319,  514,  413,  591],
       [ 469,  461,  588,  591],
       [ 680,  445,  748,  503],
       [ 807,  414,  861,  468],
       [ 632,  401,  682,  438],
       [ 557,  399,  607,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([25724., 14445., 10578.,  4836.,  2623.,  6278.,  7790.,  7410.,
       15720.,  4071.,  3025.,  1938.,  2091.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00043.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1548,  693, 1702,  801],
       [1248,  984, 1442, 1043],
       [1586,  605, 1717,  678],
       [1178,  564, 1277,  641],
       [1253,  503, 1332,  564],
       [1021,  513, 1092,  568],
       [ 540,  951,  734, 1047],
       [ 102, 1001,  290, 1041],
       [   9,  664,  177,  799],
       [ 202,  593,  403,  814],
       [ 588,  547,  680,  628],
       [ 761,  522,  840,  603],
       [ 563,  459,  628,  511],
       [ 477,  449,  544,  499],
       [ 798,  443,  855,  501],
       [1132,  416, 1180,  463],
       [ 471,  405,  523,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([16895., 11700.,  9768.,  7800.,  4960.,  4032., 18915.,  7749.,
       22984., 44844.,  7626.,  6560.,  3498.,  3468.,  3422.,  2352.,
        2279.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00044.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1552,  982, 1811, 1047],
       [1748,  716, 1919,  862],
       [1444,  668, 1575,  757],
       [1146,  757, 1288,  886],
       [1050,  570, 1138,  641],
       [1361,  528, 1444,  593],
       [1373,  478, 1446,  526],
       [1084,  443, 1138,  495],
       [1171,  428, 1225,  468],
       [ 980,  418, 1028,  457],
       [ 598,  801,  765,  982],
       [ 330,  779,  515,  954],
       [ 736,  572,  828,  676],
       [ 403,  570,  502,  643],
       [ 321,  545,  409,  605],
       [ 348,  470,  409,  514],
       [ 534,  428,  584,  476],
       [ 707,  395,  767,  441],
       [ 813,  391,  861,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17160., 25284., 11880., 18590.,  6408.,  5544.,  3626.,  2915.,
        2255.,  1960., 30576., 32736.,  9765.,  7400.,  5429.,  2790.,
        2499.,  2867.,  2499.], dtype=float32), 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00045.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  847,  148, 1032],
       [   0,  730,  117,  839],
       [ 102,  580,  217,  659],
       [ 415,  497,  492,  561],
       [ 652,  466,  727,  539],
       [ 786,  463,  855,  530],
       [ 488,  438,  550,  497],
       [ 434,  422,  490,  466],
       [1646,  839, 1842,  959],
       [1053,  626, 1152,  703],
       [1201,  576, 1313,  668],
       [1423,  522, 1553,  611],
       [1253,  514, 1332,  563],
       [1030,  516, 1100,  578],
       [1261,  439, 1323,  497],
       [ 994,  447, 1050,  491]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([27714., 12980.,  9280.,  5070.,  5624.,  4760.,  3780.,  2565.,
       23837.,  7800., 10509., 11790.,  4000.,  4473.,  3717.,  2565.],
      dtype=float32), 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00046.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1459,  895, 1740, 1041],
       [1530,  588, 1675,  678],
       [1315,  563, 1402,  616],
       [1280,  436, 1365,  491],
       [1161,  430, 1217,  472],
       [1090,  449, 1157,  503],
       [ 992,  466, 1044,  513],
       [ 977,  418, 1023,  457],
       [1200,  393, 1242,  428],
       [ 703,  622,  811,  732],
       [ 502,  599,  630,  709],
       [ 173,  620,  292,  716],
       [ 346,  513,  442,  586],
       [ 302,  493,  382,  547],
       [ 496,  447,  553,  493],
       [ 696,  428,  740,  468],
       [ 463,  416,  511,  451]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([41454., 13286.,  4752.,  4816.,  2451.,  3740.,  2544.,  1880.,
        1548., 12099., 14319., 11640.,  7178.,  4455.,  2726.,  1845.,
        1764.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00047.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 115, 1026,  309, 1047],
       [  69,  647,  221,  772],
       [  25,  609,  152,  697],
       [1778,  911, 1919, 1048],
       [1428,  636, 1561,  728],
       [1175,  561, 1290,  657],
       [1330,  466, 1425,  532],
       [1180,  447, 1238,  489],
       [1194,  378, 1257,  426],
       [ 615,  516,  682,  570],
       [ 353,  524,  440,  584],
       [ 359,  463,  425,  507],
       [ 600,  436,  648,  480],
       [ 798,  407,  834,  447],
       [ 467,  403,  517,  439],
       [1032,  388, 1080,  430],
       [ 955,  393,  992,  428],
       [ 573,  399,  609,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 4290., 19278., 11392., 19596., 12462., 11252.,  6432.,  2537.,
        3136.,  3740.,  5368.,  3015.,  2205.,  1517.,  1887.,  2107.,
        1368.,  1665.], dtype=float32), 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00048.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 394,  716,  530,  826],
       [  69,  668,  213,  766],
       [ 178,  551,  275,  609],
       [ 490,  522,  561,  574],
       [ 767,  497,  825,  551],
       [ 488,  453,  546,  491],
       [ 377,  453,  436,  488],
       [1182,  618, 1284,  689],
       [1390,  601, 1505,  691],
       [1844,  772, 1919,  890],
       [1259,  499, 1338,  559],
       [1078,  445, 1153,  503],
       [1227,  405, 1288,  449],
       [ 613,  418,  669,  459]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([15207., 14355.,  5782.,  3816.,  3245.,  2301.,  2160.,  7416.,
       10556.,  9044.,  4880.,  4484.,  2790.,  2394.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00049.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1677,  857, 1919, 1022],
       [ 657,  680,  763,  784],
       [ 234,  693,  371,  793],
       [ 225,  528,  313,  588],
       [ 340,  538,  425,  597],
       [ 452,  470,  525,  516],
       [ 523,  493,  598,  553],
       [ 673,  489,  738,  541],
       [1478,  547, 1584,  620],
       [1238,  482, 1311,  539],
       [1080,  474, 1142,  526],
       [1173,  426, 1227,  484],
       [ 790,  430,  844,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([40338., 11235., 13938.,  5429.,  5160.,  3478.,  4636.,  3498.,
        7918.,  4292.,  3339.,  3245.,  2145.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00050.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 509,  659,  621,  753],
       [ 328,  624,  444,  716],
       [ 275,  568,  371,  641],
       [  28,  703,  180,  803],
       [1736,  724, 1917,  828],
       [1348,  582, 1450,  668],
       [ 753,  523,  826,  591],
       [ 646,  488,  717,  547],
       [ 790,  430,  844,  472],
       [1309,  449, 1378,  501],
       [1150,  413, 1209,  463],
       [1027,  401, 1075,  436],
       [ 550,  405,  596,  445],
       [1105,  384, 1153,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([10735., 10881.,  7178., 15453., 19110.,  8961.,  5106.,  4320.,
        2365.,  3710.,  3060.,  1764.,  1927.,  2107.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00051.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   0,  786,   48,  889],
       [ 634,  747,  767,  870],
       [ 484,  659,  600,  755],
       [ 736,  524,  817,  582],
       [ 463,  453,  525,  501],
       [ 553,  405,  602,  447],
       [ 621,  411,  675,  459],
       [ 709,  411,  757,  449],
       [1850,  997, 1919, 1048],
       [1432,  534, 1525,  593],
       [1209,  470, 1278,  524],
       [1211,  393, 1263,  434],
       [1096,  374, 1144,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([ 5096., 16616., 11349.,  4838.,  3087.,  2150.,  2695.,  1911.,
        3640.,  5640.,  3850.,  2226.,  1666.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00052.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1796,  766, 1919,  902],
       [1382,  616, 1505,  699],
       [ 600,  749,  748,  878],
       [ 311,  545,  390,  611],
       [ 540,  478,  607,  545],
       [ 652,  480,  719,  528],
       [1286,  438, 1344,  482],
       [1136,  411, 1186,  451],
       [ 480,  457,  540,  499]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([16988., 10416., 19370.,  5360.,  4624.,  3332.,  2655.,  2091.,
        2623.], dtype=float32), 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00053.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  709,  136,  843],
       [ 346,  614,  473,  713],
       [ 527,  624,  632,  716],
       [ 327,  539,  423,  611],
       [ 436,  413,  488,  463],
       [ 548,  405,  602,  459],
       [1436,  663, 1559,  751],
       [1444,  541, 1552,  618],
       [1223,  484, 1298,  539],
       [1196,  388, 1248,  422],
       [ 794,  413,  842,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([18225., 12800.,  9858.,  7081.,  2703.,  3025., 11036.,  8502.,
        4256.,  1855.,  1715.], dtype=float32), 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00054.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[   2,  714,  163,  839],
       [ 315,  472,  384,  532],
       [ 442,  468,  521,  538],
       [ 767,  497,  828,  553],
       [ 600,  445,  659,  486],
       [1434,  636, 1605,  772],
       [1546,  595, 1663,  682],
       [1269,  505, 1346,  564],
       [1284,  445, 1357,  507],
       [1138,  416, 1194,  451],
       [ 557,  405,  611,  447],
       [ 469,  414,  519,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([20412.,  4270.,  5680.,  3534.,  2520., 23564., 10384.,  4680.,
        4662.,  2052.,  2365.,  2142.], dtype=float32), 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00055.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 665,  676,  777,  778],
       [ 244,  572,  361,  668],
       [  90,  570,  202,  657],
       [ 478,  541,  565,  599],
       [1382,  841, 1557,  966],
       [1427,  653, 1548,  741],
       [1261,  484, 1363,  576],
       [1346,  474, 1419,  524],
       [ 342,  474,  417,  522],
       [ 484,  455,  538,  507],
       [ 784,  451,  825,  489],
       [1196,  422, 1248,  468],
       [ 634,  409,  682,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([11639., 11446.,  9944.,  5192., 22176., 10858.,  9579.,  3774.,
        3724.,  2915.,  1638.,  2491.,  1715.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00056.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 203,  722,  353,  836],
       [ 103,  586,  211,  657],
       [ 328,  541,  417,  618],
       [ 727,  557,  802,  622],
       [ 569,  472,  632,  509],
       [ 673,  461,  734,  511],
       [ 796,  468,  861,  514],
       [1153,  564, 1252,  624],
       [1261,  513, 1330,  561],
       [1186,  418, 1252,  480],
       [ 477,  413,  525,  449],
       [ 628,  416,  673,  457],
       [1250,  407, 1296,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'seg_areas': array([17365.,  7848.,  7020.,  5016.,  2432.,  3162.,  3102.,  6100.,
        3430.,  4221.,  1813.,  1932.,  2209.], dtype=float32), 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00057.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 546,  838,  698,  978],
       [   2,  711,  142,  863],
       [ 503,  630,  617,  732],
       [ 728,  607,  819,  691],
       [ 438,  572,  534,  632],
       [ 342,  476,  405,  528],
       [ 552,  480,  615,  532],
       [ 719,  426,  767,  472],
       [1075,  447, 1125,  501],
       [1169,  434, 1227,  478],
       [1075,  691, 1188,  784],
       [1292,  732, 1434,  834],
       [1540,  741, 1709,  878],
       [1527,  605, 1642,  688]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([21573., 21573., 11845.,  7820.,  5917.,  3392.,  3392.,  2303.,
        2805.,  2655., 10716., 14729., 23460.,  9744.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00058.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[ 123,  789,  292,  916],
       [1109,  730, 1278,  905],
       [1552,  784, 1728,  889],
       [1573,  603, 1723,  714],
       [1292,  539, 1382,  611],
       [1342,  484, 1409,  538],
       [1128,  522, 1209,  578],
       [1000,  507, 1071,  561],
       [  77,  599,  188,  678],
       [ 395,  580,  488,  657],
       [ 650,  513,  719,  572],
       [ 486,  426,  559,  484],
       [ 613,  466,  678,  516],
       [ 613,  426,  678,  466]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([21760., 29920., 18762., 16912.,  6643.,  3740.,  4674.,  3960.,
        8960.,  7332.,  4200.,  4366.,  3366.,  2706.], dtype=float32), 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00059.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1409,  861, 1625, 1032],
       [1767,  930, 1919, 1047],
       [1292,  543, 1371,  611],
       [1375,  489, 1465,  555],
       [1007,  514, 1094,  572],
       [1182,  441, 1236,  497],
       [1063,  428, 1113,  468],
       [ 973,  420, 1017,  461],
       [1236,  414, 1292,  457],
       [ 475,  695,  588,  795],
       [   9,  824,  196,  961],
       [ 417,  593,  517,  678],
       [ 355,  501,  453,  570],
       [ 365,  451,  423,  491],
       [ 511,  516,  584,  570],
       [ 688,  451,  746,  491],
       [ 630,  413,  678,  451]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([37324., 18054.,  5520.,  6097.,  5192.,  3135.,  2091.,  1890.,
        2508., 11514., 25944.,  8686.,  6930.,  2419.,  4070.,  2419.,
        1911.], dtype=float32), 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00060.jpeg', 'flipped': False, 'width': 1920, 'boxes': array([[1413,  884, 1602, 1024],
       [1753,  905, 1915, 1047],
       [1590,  624, 1723,  718],
       [1380,  601, 1490,  674],
       [1177,  568, 1275,  655],
       [   2,  943,  115, 1041],
       [ 263,  684,  405,  780],
       [  90,  626,  267,  738],
       [ 146,  549,  252,  614],
       [ 571,  574,  667,  643],
       [ 550,  478,  607,  530],
       [ 696,  443,  746,  478],
       [1171,  449, 1225,  489],
       [ 973,  416, 1025,  472],
       [1263,  420, 1327,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'seg_areas': array([26790., 23309., 12730.,  8214.,  8712., 11286., 13871., 20114.,
        7062.,  6790.,  3074.,  1836.,  2255.,  3021.,  3185.],
      dtype=float32), 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00001.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 675,  911,  804, 1024],
       [ 346, 1018,  492, 1045],
       [ 237,  922,  391, 1022],
       [  96,  886,  237,  968],
       [ 319,  728,  435,  811],
       [ 512,  718,  592,  782],
       [ 633,  676,  748,  789],
       [1379,  647, 1487,  749],
       [1121,  641, 1181,  684],
       [1266,  603, 1310,  639],
       [1217,  580, 1256,  614],
       [ 629,  595,  681,  634],
       [ 735,  547,  798,  609],
       [ 673,  574,  714,  614],
       [ 860,  543,  894,  574],
       [ 816,  538,  854,  563],
       [1198,  541, 1231,  568],
       [1142,  532, 1179,  564]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00002.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 648,  939,  783, 1045],
       [   0,  901,  177, 1024],
       [ 614,  759,  706,  838],
       [ 521,  732,  612,  797],
       [ 396,  726,  481,  784],
       [ 802,  711,  873,  774],
       [ 733,  603,  816,  686],
       [ 637,  634,  696,  684],
       [ 502,  639,  579,  699],
       [1200,  753, 1285,  826],
       [1542,  732, 1710,  884],
       [1321,  645, 1383,  695],
       [1266,  613, 1321,  657],
       [1217,  564, 1252,  591],
       [1146,  530, 1192,  584],
       [ 789,  526,  846,  580],
       [ 700,  561,  746,  593],
       [1254,  524, 1287,  555],
       [1202,  524, 1241,  555]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00003.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 681,  882,  798,  978],
       [ 344,  732,  446,  803],
       [ 796,  720,  869,  780],
       [ 723,  655,  789,  711],
       [ 650,  643,  712,  689],
       [ 546,  643,  604,  684],
       [ 608,  589,  664,  639],
       [ 710,  588,  758,  624],
       [ 858,  626,  910,  670],
       [ 787,  561,  852,  624],
       [ 764,  538,  794,  564],
       [ 835,  509,  883,  553],
       [1423,  718, 1502,  784],
       [1341,  659, 1412,  722],
       [1298,  636, 1354,  684],
       [1242,  591, 1289,  628],
       [1162,  555, 1217,  626],
       [1217,  541, 1260,  580],
       [1271,  538, 1304,  568]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00004.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 604, 1016,  746, 1047],
       [   0,  976,   79, 1044],
       [1631,  845, 1767,  953],
       [1471,  738, 1571,  820],
       [1381,  693, 1460,  751],
       [ 800,  701,  869,  759],
       [ 514,  643,  583,  697],
       [1208,  601, 1275,  686],
       [ 852,  626,  904,  666],
       [ 789,  599,  837,  638],
       [ 729,  589,  775,  626],
       [ 642,  586,  687,  626],
       [ 898,  576,  935,  605],
       [ 831,  532,  883,  584],
       [ 771,  555,  810,  582],
       [1291,  632, 1350,  674],
       [1300,  559, 1342,  599],
       [1231,  564, 1287,  601],
       [1092,  534, 1125,  557]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00005.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[  60, 1007,  241, 1047],
       [ 535,  807,  650,  913],
       [ 271,  764,  466,  955],
       [ 773,  739,  850,  807],
       [1721,  880, 1877, 1009],
       [1529,  788, 1639,  868],
       [1289,  663, 1389,  782],
       [1379,  688, 1448,  743],
       [ 854,  618,  902,  655],
       [ 621,  595,  671,  636],
       [ 889,  576,  927,  609],
       [ 837,  561,  873,  591],
       [ 781,  561,  823,  588],
       [ 714,  559,  750,  588],
       [1264,  576, 1331,  647],
       [1344,  584, 1396,  636],
       [1094,  563, 1129,  597],
       [1227,  555, 1271,  591],
       [1289,  559, 1331,  593],
       [ 931,  543,  964,  568],
       [ 875,  514,  914,  559],
       [ 821,  534,  850,  559],
       [ 750,  532,  785,  566]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <23x16 sparse matrix of type '<type 'numpy.float32'>'
	with 23 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00006.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 712,  820,  827,  932],
       [ 506,  853,  629,  953],
       [  41,  897,  202,  993],
       [ 419,  778,  525,  859],
       [ 689,  682,  760,  747],
       [ 508,  655,  629,  772],
       [1833,  970, 1917, 1047],
       [1452,  795, 1641,  982],
       [1312,  616, 1404,  705],
       [1414,  624, 1475,  684],
       [ 841,  636,  896,  678],
       [1112,  607, 1158,  643],
       [1254,  584, 1306,  632],
       [1329,  588, 1377,  626],
       [ 687,  563,  735,  599],
       [ 891,  568,  929,  601],
       [ 767,  536,  800,  564],
       [1225,  538, 1260,  561]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00007.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 664,  978,  802, 1047],
       [ 460,  886,  596,  980],
       [ 302,  859,  441,  972],
       [ 369,  730,  462,  788],
       [ 679,  699,  754,  763],
       [ 583,  672,  656,  730],
       [ 814,  672,  885,  741],
       [ 760,  611,  817,  663],
       [ 629,  595,  719,  682],
       [1820,  961, 1919, 1053],
       [1148,  678, 1214,  738],
       [1400,  676, 1525,  784],
       [1514,  678, 1591,  751],
       [1291,  622, 1356,  674],
       [1398,  632, 1456,  676],
       [1291,  597, 1341,  624],
       [1264,  559, 1300,  589],
       [ 883,  580,  923,  613],
       [ 746,  538,  787,  572],
       [1191,  543, 1223,  576],
       [ 929,  541,  960,  568]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <21x16 sparse matrix of type '<type 'numpy.float32'>'
	with 21 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00008.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 629,  963,  767, 1045],
       [ 285,  876,  421,  966],
       [ 800,  739,  873,  799],
       [ 662,  714,  742,  774],
       [ 525,  716,  612,  786],
       [ 539,  645,  602,  686],
       [ 760,  628,  814,  672],
       [ 675,  611,  729,  655],
       [ 860,  603,  914,  649],
       [ 812,  572,  856,  613],
       [ 702,  557,  777,  626],
       [1258,  845, 1371,  941],
       [1569,  776, 1771,  938],
       [1512,  693, 1589,  751],
       [1362,  672, 1448,  738],
       [1377,  638, 1437,  680],
       [1317,  591, 1364,  626],
       [1227,  574, 1267,  607],
       [1189,  547, 1225,  582],
       [1089,  551, 1119,  586],
       [1025,  555, 1060,  582],
       [1273,  543, 1300,  568],
       [ 917,  547,  950,  574]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <23x16 sparse matrix of type '<type 'numpy.float32'>'
	with 23 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00009.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  997,   98, 1045],
       [ 535,  830,  652,  918],
       [ 329,  828,  452,  926],
       [ 785,  732,  860,  795],
       [ 517,  726,  600,  788],
       [ 850,  643,  900,  684],
       [ 756,  630,  804,  676],
       [ 635,  636,  700,  689],
       [ 637,  595,  687,  628],
       [1485,  751, 1608,  849],
       [1687,  788, 1800,  866],
       [1502,  707, 1592,  755],
       [1391,  636, 1448,  672],
       [1287,  613, 1337,  653],
       [1231,  574, 1275,  626],
       [1094,  595, 1137,  628],
       [1019,  591, 1066,  634],
       [1292,  561, 1331,  593],
       [ 814,  578,  854,  614],
       [ 739,  574,  781,  609],
       [ 896,  561,  939,  595],
       [1156,  563, 1191,  593],
       [1025,  553, 1058,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <23x16 sparse matrix of type '<type 'numpy.float32'>'
	with 23 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00010.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 691,  838,  812,  949],
       [ 325,  753,  429,  834],
       [ 535,  699,  614,  759],
       [ 685,  693,  758,  747],
       [ 631,  647,  689,  691],
       [ 841,  638,  892,  680],
       [ 712,  593,  758,  632],
       [ 808,  582,  848,  614],
       [ 708,  559,  748,  591],
       [ 883,  586,  923,  620],
       [ 852,  547,  891,  578],
       [ 787,  545,  823,  576],
       [1733,  907, 1919, 1043],
       [1716,  813, 1844,  895],
       [1500,  693, 1577,  747],
       [1375,  674, 1442,  728],
       [1291,  618, 1348,  670],
       [1123,  659, 1181,  711],
       [1025,  655, 1085,  709],
       [1100,  613, 1146,  651],
       [1183,  603, 1229,  639],
       [1327,  589, 1377,  632],
       [1246,  591, 1291,  624],
       [1019,  588, 1058,  628],
       [1087,  520, 1125,  570]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <25x16 sparse matrix of type '<type 'numpy.float32'>'
	with 25 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00011.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 123,  961,  319, 1045],
       [ 792,  686,  867,  751],
       [ 508,  651,  577,  705],
       [ 648,  626,  702,  676],
       [ 762,  616,  816,  661],
       [ 700,  595,  746,  632],
       [ 877,  582,  917,  614],
       [ 764,  559,  806,  593],
       [ 846,  549,  883,  576],
       [ 912,  553,  950,  580],
       [1054,  782, 1146,  870],
       [1210,  793, 1308,  874],
       [1537,  776, 1644,  855],
       [1689,  791, 1798,  870],
       [1387,  686, 1469,  759],
       [1148,  693, 1217,  749],
       [1029,  653, 1083,  705],
       [1244,  666, 1312,  722],
       [1398,  632, 1454,  676],
       [1296,  636, 1354,  678],
       [1337,  588, 1383,  626],
       [1258,  595, 1310,  639],
       [1010,  593, 1073,  653],
       [1092,  549, 1141,  605],
       [1154,  545, 1185,  578],
       [1206,  538, 1235,  561]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <26x16 sparse matrix of type '<type 'numpy.float32'>'
	with 26 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00012.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 166,  816,  325,  939],
       [ 446,  757,  560,  839],
       [ 756,  776,  852,  851],
       [1273,  863, 1396,  963],
       [1058,  778, 1146,  863],
       [1577,  799, 1719,  905],
       [1385,  797, 1492,  880],
       [1021,  659, 1108,  757],
       [1383,  699, 1466,  755],
       [1317,  641, 1389,  695],
       [1508,  691, 1583,  749],
       [1391,  630, 1460,  674],
       [1108,  572, 1171,  664],
       [1167,  578, 1202,  607],
       [ 844,  614,  894,  659],
       [ 614,  589,  667,  634],
       [ 716,  586,  754,  620],
       [ 812,  572,  854,  611],
       [ 756,  564,  794,  591]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00013.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1062,  807, 1198,  986],
       [1556,  813, 1677,  895],
       [1696,  791, 1814,  866],
       [1435,  709, 1525,  789],
       [1146,  632, 1254,  757],
       [1506,  682, 1587,  749],
       [ 831,  661,  892,  709],
       [ 596,  664,  671,  722],
       [ 416,  682,  516,  759],
       [ 892,  570,  927,  607],
       [ 762,  559,  802,  588],
       [ 691,  557,  733,  589],
       [1089,  570, 1125,  601],
       [1169,  572, 1206,  611],
       [1244,  576, 1279,  607]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00014.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1646,  841, 1800,  966],
       [1698,  776, 1817,  868],
       [1236,  754, 1425,  979],
       [1181,  741, 1256,  807],
       [1271,  684, 1335,  736],
       [1202,  616, 1262,  682],
       [1104,  613, 1156,  663],
       [1285,  607, 1325,  651],
       [1239,  572, 1285,  613],
       [1300,  564, 1342,  603],
       [ 241,  797,  354,  870],
       [ 554,  609,  623,  666],
       [ 685,  605,  742,  651],
       [ 871,  599,  919,  638],
       [ 754,  532,  791,  559],
       [ 919,  539,  952,  563]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00015.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1346,  980, 1504, 1045],
       [1406,  795, 1514,  874],
       [ 364, 1014,  516, 1047],
       [ 358,  847,  475,  924],
       [ 275,  772,  383,  847],
       [ 592,  786,  685,  863],
       [ 466,  680,  535,  730],
       [1156,  693, 1227,  766],
       [1275,  680, 1364,  770],
       [1333,  659, 1392,  709],
       [1277,  605, 1329,  651],
       [1352,  601, 1400,  639],
       [1296,  564, 1341,  601],
       [ 648,  568,  698,  611],
       [ 744,  572,  787,  607],
       [ 902,  561,  939,  588]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00016.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1289,  859, 1419,  974],
       [1433,  809, 1585,  957],
       [1435,  726, 1519,  793],
       [1335,  653, 1404,  707],
       [1431,  645, 1491,  699],
       [1352,  603, 1414,  649],
       [ 452,  918,  598, 1038],
       [ 390,  801,  494,  880],
       [ 741,  799,  835,  876],
       [ 616,  761,  706,  832],
       [ 554,  707,  629,  764],
       [ 481,  664,  550,  716],
       [ 717,  670,  779,  713],
       [ 592,  609,  644,  657],
       [ 721,  536,  767,  572],
       [ 791,  543,  831,  574],
       [1019,  547, 1066,  605],
       [1160,  561, 1194,  591],
       [1252,  532, 1294,  564]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00017.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1627,  855, 1762,  957],
       [1446,  716, 1537,  801],
       [1566,  724, 1654,  789],
       [1444,  655, 1529,  714],
       [ 346,  974,  537, 1045],
       [ 166,  966,  335, 1039],
       [ 142,  861,  281,  941],
       [ 406,  795,  514,  876],
       [ 654,  730,  737,  799],
       [ 567,  684,  642,  739],
       [ 729,  659,  787,  703],
       [ 658,  638,  710,  680],
       [ 594,  601,  648,  645],
       [ 825,  655,  887,  701],
       [ 785,  607,  839,  641],
       [ 671,  574,  717,  605],
       [1016,  589, 1075,  664],
       [1185,  607, 1231,  643],
       [1279,  549, 1321,  589],
       [1227,  557, 1252,  591],
       [1087,  547, 1127,  576],
       [ 783,  520,  819,  549]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <22x16 sparse matrix of type '<type 'numpy.float32'>'
	with 22 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00018.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1660,  857, 1808,  978],
       [1819,  857, 1919,  955],
       [1608,  741, 1744,  832],
       [1244,  678, 1314,  728],
       [1027,  664, 1110,  768],
       [ 616,  743,  719,  832],
       [ 271,  897,  404,  993],
       [ 458,  768,  550,  839],
       [ 441,  705,  517,  755],
       [ 571,  688,  642,  738],
       [ 752,  638,  806,  689],
       [ 664,  628,  719,  661],
       [ 721,  597,  764,  620],
       [ 667,  570,  721,  603],
       [ 791,  601,  829,  636],
       [ 870,  591,  910,  622],
       [ 835,  566,  873,  591],
       [1314,  572, 1367,  630],
       [1250,  588, 1296,  616],
       [1216,  557, 1258,  599],
       [1092,  570, 1135,  614]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <21x16 sparse matrix of type '<type 'numpy.float32'>'
	with 21 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00019.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1069,  826, 1214, 1018],
       [1387,  809, 1498,  891],
       [ 283,  761,  404,  838],
       [ 517,  736,  594,  801],
       [ 598,  674,  667,  724],
       [ 581,  622,  641,  659],
       [ 667,  624,  719,  668],
       [ 727,  643,  796,  703],
       [ 806,  589,  848,  628],
       [ 737,  582,  775,  616],
       [1019,  609, 1064,  641],
       [1117,  613, 1177,  663],
       [1302,  632, 1367,  678],
       [1375,  607, 1437,  668],
       [1252,  597, 1302,  632],
       [1152,  563, 1194,  595],
       [1027,  549, 1064,  586],
       [1294,  566, 1321,  593],
       [ 842,  561,  879,  588],
       [ 773,  563,  808,  591],
       [ 906,  553,  944,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <21x16 sparse matrix of type '<type 'numpy.float32'>'
	with 21 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00020.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1408,  705, 1494,  764],
       [1471,  657, 1556,  728],
       [1319,  643, 1383,  695],
       [1164,  678, 1250,  751],
       [1031,  693, 1094,  749],
       [ 487,  657,  558,  716],
       [ 637,  657,  692,  699],
       [ 791,  586,  839,  628],
       [ 689,  614,  742,  653],
       [ 731,  578,  773,  616],
       [ 669,  576,  717,  607],
       [1185,  599, 1233,  643],
       [1017,  589, 1058,  624],
       [1337,  593, 1373,  626],
       [1285,  557, 1316,  588],
       [ 848,  553,  887,  588],
       [ 783,  553,  819,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00021.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 604,  955,  771, 1041],
       [ 110,  874,  250,  963],
       [1081,  866, 1191,  970],
       [1260,  799, 1391,  918],
       [1617,  838, 1754,  932],
       [1427,  720, 1529,  797],
       [1252,  664, 1317,  728],
       [1023,  655, 1077,  707],
       [1642,  741, 1775,  847],
       [1402,  639, 1454,  678],
       [1327,  576, 1366,  618],
       [ 604,  603,  652,  643],
       [ 706,  605,  752,  647],
       [ 760,  580,  804,  609],
       [ 829,  551,  881,  582],
       [ 737,  549,  773,  580],
       [1221,  566, 1256,  597]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00022.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1667,  868, 1835,  989],
       [1389,  784, 1496,  882],
       [1060,  788, 1146,  864],
       [ 769,  718,  858,  795],
       [ 456,  697,  523,  747],
       [ 679,  566,  723,  595],
       [ 762,  566,  798,  597],
       [1523,  705, 1596,  761],
       [1391,  620, 1442,  659],
       [1254,  607, 1306,  638],
       [1175,  563, 1200,  589],
       [1085,  547, 1125,  589],
       [ 831,  549,  866,  576]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00023.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1760,  824, 1885,  911],
       [1492,  674, 1562,  728],
       [1321,  659, 1385,  701],
       [1192,  605, 1239,  639],
       [1096,  582, 1158,  641],
       [1291,  572, 1337,  611],
       [1227,  547, 1264,  584],
       [ 833,  620,  887,  674],
       [ 604,  613,  658,  653],
       [ 571,  793,  671,  872],
       [ 319,  838,  450,  938],
       [ 794,  545,  829,  572],
       [ 737,  547,  775,  574]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00024.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1677,  776, 1787,  845],
       [1452,  747, 1544,  813],
       [ 598,  778,  691,  845],
       [ 556,  689,  635,  747],
       [ 708,  674,  769,  720],
       [1125,  636, 1202,  720],
       [1246,  661, 1306,  714],
       [1350,  605, 1404,  647],
       [1246,  561, 1296,  616],
       [ 866,  568,  910,  603],
       [ 692,  568,  735,  597],
       [1142,  549, 1181,  578],
       [1071,  551, 1100,  580],
       [1214,  557, 1246,  595]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00025.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1731,  926, 1900, 1043],
       [1354,  764, 1446,  838],
       [1192,  734, 1300,  843],
       [1441,  655, 1508,  711],
       [1291,  609, 1352,  672],
       [1244,  588, 1285,  632],
       [1162,  576, 1206,  609],
       [1079,  588, 1121,  618],
       [1225,  551, 1260,  586],
       [ 719,  663,  781,  711],
       [ 667,  614,  719,  663],
       [ 777,  609,  827,  645],
       [ 891,  532,  925,  570]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00026.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1604,  747, 1700,  807],
       [1379,  663, 1464,  738],
       [1389,  964, 1785, 1045],
       [ 460,  895,  592,  993],
       [  27,  911,  191, 1003],
       [ 754,  793,  837,  861],
       [ 787,  607,  827,  641],
       [ 737,  564,  779,  599],
       [ 829,  568,  867,  595],
       [1106,  647, 1164,  699],
       [1200,  624, 1252,  666],
       [1294,  639, 1362,  684],
       [1256,  584, 1304,  636],
       [1094,  564, 1135,  611],
       [1166,  570, 1202,  605]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00027.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 375,  805,  498,  893],
       [ 375,  732,  466,  789],
       [ 666,  718,  737,  766],
       [ 841,  651,  892,  691],
       [ 823,  564,  871,  597],
       [1184,  759, 1265,  830],
       [1541,  766, 1681,  889],
       [1408,  709, 1496,  782],
       [1271,  699, 1341,  757],
       [1325,  639, 1381,  688],
       [1191,  613, 1233,  643],
       [1108,  597, 1162,  655],
       [1162,  561, 1202,  603],
       [1092,  547, 1123,  583]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00028.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1623,  845, 1771,  963],
       [1421,  838, 1550,  939],
       [1450,  716, 1535,  782],
       [1242,  666, 1308,  718],
       [1146,  657, 1214,  732],
       [1185,  599, 1242,  657],
       [1096,  588, 1141,  624],
       [ 452,  905,  594, 1009],
       [ 352,  805,  454,  876],
       [ 569,  674,  642,  739],
       [ 535,  647,  600,  688],
       [ 756,  626,  812,  668],
       [ 879,  586,  917,  626]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00029.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1716,  868, 1871,  999],
       [1354,  764, 1446,  843],
       [1223,  761, 1323,  857],
       [1231,  657, 1325,  734],
       [1116,  632, 1175,  686],
       [1346,  599, 1392,  638],
       [1252,  599, 1294,  634],
       [1300,  561, 1342,  597],
       [ 644,  959,  791, 1045],
       [ 346,  986,  508, 1045],
       [  54,  905,  204,  995],
       [ 667,  709,  744,  766],
       [ 519,  680,  587,  732],
       [ 669,  609,  731,  659],
       [ 639,  593,  681,  630],
       [ 806,  578,  844,  607],
       [1096,  569, 1129,  598]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00030.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1416, 1003, 1579, 1039],
       [1644, 1013, 1783, 1043],
       [1339,  759, 1492,  864],
       [1175,  714, 1254,  786],
       [ 791,  716,  867,  788],
       [ 633,  738,  717,  807],
       [ 412,  713,  492,  766],
       [ 764,  620,  810,  657],
       [ 619,  618,  671,  645],
       [1329,  657, 1389,  699],
       [1435,  653, 1498,  701],
       [1348,  599, 1402,  639],
       [1098,  607, 1152,  643],
       [ 735,  570,  789,  618],
       [1291,  561, 1346,  605],
       [1021,  582, 1066,  620]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00031.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1608,  993, 1879, 1051],
       [1296,  876, 1431, 1001],
       [1492,  766, 1587,  836],
       [1606,  747, 1698,  813],
       [1431,  645, 1502,  701],
       [1352,  599, 1419,  651],
       [1142,  670, 1200,  720],
       [1027,  641, 1073,  691],
       [   0,  832,  160, 1047],
       [ 346,  828,  467,  918],
       [ 742,  638,  796,  688],
       [ 575,  624,  625,  664],
       [ 850,  622,  902,  663],
       [1112,  603, 1162,  636],
       [1250,  605, 1292,  636],
       [ 683,  578,  725,  601],
       [ 823,  574,  858,  603]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00032.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 585,  803,  685,  882],
       [ 146,  672,  441,  914],
       [ 575,  676,  644,  736],
       [1050,  757, 1125,  838],
       [1233,  789, 1331,  874],
       [1587,  726, 1683,  799],
       [1456,  655, 1542,  726],
       [1335,  664, 1400,  718],
       [1146,  666, 1212,  718],
       [1389,  624, 1442,  670],
       [1029,  603, 1071,  638],
       [1104,  593, 1146,  626],
       [ 798,  582,  848,  618],
       [ 664,  576,  710,  613],
       [ 902,  566,  935,  601],
       [1162,  564, 1200,  599]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00033.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 529,  955,  683, 1041],
       [ 725,  663,  792,  713],
       [ 408,  601,  587,  753],
       [ 592,  670,  662,  716],
       [ 679,  601,  733,  641],
       [1239,  784, 1342,  864],
       [1508,  782, 1608,  857],
       [1641,  749, 1777,  845],
       [1514,  695, 1591,  751],
       [1039,  682, 1102,  734],
       [1137,  661, 1192,  701],
       [1191,  609, 1244,  655],
       [1344,  603, 1392,  641]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00034.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1085,  855, 1200,  953],
       [1748,  824, 1887,  913],
       [1225,  776, 1310,  845],
       [1256,  678, 1333,  751],
       [1441,  657, 1504,  709],
       [1269,  607, 1319,  649],
       [1171,  588, 1212,  618],
       [ 746,  728,  821,  807],
       [ 100,  859,  242,  943],
       [ 556,  559,  677,  664],
       [ 694,  599,  752,  641],
       [ 800,  595,  839,  638],
       [ 741,  564,  783,  601]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00035.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1414,  805, 1533,  909],
       [1604,  751, 1708,  820],
       [1352,  663, 1417,  707],
       [1208,  636, 1262,  676],
       [ 212,  901,  371, 1020],
       [ 396,  709,  483,  761],
       [ 823,  636,  875,  684],
       [ 642,  536,  742,  609],
       [ 767,  561,  808,  591],
       [1246,  584, 1292,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00036.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1512,  768, 1610,  847],
       [1285,  720, 1364,  776],
       [ 462,  886,  598, 1001],
       [ 504,  724,  592,  793],
       [ 552,  636,  604,  670],
       [1312,  628, 1364,  670],
       [1337,  597, 1377,  632],
       [1096,  578, 1148,  626],
       [ 867,  582,  906,  626]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00037.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1464,  884, 1606,  995],
       [ 248,  895,  398,  995],
       [ 675,  700,  744,  771],
       [ 644,  636,  702,  688],
       [1125,  639, 1192,  707],
       [1017,  624, 1067,  655],
       [ 648,  580,  700,  614],
       [1416,  705, 1487,  764],
       [1419,  643, 1481,  686],
       [1344,  597, 1389,  634]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00038.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 239,  886,  389,  993],
       [1225,  770, 1331,  872],
       [1637,  849, 1766,  945],
       [1581,  732, 1671,  797],
       [1035,  726, 1104,  782],
       [ 531,  713,  608,  770],
       [ 769,  618,  817,  661],
       [ 729,  582,  769,  628],
       [1423,  649, 1489,  688],
       [1325,  591, 1375,  636],
       [1016,  561, 1058,  597]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00039.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1104, 1001, 1237, 1047],
       [1573,  726, 1666,  786],
       [1402,  649, 1469,  695],
       [1327,  582, 1394,  634],
       [1219,  528, 1279,  599],
       [1016,  613, 1071,  651],
       [ 521,  709,  610,  774],
       [ 329,  745,  421,  805],
       [ 662,  630,  714,  668],
       [ 823,  574,  860,  609]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00040.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 348,  928,  542, 1043],
       [ 327,  859,  454,  945],
       [ 521,  639,  585,  689],
       [1033,  707, 1110,  780],
       [1546,  732, 1635,  801],
       [1400,  622, 1489,  693],
       [1254,  563, 1333,  647],
       [1119,  624, 1177,  663],
       [ 652,  626,  714,  676],
       [ 735,  578,  777,  611],
       [1096,  568, 1139,  622],
       [1160,  563, 1202,  603],
       [1881,  891, 1919,  982]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00041.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1117,  961, 1271, 1045],
       [ 637,  718,  729,  805],
       [ 556,  703,  629,  755],
       [1177,  711, 1246,  766],
       [1848,  903, 1916, 1028],
       [1542,  688, 1667,  789],
       [1314,  603, 1423,  714],
       [1119,  618, 1183,  691],
       [1189,  601, 1248,  659],
       [ 637,  589,  681,  624],
       [ 733,  576,  779,  614],
       [ 794,  551,  829,  574],
       [1206,  530, 1250,  576]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00042.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1825,  811, 1917,  955],
       [1310,  901, 1444, 1003],
       [ 285,  843,  423,  943],
       [ 741,  620,  804,  680],
       [ 669,  624,  727,  668],
       [1189,  724, 1283,  826],
       [1444,  672, 1598,  830],
       [1260,  674, 1344,  747],
       [1225,  549, 1281,  607],
       [1087,  578, 1137,  609],
       [ 796,  547,  833,  576],
       [ 716,  551,  754,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00043.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1716,  834, 1916, 1047],
       [1366,  934, 1550, 1045],
       [1414,  811, 1558,  932],
       [1644,  768, 1746,  836],
       [ 383,  801,  494,  882],
       [ 298,  759,  406,  839],
       [ 504,  691,  583,  753],
       [ 802,  570,  854,  618],
       [ 741,  578,  785,  614],
       [1110,  620, 1160,  664],
       [1262,  576, 1331,  651],
       [1166,  574, 1212,  614]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00044.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1158,  699, 1229,  757],
       [ 456,  772,  552,  845],
       [ 587,  672,  656,  724],
       [ 498,  653,  577,  709],
       [ 606,  611,  671,  661],
       [1208,  624, 1262,  674],
       [1323,  630, 1429,  718],
       [ 846,  541,  889,  578],
       [ 806,  547,  837,  576],
       [1206,  543, 1241,  578]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00045.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1271,  859, 1392,  959],
       [1473,  709, 1610,  832],
       [1291,  697, 1369,  772],
       [ 712,  789,  817,  888],
       [ 523,  822,  629,  913],
       [ 256,  884,  402,  989],
       [ 621,  659,  689,  703],
       [ 692,  603,  742,  639],
       [ 619,  597,  673,  639],
       [ 685,  570,  729,  607],
       [1231,  570, 1269,  609]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00046.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1758,  876, 1916, 1045],
       [1471,  845, 1610,  963],
       [1716,  786, 1848,  872],
       [ 127,  789,  323,  930],
       [ 539,  703,  617,  763],
       [ 694,  678,  756,  741],
       [ 816,  655,  877,  713],
       [1273,  611, 1327,  659],
       [ 717,  597,  760,  632],
       [ 692,  564,  741,  601],
       [ 762,  561,  808,  593]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00047.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 517,  834,  648,  936],
       [ 416,  663,  535,  755],
       [ 667,  618,  727,  666],
       [ 777,  609,  821,  653],
       [ 862,  593,  906,  632],
       [1366,  678, 1431,  730]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <6x16 sparse matrix of type '<type 'numpy.float32'>'
	with 6 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00048.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 177,  916,  381, 1047],
       [1541,  791, 1648,  872],
       [ 691,  688,  767,  753],
       [ 562,  601,  642,  666],
       [1292,  566, 1352,  607],
       [ 744,  570,  791,  605],
       [ 831,  566,  867,  601],
       [ 898,  553,  931,  588]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00049.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 516,  714,  617,  803],
       [ 769,  616,  827,  664],
       [ 652,  563,  717,  614],
       [1346,  601, 1419,  645],
       [1114,  572, 1144,  613],
       [1158,  543, 1187,  570]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <6x16 sparse matrix of type '<type 'numpy.float32'>'
	with 6 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00050.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  884,  291, 1043],
       [ 533,  822,  637,  897],
       [ 650,  628,  721,  689],
       [ 817,  572,  862,  611],
       [1439,  647, 1546,  713],
       [1129,  620, 1175,  661],
       [1029,  557, 1071,  591],
       [1171,  566, 1204,  601],
       [ 719,  532,  777,  580]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00051.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 648,  928,  787, 1045],
       [ 389,  953,  556, 1045],
       [   0,  924,  158, 1021],
       [ 379,  707,  550,  870],
       [ 664,  682,  729,  732],
       [1610,  730, 1777,  841],
       [1177,  701, 1246,  755],
       [1017,  597, 1069,  639],
       [1192,  601, 1235,  643],
       [1246,  580, 1285,  611],
       [1094,  561, 1133,  597],
       [1162,  572, 1200,  613],
       [ 729,  572,  781,  622]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00052.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1296,  855, 1408,  951],
       [1025,  664, 1089,  730],
       [1237,  651, 1296,  705],
       [1294,  622, 1346,  666],
       [1183,  605, 1239,  651],
       [1104,  601, 1152,  638],
       [1333,  589, 1387,  645],
       [ 785,  716,  869,  788],
       [ 635,  736,  723,  807],
       [ 354,  736,  450,  789],
       [  52,  845,  250,  980],
       [ 562,  618,  664,  736],
       [ 735,  609,  775,  649]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00053.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1066,  809, 1179,  939],
       [1327,  736, 1408,  809],
       [1389,  693, 1466,  753],
       [1416,  639, 1483,  699],
       [1233,  661, 1300,  718],
       [1135,  657, 1212,  730],
       [1279,  607, 1321,  641],
       [1091,  574, 1131,  614],
       [ 727,  776,  842,  878],
       [ 610,  772,  700,  845],
       [ 381,  813,  491,  888],
       [ 106,  876,  246,  959],
       [ 387,  695,  498,  780],
       [ 525,  641,  587,  684],
       [ 735,  639,  800,  689],
       [ 654,  576,  733,  657],
       [ 850,  630,  900,  678],
       [ 773,  570,  810,  603],
       [1231,  568, 1262,  603]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00054.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1519,  897, 1666, 1026],
       [1221,  774, 1337,  891],
       [1581,  811, 1700,  905],
       [1321,  749, 1427,  836],
       [1544,  724, 1650,  813],
       [1360,  664, 1425,  720],
       [1264,  607, 1317,  647],
       [1106,  616, 1164,  676],
       [ 819,  657,  883,  722],
       [ 727,  661,  785,  713],
       [ 564,  693,  635,  745],
       [ 408,  720,  487,  778],
       [ 548,  614,  623,  678],
       [ 796,  586,  846,  622],
       [ 721,  545,  781,  611],
       [ 885,  576,  931,  614],
       [ 631,  589,  681,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00055.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1523,  924, 1696, 1045],
       [1823,  880, 1919, 1039],
       [1525,  772, 1635,  851],
       [1162,  695, 1241,  778],
       [1350,  664, 1412,  711],
       [1342,  597, 1387,  634],
       [ 679,  882,  800,  978],
       [ 554,  632,  612,  676],
       [ 662,  626,  717,  664],
       [ 792,  603,  841,  636],
       [ 864,  589,  919,  630],
       [ 646,  570,  702,  618]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00056.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 100,  759,  477, 1039],
       [ 596,  784,  691,  857],
       [ 792,  701,  864,  757],
       [1302,  861, 1435, 1003],
       [1492,  759, 1589,  832],
       [1427,  645, 1492,  695],
       [1254,  609, 1306,  647],
       [1335,  597, 1381,  632],
       [ 733,  584,  773,  611],
       [ 642,  584,  694,  613],
       [1098,  586, 1141,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00057.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1835,  964, 1916, 1045],
       [   0,  972,   85, 1045],
       [ 560,  843,  667,  924],
       [ 425,  653,  627,  851],
       [ 717,  668,  781,  714],
       [ 844,  620,  892,  657],
       [1583,  730, 1677,  801],
       [1350,  676, 1419,  726],
       [1414,  641, 1469,  688],
       [1127,  643, 1183,  689],
       [1316,  582, 1362,  622],
       [1019,  570, 1056,  605]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00058.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1544,  801, 1660,  886],
       [1552,  720, 1642,  776],
       [1194,  741, 1277,  809],
       [1377,  624, 1439,  672],
       [1341,  584, 1387,  620],
       [1264,  603, 1304,  638],
       [1023,  634, 1071,  668],
       [ 752,  768,  842,  843],
       [ 708,  695,  773,  751],
       [ 133,  853,  258,  938],
       [ 300,  766,  408,  822],
       [ 577,  591,  708,  726],
       [ 779,  607,  823,  639],
       [ 881,  572,  919,  605]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00059.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1358,  984, 1521, 1053],
       [1835,  855, 1917,  957],
       [1491,  684, 1571,  753],
       [1333,  661, 1394,  711],
       [1046,  747, 1119,  811],
       [1408,  626, 1467,  674],
       [ 837,  645,  891,  688],
       [ 410,  709,  483,  768],
       [ 492,  666,  558,  709],
       [ 781,  622,  823,  661],
       [ 669,  563,  769,  657],
       [1098,  588, 1142,  614],
       [1169,  557, 1210,  601],
       [1292,  557, 1327,  595]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_1_00060.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 135,  974,  304, 1045],
       [ 750,  759,  831,  818],
       [ 548,  632,  602,  678],
       [ 602,  603,  652,  638],
       [ 729,  534,  810,  609],
       [ 877,  582,  919,  618],
       [ 816,  576,  856,  605],
       [1698,  801, 1833,  903],
       [1473,  755, 1566,  818],
       [1519,  688, 1598,  755],
       [1125,  632, 1175,  678],
       [1016,  607, 1067,  655],
       [1194,  595, 1250,  647],
       [1329,  588, 1381,  626],
       [1106,  584, 1144,  616],
       [1242,  586, 1291,  624]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00001.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1769,  884, 1916, 1043],
       [   0,  891,  289, 1040],
       [ 671,  688,  794,  795],
       [ 366,  647,  492,  730],
       [ 714,  497,  785,  549],
       [ 673,  413,  729,  470],
       [ 898,  401,  944,  436],
       [1504,  545, 1598,  613],
       [1335,  324, 1404,  407],
       [1146,  361, 1181,  393]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00002.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  991,   77, 1044],
       [1844,  778, 1919,  909],
       [ 427,  768,  579,  884],
       [ 552,  576,  673,  664],
       [ 829,  495,  900,  557],
       [ 596,  491,  673,  547],
       [1169,  409, 1217,  449],
       [ 806,  413,  854,  457],
       [ 739,  364,  789,  411],
       [1392,  349, 1479,  455],
       [1296,  380, 1335,  411],
       [1217,  382, 1258,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00003.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1485,  389, 1608,  530],
       [1217,  493, 1287,  553],
       [1350,  422, 1412,  470],
       [1256,  439, 1310,  472],
       [   0,  943,  100, 1046],
       [ 123,  647,  275,  751],
       [ 410,  616,  527,  691],
       [ 685,  538,  766,  599],
       [ 737,  461,  814,  514],
       [ 896,  411,  946,  451],
       [ 716,  416,  769,  459]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00004.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 275,  878,  479, 1020],
       [1348,  684, 1477,  793],
       [ 410,  595,  535,  688],
       [ 442,  488,  531,  547],
       [ 616,  478,  692,  530],
       [ 789,  439,  841,  480],
       [ 833,  393,  875,  439],
       [1337,  522, 1412,  582],
       [1177,  438, 1227,  484],
       [1479,  520, 1564,  584],
       [1648,  457, 1844,  659],
       [1294,  401, 1342,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00005.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 198,  897,  446, 1045],
       [ 221,  613,  344,  691],
       [ 637,  570,  729,  638],
       [ 627,  468,  698,  526],
       [1533,  718, 1681,  834],
       [1806,  730, 1919,  864],
       [1244,  561, 1337,  630],
       [1377,  461, 1446,  509],
       [ 602,  413,  664,  459],
       [ 727,  409,  775,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00006.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1494,  918, 1708, 1043],
       [ 527,  891,  717, 1034],
       [ 614,  566,  725,  655],
       [ 506,  472,  575,  522],
       [1558,  591, 1667,  666],
       [1254,  397, 1298,  434],
       [1075,  411, 1123,  453],
       [ 766,  457,  823,  499],
       [ 723,  401,  777,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00007.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 233,  607,  358,  693],
       [ 789,  566,  871,  636],
       [ 758,  449,  827,  503],
       [ 644,  401,  696,  443],
       [1081,  489, 1152,  549],
       [1339,  464, 1406,  511],
       [1348,  351, 1416,  411],
       [ 841,  391,  883,  426],
       [ 787,  353,  825,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00008.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1114,  657, 1233,  763],
       [ 316,  568,  435,  647],
       [ 506,  470,  583,  524],
       [1392,  366, 1475,  449],
       [1266,  380, 1308,  413],
       [ 877,  449,  933,  493],
       [ 831,  389,  879,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00009.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1150,  403, 1198,  445],
       [1464,  409, 1575,  514],
       [1325,  436, 1389,  480],
       [1381,  388, 1421,  422],
       [ 550,  453,  621,  509],
       [ 648,  401,  698,  445],
       [ 921,  391,  958,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00010.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1596,  466, 1748,  613],
       [1458,  530, 1546,  595],
       [1192,  486, 1267,  549],
       [1441,  422, 1491,  466],
       [ 671,  388,  721,  434],
       [1269,  359, 1317,  397],
       [ 733,  361,  773,  393],
       [1327,  355, 1369,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00011.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1760,  732, 1916,  855],
       [1321,  668, 1452,  791],
       [1823,  572, 1917,  722],
       [1533,  484, 1604,  532],
       [1317,  397, 1373,  447],
       [1369,  388, 1402,  434],
       [ 740,  359,  788,  394]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00012.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 662,  782,  800,  901],
       [1696,  566, 1794,  636],
       [1396,  453, 1466,  514],
       [1406,  418, 1456,  459],
       [1373,  384, 1414,  413],
       [1150,  374, 1187,  407],
       [1066,  364, 1104,  393],
       [1204,  355, 1242,  389]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00013.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1546,  549, 1664,  649],
       [ 821,  538,  896,  603],
       [1058,  414, 1102,  461],
       [1469,  472, 1539,  536],
       [1435,  420, 1487,  468],
       [1169,  428, 1225,  476],
       [1241,  409, 1285,  445],
       [1356,  370, 1398,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00014.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1602,  572, 1706,  655],
       [1235,  520, 1308,  595],
       [1077,  505, 1146,  564],
       [1321,  501, 1392,  557],
       [1544,  488, 1621,  543],
       [1410,  401, 1466,  443],
       [1239,  399, 1281,  430],
       [1067,  401, 1110,  430],
       [1337,  366, 1373,  401],
       [ 885,  434,  939,  480]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00015.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[  85,  588,  439,  893],
       [ 660,  693,  808,  816],
       [1146,  716, 1269,  834],
       [1406,  749, 1569,  899],
       [1575,  722, 1737,  843],
       [1760,  609, 1887,  695],
       [1496,  453, 1569,  505],
       [1291,  459, 1356,  507],
       [1075,  468, 1135,  509],
       [1385,  399, 1437,  441],
       [1142,  376, 1191,  416],
       [ 927,  380,  960,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00016.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 475,  447,  646,  611],
       [1116,  628, 1216,  709],
       [ 833,  495,  908,  559],
       [1419,  568, 1508,  641],
       [1650,  534, 1752,  611],
       [1469,  453, 1542,  509],
       [1175,  436, 1233,  489],
       [1144,  363, 1187,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00017.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1758,  868, 1917, 1028],
       [1625,  539, 1727,  609],
       [1241,  541, 1323,  622],
       [1171,  413, 1219,  461],
       [ 604,  816,  758,  951],
       [ 423,  741,  591,  891],
       [ 223,  722,  387,  824],
       [ 637,  380,  750,  501],
       [ 894,  407,  946,  451],
       [1219,  366, 1256,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00018.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1416,  809, 1616,  989],
       [ 481,  711,  617,  816],
       [ 319,  688,  450,  766],
       [   0,  807,   41,  889],
       [ 535,  526,  623,  589],
       [ 692,  518,  775,  591],
       [ 816,  541,  885,  599],
       [ 731,  343,  814,  434],
       [1223,  493, 1304,  561],
       [1260,  403, 1314,  449],
       [1310,  393, 1354,  437],
       [ 929,  361,  975,  391],
       [1350,  366, 1396,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00019.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1356,  666, 1496,  797],
       [1348,  478, 1435,  543],
       [1400,  399, 1456,  439],
       [ 721,  509,  792,  568],
       [ 352,  538,  462,  622],
       [ 591,  507,  664,  564],
       [ 679,  441,  741,  480],
       [ 800,  420,  850,  468],
       [ 889,  432,  933,  468],
       [ 792,  320,  867,  393],
       [1208,  363, 1248,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00020.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1573,  632, 1719,  747],
       [1512,  549, 1602,  613],
       [1479,  447, 1556,  507],
       [1242,  409, 1291,  449],
       [1316,  401, 1360,  432],
       [ 442,  611,  550,  693],
       [ 566,  436,  629,  495],
       [ 714,  430,  769,  470],
       [ 817,  420,  862,  455],
       [ 771,  382,  810,  416],
       [ 862,  372,  906,  399],
       [ 929,  366,  960,  412],
       [ 841,  303,  902,  366]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00021.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  716,  167,  850],
       [1825,  770, 1917,  889],
       [1625,  520, 1735,  611],
       [1308,  466, 1375,  534],
       [1387,  455, 1444,  501],
       [1316,  403, 1356,  436],
       [ 656,  468,  719,  518],
       [ 683,  378,  733,  420],
       [ 787,  378,  827,  409],
       [ 873,  374,  908,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00022.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1433,  576, 1537,  678],
       [1521,  555, 1616,  620],
       [ 483,  659,  644,  784],
       [ 379,  532,  483,  609],
       [1379,  449, 1435,  499],
       [1387,  384, 1441,  436],
       [ 766,  399,  806,  434],
       [ 762,  345,  804,  380]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00023.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 316,  843,  502,  980],
       [ 808,  588,  891,  653],
       [ 702,  488,  787,  563],
       [ 564,  443,  627,  497],
       [1760,  851, 1919, 1043],
       [1844,  764, 1919,  851],
       [1504,  539, 1594,  601],
       [1477,  441, 1546,  501]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00024.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1789,  728, 1917,  847],
       [1646,  526, 1750,  620],
       [ 646,  561,  739,  630],
       [ 883,  447,  941,  493],
       [ 796,  409,  860,  459],
       [ 664,  388,  719,  430],
       [1300,  376, 1342,  413],
       [1216,  355, 1254,  386]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00025.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1360,  432, 1416,  480],
       [1242,  391, 1281,  434],
       [1150,  382, 1191,  418],
       [1291,  374, 1325,  399],
       [ 767,  451,  829,  493],
       [ 933,  386,  967,  414],
       [ 860,  366,  902,  399],
       [ 746,  355,  787,  386],
       [1071,  353, 1112,  386]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00026.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 491,  699,  625,  791],
       [1485,  522, 1569,  584],
       [1292,  445, 1350,  499],
       [1175,  426, 1227,  482],
       [1341,  422, 1391,  455],
       [1066,  397, 1112,  439],
       [ 831,  397,  879,  434],
       [1137,  353, 1175,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00027.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1791,  732, 1917,  857],
       [ 375,  770,  577,  930],
       [ 764,  624,  875,  711],
       [ 317,  551,  435,  636],
       [ 712,  513,  779,  563],
       [1389,  534, 1477,  611],
       [1237,  518, 1321,  591],
       [1450,  501, 1527,  555],
       [1077,  476, 1150,  539],
       [1185,  468, 1246,  511],
       [1145,  392, 1197,  450],
       [1387,  403, 1431,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00028.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1387,  713, 1535,  859],
       [1637,  736, 1804,  876],
       [1710,  666, 1854,  770],
       [1121,  639, 1239,  772],
       [1258,  576, 1350,  661],
       [1548,  499, 1621,  549],
       [1158,  464, 1241,  553],
       [ 675,  532,  771,  613],
       [ 866,  474,  925,  522],
       [ 537,  447,  614,  501],
       [ 798,  424,  854,  466]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00029.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1477,  876, 1683, 1043],
       [1198,  624, 1335,  795],
       [ 129,  695,  279,  780],
       [1433,  418, 1500,  470],
       [ 781,  432,  850,  488],
       [ 656,  391,  714,  432],
       [ 910,  399,  962,  445],
       [ 858,  372,  904,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00030.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1594,  501, 1685,  570],
       [ 560,  655,  683,  738],
       [ 264,  657,  448,  791],
       [ 431,  528,  516,  582],
       [ 848,  382,  900,  414],
       [1146,  388, 1181,  420],
       [1227,  361, 1269,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00031.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  795,  254, 1011],
       [ 116,  663,  269,  757],
       [ 542,  501,  646,  591],
       [ 760,  478,  825,  532],
       [ 579,  443,  639,  484],
       [1267,  411, 1331,  480],
       [1164,  439, 1216,  480],
       [1291,  363, 1364,  428],
       [1225,  395, 1271,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00032.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 435,  555,  564,  672],
       [ 433,  501,  523,  557],
       [ 677,  424,  748,  486],
       [ 671,  393,  716,  430],
       [ 846,  397,  894,  434],
       [1139,  378, 1179,  411],
       [1212,  526, 1287,  582],
       [1371,  503, 1464,  593],
       [1283,  459, 1352,  518],
       [1339,  409, 1456,  491],
       [1292,  370, 1339,  422],
       [1221,  395, 1275,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00033.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1617,  688, 1823,  880],
       [1337,  705, 1464,  813],
       [1425,  580, 1535,  678],
       [1442,  457, 1612,  605],
       [1342,  413, 1408,  476],
       [1277,  451, 1341,  511],
       [1156,  438, 1208,  482],
       [ 308,  591,  419,  663],
       [ 617,  459,  704,  532],
       [ 592,  428,  652,  474],
       [ 758,  380,  814,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00034.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 208,  974,  429, 1045],
       [ 671,  789,  806,  895],
       [ 516,  476,  591,  534],
       [ 716,  397,  779,  455],
       [1654,  564, 1919,  838],
       [1385,  551, 1483,  636],
       [1208,  545, 1292,  613],
       [1444,  484, 1535,  566]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00035.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1391,  822, 1573,  972],
       [1664,  772, 1850,  918],
       [1658,  607, 1819,  755],
       [ 731,  664,  862,  774],
       [ 262,  672,  444,  809],
       [ 608,  607,  708,  682],
       [ 846,  522,  914,  576],
       [ 635,  414,  689,  449],
       [ 781,  363,  833,  407],
       [1369,  374, 1414,  416],
       [1285,  370, 1335,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00036.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 548,  853,  769, 1045],
       [ 273,  878,  477, 1018],
       [ 291,  691,  442,  784],
       [ 248,  507,  423,  659],
       [ 552,  507,  650,  586],
       [ 854,  489,  925,  553],
       [ 750,  474,  819,  528],
       [ 914,  422,  960,  455],
       [1444,  426, 1508,  474],
       [1319,  407, 1385,  451],
       [1073,  361, 1114,  399],
       [ 712,  376,  758,  405],
       [ 831,  336,  877,  374],
       [1321,  320, 1375,  386]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00037.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 798,  543,  898,  632],
       [ 631,  574,  727,  641],
       [ 573,  520,  656,  570],
       [ 489,  422,  604,  526],
       [ 685,  420,  750,  476],
       [ 904,  413,  956,  459],
       [ 823,  409,  873,  447],
       [1071,  416, 1125,  461],
       [1592,  505, 1689,  572],
       [1392,  455, 1475,  518],
       [1360,  341, 1433,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00038.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 592,  861,  762,  999],
       [ 127,  807,  314,  930],
       [ 258,  599,  383,  676],
       [ 466,  736,  604,  843],
       [1092,  514, 1171,  586],
       [1508,  530, 1625,  620],
       [1431,  376, 1531,  480],
       [ 764,  459,  829,  509],
       [ 879,  436,  933,  488],
       [ 702,  428,  752,  476],
       [ 619,  370,  687,  449],
       [ 754,  376,  806,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00039.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1154,  772, 1316,  945],
       [1696,  613, 1919,  828],
       [1556,  434, 1706,  582],
       [ 337,  861,  529, 1005],
       [  66,  826,  269,  968],
       [  71,  661,  260,  788],
       [ 485,  578,  587,  649],
       [ 694,  532,  771,  593],
       [ 804,  555,  881,  620],
       [ 510,  476,  577,  514]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00040.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1812,  538, 1919,  749],
       [ 231,  618,  356,  695],
       [ 454,  584,  558,  661],
       [ 660,  574,  756,  641],
       [ 423,  505,  531,  580],
       [ 644,  472,  712,  520],
       [ 787,  445,  844,  489],
       [ 877,  445,  935,  488],
       [ 633,  413,  689,  449],
       [1339,  413, 1391,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00041.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1425,  472, 1498,  522],
       [1402,  399, 1458,  447],
       [1298,  378, 1344,  413],
       [1146,  376, 1185,  413],
       [ 771,  455,  842,  503],
       [ 625,  476,  696,  534],
       [ 489,  480,  569,  528],
       [ 592,  420,  667,  470],
       [ 739,  413,  792,  449],
       [ 927,  386,  966,  414],
       [ 848,  391,  891,  424],
       [ 717,  370,  760,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00042.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1585,  580, 1694,  668],
       [ 300,  574,  410,  655],
       [ 631,  413,  681,  455],
       [ 721,  414,  771,  453],
       [ 842,  401,  881,  438],
       [ 698,  374,  754,  414],
       [1178,  428, 1226,  472],
       [1492,  451, 1573,  513],
       [1371,  416, 1425,  463],
       [1277,  370, 1317,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00043.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1654,  536, 1769,  626],
       [1229,  532, 1306,  589],
       [1485,  476, 1560,  541],
       [1450,  432, 1506,  474],
       [1314,  409, 1364,  441],
       [ 483,  705,  627,  818],
       [ 298,  572,  402,  645],
       [ 508,  470,  581,  524],
       [1081,  374, 1119,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00044.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1392,  772, 1544,  897],
       [1706,  582, 1823,  674],
       [1560,  493, 1644,  557],
       [1389,  466, 1450,  511],
       [1081,  424, 1129,  472],
       [ 696,  514,  779,  586],
       [ 279,  568,  398,  657],
       [ 510,  466,  577,  518],
       [ 629,  414,  691,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00045.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1769,  597, 1894,  693],
       [1519,  557, 1608,  624],
       [1100,  522, 1177,  588],
       [1387,  380, 1441,  438],
       [ 133,  782,  329,  920],
       [ 502,  463,  577,  522],
       [ 789,  430,  852,  478],
       [ 631,  403,  675,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00046.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1166,  743, 1308,  889],
       [1800,  753, 1917,  864],
       [1467,  422, 1539,  495],
       [1352,  380, 1394,  413],
       [1144,  372, 1183,  409],
       [  81,  807,  275,  926],
       [ 506,  553,  606,  628],
       [ 629,  397,  683,  441],
       [ 852,  376,  898,  418],
       [ 704,  370,  746,  405],
       [1275,  359, 1317,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00047.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1604,  491, 1717,  603],
       [1164,  418, 1219,  463],
       [1406,  413, 1452,  451],
       [1314,  399, 1364,  434],
       [ 527,  678,  646,  766],
       [ 485,  570,  579,  630],
       [ 664,  453,  731,  501],
       [ 706,  361,  754,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00048.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  814,   62,  907],
       [ 333,  678,  477,  770],
       [ 719,  513,  787,  566],
       [ 642,  461,  712,  507],
       [1216,  507, 1298,  570],
       [1375,  443, 1446,  499],
       [1491,  463, 1550,  507],
       [1237,  411, 1281,  447],
       [1289,  386, 1335,  426],
       [ 750,  399,  798,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00049.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1352,  714, 1508,  845],
       [1617,  528, 1694,  593],
       [1500,  522, 1592,  599],
       [1291,  468, 1348,  518],
       [1350,  436, 1410,  489],
       [ 194,  751,  364,  853],
       [ 327,  578,  439,  645],
       [ 583,  511,  667,  570],
       [ 804,  430,  852,  470],
       [ 737,  399,  785,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00050.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[  12,  807,  258,  989],
       [ 516,  664,  652,  788],
       [ 167,  641,  310,  730],
       [ 521,  549,  616,  613],
       [ 533,  470,  602,  512],
       [ 706,  428,  767,  474],
       [1744,  668, 1914,  793],
       [1400,  572, 1494,  645],
       [1479,  520, 1564,  593],
       [1252,  403, 1312,  463],
       [1142,  401, 1185,  439],
       [ 860,  384,  898,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00051.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1664,  801, 1841,  938],
       [1742,  682, 1894,  813],
       [1323,  464, 1408,  543],
       [1177,  464, 1239,  516],
       [1225,  389, 1267,  424],
       [ 512,  711,  637,  795],
       [ 458,  566,  577,  653],
       [ 285,  599,  398,  674],
       [ 710,  503,  796,  570],
       [ 454,  499,  541,  553],
       [ 662,  455,  729,  499],
       [ 650,  405,  708,  447],
       [ 779,  384,  827,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00052.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 544,  668,  669,  763],
       [ 710,  530,  783,  580],
       [ 635,  459,  714,  518],
       [ 517,  482,  585,  530],
       [ 598,  426,  660,  464],
       [ 806,  424,  864,  468],
       [ 746,  393,  802,  430],
       [1466,  586, 1604,  716],
       [1258,  578, 1360,  661],
       [1271,  445, 1331,  488]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00053.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1469,  878, 1675, 1043],
       [1371,  536, 1464,  597],
       [   0,  961,   89, 1048],
       [ 377,  651,  504,  732],
       [ 719,  509,  792,  564],
       [ 800,  443,  854,  480],
       [ 637,  411,  689,  455],
       [ 733,  399,  791,  441],
       [1060,  397, 1114,  443],
       [1244,  395, 1292,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00054.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1592,  724, 1752,  839],
       [ 141,  780,  325,  905],
       [ 406,  616,  519,  697],
       [ 608,  497,  685,  547],
       [1064,  461, 1139,  528],
       [1171,  455, 1233,  505],
       [1300,  457, 1371,  511],
       [1337,  413, 1387,  463],
       [1162,  411, 1206,  449],
       [ 802,  428,  856,  472]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00055.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1089,  603, 1206,  705],
       [1241,  564, 1327,  634],
       [1433,  561, 1544,  661],
       [1425,  484, 1502,  545],
       [1196,  484, 1262,  538],
       [   0,  774,   64,  887],
       [ 498,  555,  594,  630],
       [ 614,  484,  689,  541],
       [ 723,  424,  775,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00056.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1773,  828, 1919, 1045],
       [1421,  828, 1594,  988],
       [1287,  624, 1391,  713],
       [1608,  605, 1733,  709],
       [ 425,  759,  573,  880],
       [ 254,  716,  406,  820],
       [ 283,  503,  439,  649],
       [ 656,  453,  719,  505],
       [ 717,  411,  775,  457],
       [1414,  418, 1471,  463]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00057.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  970,  117, 1044],
       [ 467,  763,  617,  870],
       [ 271,  713,  433,  826],
       [ 185,  616,  335,  720],
       [ 531,  543,  614,  601],
       [ 673,  549,  756,  603],
       [ 508,  416,  606,  514],
       [ 737,  401,  789,  439],
       [1529,  482, 1608,  541],
       [1383,  391, 1429,  426],
       [ 787,  370,  833,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00058.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 423,  764,  589,  893],
       [ 379,  653,  491,  738],
       [ 523,  553,  621,  622],
       [ 441,  499,  535,  563],
       [ 689,  543,  775,  605],
       [ 654,  454,  725,  500],
       [ 781,  445,  835,  489],
       [ 631,  363,  706,  441],
       [1752,  607, 1879,  686],
       [1456,  438, 1514,  476],
       [1292,  380, 1339,  418],
       [1377,  391, 1417,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00059.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 514,  874,  762, 1043],
       [   0,  970,   79, 1043],
       [ 208,  614,  348,  714],
       [ 681,  545,  773,  614],
       [ 569,  522,  648,  574],
       [ 646,  468,  714,  522],
       [ 591,  428,  654,  476],
       [ 792,  449,  846,  497],
       [ 742,  403,  789,  441],
       [1591,  516, 1675,  568],
       [1448,  430, 1502,  476],
       [1366,  436, 1425,  478],
       [ 842,  388,  883,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_2_00060.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 194,  645,  319,  732],
       [ 348,  641,  477,  732],
       [ 798,  536,  906,  649],
       [ 458,  497,  546,  563],
       [ 671,  453,  729,  497],
       [ 781,  449,  846,  499],
       [ 721,  413,  773,  457],
       [1498,  528, 1592,  603],
       [1866,  661, 1919,  759],
       [1564,  503, 1635,  555],
       [1408,  403, 1464,  449],
       [ 850,  395,  892,  434],
       [ 683,  388,  725,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00001.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 237,  909,  462, 1041],
       [  37,  709,  202,  811],
       [ 560,  641,  669,  716],
       [ 708,  464,  771,  511],
       [1121,  622, 1233,  709],
       [1231,  522, 1323,  622],
       [1356,  528, 1439,  586],
       [1458,  503, 1535,  568],
       [1323,  397, 1375,  439],
       [1154,  405, 1196,  441],
       [ 742,  403,  781,  441],
       [ 635,  405,  692,  447],
       [ 685,  432,  737,  474],
       [1214,  382, 1256,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00002.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 156,  978,  410, 1038],
       [1385,  738, 1575,  951],
       [1622,  767, 1790,  892],
       [1708,  666, 1860,  778],
       [1194,  480, 1258,  536],
       [1406,  461, 1477,  522],
       [1260,  438, 1319,  489],
       [1067,  441, 1123,  482],
       [ 614,  591,  717,  676],
       [ 416,  522,  500,  582],
       [ 729,  488,  794,  534],
       [ 808,  401,  852,  439],
       [1073,  378, 1117,  413],
       [ 750,  389,  791,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00003.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1310,  638, 1416,  738],
       [1585,  582, 1704,  666],
       [1369,  541, 1466,  622],
       [1092,  559, 1169,  634],
       [ 592,  599,  716,  699],
       [ 746,  470,  815,  528],
       [ 585,  428,  650,  470],
       [1077,  434, 1141,  495],
       [ 808,  416,  854,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00004.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1675,  799, 1879,  980],
       [1185,  922, 1367, 1045],
       [ 333,  866,  527, 1001],
       [   0,  803,   77,  914],
       [1114,  559, 1212,  655],
       [ 744,  472,  819,  534],
       [1427,  424, 1479,  464],
       [ 825,  409,  873,  445],
       [1156,  393, 1196,  432],
       [ 692,  380,  742,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00005.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1225,  939, 1446, 1047],
       [1533,  491, 1604,  547],
       [ 171,  934,  433, 1043],
       [   0,  963,  112, 1045],
       [ 358,  559,  458,  626],
       [1189,  463, 1246,  509],
       [ 669,  559,  756,  628],
       [ 821,  409,  875,  451],
       [1150,  407, 1198,  443],
       [1333,  374, 1379,  407],
       [ 873,  366,  912,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00006.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1714,  595, 1827,  676],
       [1266,  580, 1348,  651],
       [1183,  474, 1252,  528],
       [1396,  409, 1448,  449],
       [ 212,  995,  406, 1047],
       [ 367,  638,  496,  714],
       [ 283,  568,  412,  664],
       [ 602,  586,  716,  672],
       [ 560,  457,  621,  503],
       [1150,  389, 1202,  428],
       [ 779,  455,  841,  499],
       [ 862,  364,  910,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00007.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1504,  916, 1696, 1047],
       [1271,  614, 1383,  707],
       [1496,  472, 1566,  524],
       [1210,  453, 1279,  505],
       [1152,  372, 1196,  414],
       [ 304,  668,  446,  774],
       [ 625,  599,  719,  672],
       [ 569,  503,  646,  557],
       [ 527,  451,  608,  514],
       [ 744,  457,  819,  514],
       [ 677,  397,  725,  432],
       [ 846,  395,  889,  424]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00008.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 427,  761,  589,  893],
       [ 260,  601,  381,  678],
       [1356,  580, 1471,  678],
       [1671,  572, 1783,  638],
       [ 556,  514,  641,  580],
       [ 762,  466,  821,  511],
       [ 671,  430,  727,  468],
       [1173,  422, 1231,  472],
       [1235,  405, 1279,  443],
       [ 823,  391,  875,  438],
       [1298,  374, 1344,  418],
       [ 658,  391,  716,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00009.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 691,  528,  771,  601],
       [  96,  628,  275,  757],
       [1225,  511, 1310,  582],
       [1312,  482, 1377,  538],
       [1358,  420, 1427,  482],
       [1439,  424, 1494,  461],
       [ 504,  480,  577,  530],
       [ 685,  432,  746,  482],
       [1154,  399, 1200,  434],
       [ 839,  403,  877,  430],
       [ 729,  380,  775,  414],
       [1208,  351, 1260,  403],
       [1833,  989, 1919, 1045]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00010.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1367,  713, 1525,  853],
       [1510,  647, 1635,  749],
       [ 458,  751,  608,  857],
       [ 264,  489,  523,  722],
       [ 796,  428,  850,  476],
       [ 631,  413,  687,  451],
       [ 767,  382,  814,  418],
       [1196,  480, 1258,  522],
       [1487,  505, 1591,  597],
       [1589,  514, 1667,  564],
       [1231,  384, 1296,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00011.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1775,  668, 1919,  820],
       [1308,  632, 1421,  724],
       [1275,  432, 1367,  516],
       [ 667,  788,  816,  905],
       [ 283,  895,  491, 1038],
       [ 704,  530,  779,  589],
       [ 585,  407,  714,  530]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00012.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1367,  503, 1504,  622],
       [ 648,  570,  741,  638],
       [ 842,  526,  916,  580],
       [ 798,  432,  848,  478],
       [ 731,  347,  810,  439],
       [ 671,  376,  721,  424],
       [1404,  403, 1452,  438],
       [1306,  378, 1348,  422],
       [1221,  368, 1266,  413],
       [1148,  388, 1183,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00013.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1567,  663, 1796,  855],
       [1500,  459, 1566,  514],
       [1362,  434, 1425,  482],
       [1260,  413, 1317,  474],
       [1171,  443, 1225,  488],
       [ 902,  424,  950,  463],
       [ 783,  447,  835,  488],
       [ 806,  320,  869,  384],
       [ 742,  349,  789,  382],
       [ 860,  384,  896,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00014.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1679,  559, 1783,  639],
       [1481,  514, 1577,  593],
       [1333,  484, 1425,  574],
       [1235,  551, 1319,  620],
       [ 808,  593,  892,  651],
       [ 616,  597,  717,  670],
       [ 264,  611,  383,  686],
       [1377,  389, 1427,  424],
       [ 852,  389,  891,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00015.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1410,  826, 1583,  976],
       [1506,  628, 1656,  776],
       [1750,  686, 1917,  830],
       [1564,  576, 1664,  649],
       [1456,  441, 1517,  486],
       [1242,  420, 1298,  461],
       [1312,  384, 1366,  422],
       [ 298,  664,  441,  774],
       [ 512,  478,  581,  524],
       [ 766,  463,  825,  511],
       [ 885,  461,  941,  497]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00016.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 208,  909,  446, 1041],
       [ 194,  757,  367,  866],
       [   6,  724,  175,  818],
       [ 300,  582,  402,  649],
       [ 573,  501,  650,  557],
       [ 648,  409,  692,  449],
       [ 841,  393,  883,  424],
       [ 929,  389,  969,  420],
       [1317,  491, 1389,  545],
       [1381,  439, 1452,  499],
       [1596,  518, 1681,  576],
       [1291,  380, 1333,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00017.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1877,  668, 1918,  778],
       [1477,  636, 1596,  726],
       [1521,  532, 1635,  618],
       [1339,  428, 1400,  468],
       [1402,  399, 1448,  436],
       [ 625,  576,  725,  655],
       [ 367,  547,  460,  611],
       [ 542,  538,  631,  601],
       [ 508,  476,  575,  522],
       [ 698,  418,  756,  461]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00018.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1842,  745, 1919,  884],
       [ 267,  813,  764, 1045],
       [ 581,  630,  694,  711],
       [ 767,  453,  831,  509],
       [ 687,  439,  750,  486],
       [ 535,  461,  604,  505],
       [1437,  507, 1529,  572],
       [1498,  459, 1564,  505],
       [1381,  391, 1421,  420],
       [1216,  378, 1254,  407],
       [ 783,  370,  823,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00019.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1677,  659, 1829,  768],
       [1691,  564, 1794,  630],
       [ 266,  897,  475, 1036],
       [ 723,  505,  898,  722],
       [ 596,  589,  714,  684],
       [ 637,  399,  691,  441],
       [1456,  436, 1521,  476],
       [1254,  422, 1304,  463],
       [ 842,  389,  887,  430],
       [ 773,  386,  819,  418],
       [ 696,  376,  741,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00020.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[  94,  788,  281,  916],
       [ 639,  572,  737,  649],
       [ 835,  405,  942,  547],
       [ 744,  464,  812,  522],
       [1323,  497, 1392,  547],
       [1602,  518, 1687,  564],
       [1156,  374, 1204,  426],
       [1269,  357, 1317,  397],
       [ 712,  372,  752,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00021.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 216,  922,  446, 1043],
       [ 462,  570,  556,  647],
       [ 771,  450,  835,  504],
       [ 891,  353,  966,  457],
       [ 817,  395,  871,  436],
       [1187,  426, 1258,  511],
       [1485,  636, 1602,  724],
       [1314,  395, 1377,  445],
       [1069,  353, 1114,  401],
       [1289,  376, 1327,  403],
       [1883,  659, 1919,  749],
       [1339,  363, 1379,  393]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00022.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[  87,  826,  289,  955],
       [ 635,  572,  737,  651],
       [ 625,  470,  691,  524],
       [ 842,  393,  883,  426],
       [ 929,  322,  992,  403],
       [ 873,  359,  908,  388],
       [1264,  532, 1387,  674],
       [1066,  403, 1127,  470],
       [1381,  447, 1477,  520],
       [1337,  416, 1389,  455],
       [1392,  397, 1439,  438],
       [1327,  355, 1369,  391],
       [1194,  345, 1229,  374]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00023.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 648,  770,  808,  922],
       [ 267,  695,  417,  793],
       [ 289,  591,  398,  666],
       [ 492,  576,  591,  638],
       [ 771,  451,  831,  503],
       [ 721,  411,  773,  453],
       [1521,  855, 1796, 1045],
       [1521,  545, 1675,  655],
       [1081,  493, 1171,  599],
       [1423,  482, 1491,  536],
       [1492,  457, 1552,  511],
       [1371,  384, 1421,  434],
       [1219,  386, 1262,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00024.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1141,  732, 1321,  968],
       [1821,  747, 1919,  922],
       [1594,  607, 1707,  695],
       [1685,  572, 1791,  645],
       [1448,  432, 1521,  489],
       [1283,  461, 1344,  509],
       [ 825,  516,  908,  589],
       [   0,  791,   92,  902],
       [ 356,  647,  487,  738],
       [ 552,  524,  635,  580],
       [ 506,  482,  575,  530],
       [ 656,  464,  723,  513],
       [ 783,  374,  825,  411],
       [ 842,  388,  889,  426],
       [1364,  389, 1410,  418],
       [1275,  338, 1325,  407],
       [1146,  368, 1187,  397],
       [1077,  372, 1114,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00025.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 129,  834,  310,  938],
       [ 333,  574,  441,  641],
       [ 579,  503,  664,  563],
       [ 689,  441,  752,  484],
       [ 898,  418,  950,  466],
       [ 623,  418,  673,  459],
       [ 744,  405,  794,  439],
       [1450,  626, 1571,  718],
       [1594,  518, 1706,  599],
       [1435,  434, 1496,  478],
       [1316,  370, 1389,  457],
       [1171,  420, 1225,  468],
       [1079,  428, 1129,  474]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00026.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 221,  732,  387,  838],
       [ 196,  553,  396,  707],
       [ 508,  574,  602,  638],
       [ 529,  468,  596,  518],
       [ 698,  428,  754,  466],
       [1094,  528, 1171,  595],
       [1241,  532, 1325,  607],
       [1408,  426, 1521,  549],
       [1575,  516, 1656,  570],
       [ 781,  391,  827,  426],
       [ 700,  380,  750,  413],
       [1339,  366, 1383,  405],
       [ 942,  368,  983,  405],
       [ 808,  372,  846,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00027.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[  33,  851,  254, 1014],
       [ 533,  534,  625,  603],
       [ 454,  451,  581,  557],
       [ 664,  466,  723,  505],
       [ 644,  411,  698,  443],
       [ 771,  378,  816,  411],
       [1150,  766, 1300,  909],
       [1491,  861, 1692, 1041],
       [1596,  532, 1800,  724],
       [1867,  664, 1917,  774],
       [1398,  407, 1456,  453],
       [1077,  389, 1121,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00028.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  795,   87,  910],
       [ 254,  588,  375,  672],
       [ 475,  574,  575,  661],
       [ 679,  443,  742,  491],
       [ 591,  391,  681,  468],
       [ 748,  403,  791,  436],
       [1081,  453, 1139,  495],
       [1506,  470, 1587,  536],
       [1229,  397, 1275,  432],
       [1071,  386, 1112,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00029.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1723,  584, 1852,  676],
       [1121,  578, 1214,  653],
       [1073,  451, 1133,  511],
       [1285,  445, 1346,  505],
       [1221,  384, 1262,  424],
       [1150,  399, 1192,  432],
       [   0,  768,  116,  878],
       [ 331,  574,  431,  645],
       [ 483,  472,  558,  534],
       [ 644,  466,  712,  516],
       [ 681,  357,  748,  420],
       [ 769,  389,  812,  426],
       [1062,  374, 1100,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00030.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1277,  991, 1466, 1045],
       [1096,  580, 1191,  674],
       [1394,  547, 1489,  624],
       [1185,  459, 1241,  511],
       [1266,  439, 1319,  491],
       [1060,  422, 1106,  464],
       [ 335,  566,  437,  632],
       [ 529,  470,  591,  520],
       [ 606,  413,  671,  459],
       [ 746,  401,  792,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00031.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1662,  757, 1852,  914],
       [1204,  993, 1367, 1049],
       [ 231,  607,  364,  693],
       [ 529,  468,  596,  516],
       [ 635,  411,  689,  445],
       [1266,  586, 1358,  664],
       [1356,  526, 1437,  597],
       [1067,  518, 1141,  580],
       [1069,  424, 1119,  472],
       [1231,  413, 1271,  443],
       [ 691,  372,  737,  407],
       [ 804,  363,  844,  395],
       [1141,  345, 1175,  378]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00032.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1527,  961, 1741, 1043],
       [1125,  745, 1260,  868],
       [1562,  711, 1721,  843],
       [1085,  520, 1160,  591],
       [1294,  480, 1360,  532],
       [   2,  861,  189, 1043],
       [ 479,  484,  558,  545],
       [ 639,  411,  687,  447],
       [1144,  382, 1191,  426],
       [1300,  395, 1350,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00033.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1148,  759, 1289,  895],
       [1433,  611, 1542,  699],
       [1373,  453, 1435,  488],
       [1175,  439, 1241,  501],
       [1071,  428, 1116,  466],
       [1064,  368, 1102,  401],
       [ 452,  568,  562,  664],
       [ 612,  413,  671,  461],
       [ 712,  374,  756,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00034.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1854,  995, 1919, 1047],
       [1512,  551, 1608,  613],
       [1248,  547, 1348,  639],
       [1073,  522, 1148,  589],
       [1060,  420, 1116,  463],
       [ 202,  764,  381,  882],
       [ 196,  634,  331,  713],
       [ 639,  455,  708,  514],
       [ 689,  374,  739,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00035.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1852,  786, 1919,  907],
       [1464,  834, 1685, 1045],
       [1125,  759, 1262,  905],
       [ 483, 1026,  650, 1045],
       [ 391,  811,  552,  930],
       [   0,  968,  133, 1044],
       [   4,  797,   62,  889],
       [ 600,  524,  685,  582],
       [ 452,  505,  537,  559],
       [1081,  518, 1152,  580],
       [ 739,  389,  792,  436],
       [ 756,  349,  792,  376],
       [1142,  374, 1175,  405],
       [1071,  370, 1102,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00036.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1142,  755, 1279,  891],
       [ 777,  584,  889,  684],
       [1162,  424, 1210,  463],
       [1069,  420, 1116,  455],
       [ 450,  607,  556,  676],
       [ 308,  576,  412,  643],
       [ 583,  430,  644,  476],
       [ 756,  424,  814,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00037.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 177,  747,  352,  855],
       [ 312,  568,  421,  643],
       [ 514,  476,  581,  520],
       [ 646,  472,  710,  518],
       [ 869,  453,  939,  511],
       [ 796,  434,  844,  478],
       [1085,  509, 1152,  566],
       [1217,  499, 1281,  561],
       [1071,  407, 1127,  461],
       [ 677,  388,  723,  422],
       [ 848,  368,  894,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00038.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1137,  724, 1264,  843],
       [1337,  661, 1446,  763],
       [1098,  489, 1173,  566],
       [ 525,  536,  614,  599],
       [ 525,  457,  600,  514],
       [ 631,  416,  685,  453],
       [ 750,  403,  796,  438],
       [1227,  395, 1279,  443],
       [1154,  382, 1198,  420],
       [ 917,  391,  960,  432],
       [ 852,  376,  892,  413],
       [ 746,  357,  783,  388],
       [1073,  347, 1114,  382]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00039.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1162,  666, 1291,  814],
       [ 439,  695,  617,  841],
       [ 256,  607,  373,  684],
       [ 667,  447,  731,  493],
       [ 642,  401,  696,  443],
       [1283,  457, 1352,  520],
       [1196,  432, 1252,  482],
       [1069,  384, 1116,  426],
       [ 714,  378,  752,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00040.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1417,  576, 1537,  682],
       [1291,  511, 1367,  578],
       [1079,  445, 1141,  516],
       [ 702,  493,  794,  578],
       [ 517,  474,  581,  524],
       [1281,  368, 1337,  416],
       [1144,  382, 1187,  422],
       [ 764,  389,  806,  424],
       [ 716,  364,  762,  403]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00041.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1850,  941, 1919, 1045],
       [1498,  676, 1641,  814],
       [1110,  584, 1217,  705],
       [1166,  438, 1223,  488],
       [1323,  411, 1400,  470],
       [1216,  372, 1266,  420],
       [1137,  395, 1179,  428],
       [ 477,  689,  648,  818],
       [ 219,  728,  389,  845],
       [ 281,  557,  414,  659],
       [ 808,  409,  867,  464],
       [ 637,  403,  689,  451],
       [ 821,  355,  864,  388]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00042.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1398,  466, 1502,  541],
       [1229,  526, 1314,  607],
       [1248,  407, 1310,  480],
       [1169,  445, 1216,  499],
       [1112,  399, 1150,  432],
       [1362,  389, 1402,  420],
       [ 562,  520,  646,  582],
       [ 137,  643,  285,  745],
       [ 508,  457,  592,  526],
       [ 723,  493,  804,  563],
       [ 869,  366,  914,  407],
       [ 727,  366,  767,  407],
       [1194,  314, 1244,  388],
       [1067,  378, 1102,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00043.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1392,  741, 1546,  897],
       [1529,  549, 1696,  666],
       [1231,  551, 1314,  620],
       [1302,  470, 1404,  559],
       [1427,  428, 1485,  470],
       [1141,  457, 1200,  507],
       [1058,  434, 1104,  466],
       [1214,  334, 1279,  426],
       [1131,  334, 1185,  399],
       [   0,  714,  169,  829],
       [ 429,  505,  525,  572],
       [ 812,  407,  873,  457],
       [ 706,  418,  768,  476],
       [ 633,  395,  698,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00044.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1794,  722, 1919,  870],
       [1410,  803, 1575,  947],
       [1410,  582, 1592,  734],
       [1537,  499, 1619,  555],
       [1208,  574, 1304,  647],
       [1060,  539, 1125,  601],
       [1250,  366, 1341,  488],
       [1139,  363, 1206,  445],
       [1377,  393, 1417,  426],
       [ 383,  526,  479,  603],
       [ 585,  430,  646,  474],
       [ 869,  357,  921,  395],
       [ 792,  374,  837,  414],
       [ 714,  359,  767,  399]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00045.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1710,  843, 1919, 1045],
       [1421,  884, 1625, 1043],
       [1117,  845, 1267,  993],
       [1746,  632, 1877,  722],
       [1317,  422, 1452,  593],
       [1173,  418, 1262,  528],
       [1456,  441, 1504,  476],
       [ 567,  441,  633,  493],
       [ 675,  382,  729,  426],
       [1069,  388, 1112,  426],
       [1294,  380, 1341,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00046.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1475,  520, 1717,  811],
       [1246,  514, 1394,  689],
       [1283,  459, 1348,  495],
       [1075,  445, 1129,  486],
       [1350,  426, 1404,  474],
       [1292,  386, 1348,  426],
       [1385,  384, 1425,  426],
       [ 671,  389,  721,  434],
       [ 750,  349,  789,  380],
       [1069,  355, 1108,  389],
       [1233,  347, 1277,  395],
       [1133,  357, 1177,  389]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00047.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1473,  772, 1827, 1049],
       [1839,  655, 1917,  749],
       [1100,  559, 1185,  626],
       [1377,  549, 1471,  616],
       [1448,  495, 1529,  557],
       [1456,  434, 1516,  480],
       [1352,  432, 1425,  491],
       [ 369,  763,  541,  897],
       [1279,  382, 1327,  434],
       [1067,  399, 1112,  438],
       [1150,  395, 1189,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00048.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1169,  832, 1325,  988],
       [1598,  741, 1756,  864],
       [1652,  622, 1783,  730],
       [1592,  509, 1683,  574],
       [1464,  511, 1567,  589],
       [1348,  430, 1421,  497],
       [1177,  453, 1233,  503],
       [1073,  466, 1131,  526],
       [ 656,  540,  747,  618],
       [1079,  391, 1125,  434],
       [1281,  370, 1321,  409],
       [1146,  366, 1185,  401]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00049.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1870,  645, 1919,  770],
       [1687,  659, 1867,  795],
       [1114,  613, 1217,  718],
       [1254,  566, 1333,  641],
       [1491,  511, 1592,  614],
       [1412,  476, 1471,  526],
       [1087,  459, 1144,  520],
       [1317,  401, 1377,  453],
       [1164,  405, 1214,  453],
       [ 273,  705,  425,  818],
       [ 173,  578,  335,  709],
       [ 631,  589,  725,  672],
       [ 773,  439,  835,  495]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00050.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1779,  682, 1919,  853],
       [1450,  843, 1625,  995],
       [1117,  599, 1214,  701],
       [1569,  582, 1673,  659],
       [1387,  457, 1477,  526],
       [1198,  470, 1269,  536],
       [ 573,  511,  658,  578],
       [ 444,  470,  539,  547],
       [ 796,  453,  854,  505],
       [1081,  418, 1123,  459],
       [1304,  403, 1344,  438],
       [ 839,  389,  887,  418],
       [1227,  380, 1269,  409],
       [1069,  374, 1106,  409],
       [1148,  374, 1187,  413],
       [1348,  368, 1387,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00051.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  901,  189, 1044],
       [1296,  603, 1404,  711],
       [1542,  563, 1667,  668],
       [ 291,  584,  402,  655],
       [1369,  451, 1425,  495],
       [1092,  505, 1158,  563],
       [1408,  407, 1460,  441],
       [1266,  424, 1314,  461],
       [1164,  428, 1217,  472],
       [1069,  428, 1125,  470],
       [ 714,  420,  769,  464],
       [ 589,  403,  658,  463],
       [ 885,  382,  935,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00052.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1594, 1003, 1785, 1047],
       [1137,  678, 1246,  791],
       [ 406,  805,  577,  932],
       [ 466,  584,  569,  668],
       [ 517,  474,  587,  526],
       [ 685,  364,  737,  409],
       [ 794,  370,  837,  405],
       [1092,  520, 1171,  582],
       [1212,  507, 1283,  578],
       [1335,  497, 1414,  551],
       [1489,  539, 1569,  605],
       [1521,  468, 1592,  530],
       [1394,  384, 1452,  443],
       [1285,  474, 1342,  522]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00053.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1764,  714, 1912,  824],
       [1754,  586, 1871,  680],
       [1489,  618, 1608,  714],
       [1341,  686, 1471,  809],
       [1158,  716, 1287,  841],
       [1494,  434, 1573,  516],
       [1398,  395, 1446,  432],
       [  16,  713,  196,  834],
       [ 698,  549,  771,  605],
       [ 650,  464,  717,  518],
       [ 644,  411,  696,  451]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00054.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1637,  799, 1823,  939],
       [1683,  526, 1806,  649],
       [ 406,  597,  527,  668],
       [ 416,  524,  506,  589],
       [ 806,  434,  854,  480],
       [ 752,  399,  800,  438],
       [1477,  439, 1537,  491]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00055.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 602,  618,  712,  699],
       [ 650,  457,  717,  507],
       [ 598,  428,  652,  484],
       [1614,  520, 1700,  584],
       [1416,  411, 1464,  449],
       [1229,  376, 1275,  422],
       [ 869,  382,  910,  414],
       [ 814,  359,  856,  391],
       [1235,  326, 1287,  380]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00056.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1506,  468, 1571,  511],
       [1262,  434, 1333,  488],
       [1381,  388, 1425,  422],
       [1258,  343, 1327,  414],
       [1139,  374, 1177,  407],
       [   0,  891,  154, 1049],
       [ 741,  684,  852,  784],
       [ 175,  605,  333,  726],
       [ 750,  474,  821,  528],
       [ 758,  395,  810,  434],
       [ 696,  380,  741,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00057.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1664,  551, 1756,  622],
       [1354,  518, 1454,  599],
       [1471,  439, 1527,  486],
       [1296,  364, 1392,  464],
       [1160,  416, 1208,  472],
       [ 871,  489,  927,  534],
       [ 579,  616,  692,  716],
       [ 460,  568,  579,  659],
       [ 187,  636,  316,  726],
       [ 485,  468,  569,  530],
       [ 827,  403,  873,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00058.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1566,  651, 1762,  861],
       [1623,  534, 1712,  586],
       [1369,  424, 1514,  543],
       [1212,  507, 1285,  582],
       [ 352,  841,  533,  963],
       [ 742,  484,  814,  532],
       [ 473,  486,  550,  543],
       [ 654,  447,  731,  501],
       [ 635,  397,  694,  447],
       [ 921,  399,  966,  438],
       [1221,  384, 1269,  430],
       [1371,  380, 1414,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00059.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1366,  716, 1510,  859],
       [1498,  503, 1733,  682],
       [1267,  428, 1335,  495],
       [1448,  436, 1506,  476],
       [ 114,  795,  292,  914],
       [ 698,  541,  775,  595],
       [ 821,  401,  871,  451],
       [ 623,  413,  673,  447],
       [ 754,  382,  810,  424],
       [1212,  386, 1258,  420],
       [1342,  364, 1381,  395],
       [ 725,  357,  773,  397]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_3_00060.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1767,  649, 1919,  903],
       [1591,  513, 1675,  568],
       [1358,  507, 1458,  613],
       [ 529,  538,  612,  599],
       [ 823,  424,  879,  468],
       [ 708,  372,  758,  401],
       [1260,  428, 1316,  484],
       [1391,  399, 1439,  436],
       [1160,  413, 1208,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00001.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1821,  605, 1917,  726],
       [1458,  591, 1566,  699],
       [1441,  476, 1514,  536],
       [1321,  397, 1366,  432],
       [1169,  434, 1217,  472],
       [1069,  384, 1110,  416],
       [ 506,  663,  637,  782],
       [ 719,  516,  791,  566],
       [ 612,  426,  721,  536],
       [ 833,  403,  881,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00002.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1829,  884, 1919, 1045],
       [1656,  628, 1781,  722],
       [1223,  528, 1304,  591],
       [1379,  443, 1441,  491],
       [1078,  436, 1128,  482],
       [ 556,  922,  742, 1043],
       [ 212,  745,  385,  857],
       [ 683,  620,  792,  705],
       [ 698,  507,  779,  582],
       [ 812,  424,  864,  470],
       [ 717,  376,  794,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00003.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1398,  770, 1556,  905],
       [1494,  526, 1577,  586],
       [1100,  539, 1173,  603],
       [1212,  366, 1248,  414],
       [ 798,  578,  883,  657],
       [ 537,  547,  625,  613],
       [ 312,  578,  416,  647],
       [ 852,  466,  912,  513],
       [ 796,  422,  848,  474],
       [ 783,  345,  846,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00004.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1167,  795, 1314,  941],
       [1731,  688, 1883,  805],
       [1244,  409, 1298,  463],
       [ 583,  609,  696,  701],
       [  46,  516,  394,  797],
       [ 546,  457,  606,  503],
       [ 677,  455,  737,  497],
       [ 877,  455,  933,  497],
       [ 921,  389,  969,  430],
       [ 852,  376,  896,  414],
       [1150,  370, 1191,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00005.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  916,  114, 1048],
       [ 416,  414,  592,  580],
       [ 748,  472,  821,  530],
       [1310,  476, 1394,  559],
       [1171,  416, 1214,  455],
       [1241,  389, 1271,  424],
       [ 917,  395,  960,  432],
       [ 756,  397,  800,  432],
       [ 666,  395,  714,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00006.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1462,  605, 1602,  749],
       [1212,  488, 1277,  538],
       [1283,  441, 1337,  482],
       [1160,  399, 1206,  443],
       [1296,  378, 1346,  424],
       [1231,  386, 1271,  424],
       [ 827,  403,  875,  445],
       [ 583,  361,  700,  478],
       [ 750,  355,  789,  388],
       [ 810,  359,  856,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00007.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1302,  624, 1410,  713],
       [1369,  526, 1448,  586],
       [1187,  455, 1256,  524],
       [1267,  428, 1317,  472],
       [1358,  426, 1427,  486],
       [ 506,  697,  641,  803],
       [ 723,  466,  802,  543],
       [ 625,  470,  698,  526],
       [ 689,  332,  773,  414],
       [1146,  403, 1189,  436],
       [1219,  370, 1260,  413],
       [ 873,  357,  914,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00008.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1562,  701, 1706,  813],
       [1269,  574, 1371,  664],
       [1481,  507, 1585,  597],
       [1342,  499, 1414,  561],
       [1183,  463, 1237,  509],
       [1254,  414, 1304,  459],
       [ 719,  501,  794,  572],
       [ 810,  397,  866,  453],
       [ 727,  403,  783,  447],
       [ 762,  318,  837,  380],
       [1383,  397, 1431,  436],
       [1210,  382, 1256,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00009.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1479,  866, 1698, 1043],
       [1746,  674, 1917,  830],
       [1502,  626, 1623,  718],
       [1252,  578, 1346,  647],
       [1310,  482, 1392,  547],
       [1491,  459, 1550,  507],
       [1242,  426, 1308,  478],
       [1152,  389, 1202,  426],
       [ 742,  638,  854,  728],
       [ 810,  418,  864,  459],
       [ 867,  355,  910,  399],
       [ 796,  366,  844,  399],
       [1077,  384, 1104,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00010.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1475,  878, 1654, 1038],
       [1700,  572, 1810,  639],
       [1448,  595, 1564,  693],
       [1325,  509, 1406,  584],
       [ 304,  866,  508, 1030],
       [  69,  691,  229,  782],
       [ 860,  474,  921,  520],
       [1185,  443, 1246,  497],
       [1075,  438, 1119,  474]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00011.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1789,  895, 1919, 1059],
       [1496,  659, 1641,  786],
       [1248,  549, 1352,  632],
       [1087,  539, 1160,  595],
       [1339,  338, 1425,  424],
       [1221,  391, 1267,  428],
       [1148,  401, 1191,  434],
       [ 677,  545,  762,  614],
       [ 402,  632,  519,  707],
       [ 208,  611,  342,  709],
       [ 435,  507,  525,  561],
       [ 914,  399,  958,  432],
       [1058,  384, 1094,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00012.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1152,  784, 1292,  914],
       [1437,  797, 1639,  986],
       [1060,  459, 1114,  499],
       [1181,  466, 1243,  511],
       [1279,  449, 1335,  495],
       [1392,  366, 1517,  478],
       [1144,  378, 1198,  443],
       [1233,  353, 1271,  389],
       [ 623,  486,  694,  532],
       [ 494,  474,  571,  532],
       [ 794,  436,  850,  478],
       [ 606,  422,  664,  459]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00013.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1496,  414, 1692,  572],
       [1396,  563, 1485,  634],
       [1262,  578, 1348,  651],
       [1094,  599, 1181,  678],
       [1181,  434, 1252,  528],
       [1291,  393, 1341,  432],
       [ 775,  618,  873,  697],
       [   0,  891,  204, 1045],
       [   0,  649,  192,  869],
       [ 639,  399,  692,  445],
       [ 739,  409,  789,  447],
       [ 700,  374,  752,  401],
       [ 860,  376,  904,  409],
       [1267,  349, 1304,  391]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00014.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1725,  857, 1916, 1005],
       [1487,  882, 1683, 1041],
       [1266,  541, 1389,  699],
       [ 508,  555,  604,  636],
       [ 341,  478,  510,  609],
       [ 873,  464,  931,  516],
       [1685,  503, 1919,  763],
       [1396,  468, 1473,  534],
       [1304,  376, 1354,  432],
       [1373,  380, 1421,  418],
       [ 729,  361,  773,  395]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00015.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1514,  861, 1783, 1045],
       [1654,  630, 1796,  747],
       [1364,  420, 1429,  486],
       [1454,  422, 1519,  478],
       [ 287,  791,  516,  999],
       [ 554,  401,  660,  489],
       [ 692,  436,  756,  491],
       [ 917,  393,  962,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00016.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1479,  499, 1585,  591],
       [1608,  507, 1706,  586],
       [ 658,  530,  760,  622],
       [ 673,  355,  748,  420],
       [ 783,  380,  833,  413],
       [1404,  409, 1450,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <6x16 sparse matrix of type '<type 'numpy.float32'>'
	with 6 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00017.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1742,  657, 1917,  826],
       [1510,  478, 1579,  530],
       [1310,  303, 1364,  384],
       [ 735,  672,  858,  788],
       [ 481,  713,  619,  809],
       [ 331,  668,  462,  757],
       [ 221,  486,  421,  672],
       [ 787,  426,  846,  488],
       [ 756,  328,  810,  382]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00018.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1733,  599, 1848,  686],
       [1335,  324, 1400,  414],
       [ 466,  714,  594,  811],
       [ 856,  486,  923,  549],
       [ 710,  513,  787,  568],
       [ 608,  497,  681,  547],
       [ 483,  401,  598,  522],
       [ 854,  372,  896,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00019.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1381,  347, 1475,  459],
       [ 704,  513,  773,  572],
       [ 625,  347,  708,  453],
       [ 735,  413,  783,  451],
       [ 808,  422,  858,  463],
       [ 916,  403,  960,  441],
       [1333,  334, 1389,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00020.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1483,  388, 1610,  536],
       [1381,  361, 1456,  443],
       [ 333,  628,  494,  749],
       [ 804,  424,  852,  463],
       [ 714,  322,  781,  399],
       [ 812,  368,  846,  395],
       [ 867,  372,  906,  405],
       [ 950,  355,  987,  384]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00021.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1660,  459, 1866,  672],
       [1475,  407, 1575,  520],
       [ 585,  874,  771, 1034],
       [ 416,  761,  560,  859],
       [ 589,  480,  677,  549],
       [1346,  361, 1389,  405],
       [ 783,  303,  835,  363],
       [ 866,  378,  900,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00022.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1642,  480, 1796,  638],
       [ 419,  801,  575,  913],
       [ 187,  759,  369,  872],
       [ 562,  651,  679,  728],
       [ 673,  543,  750,  597],
       [ 810,  549,  894,  613],
       [ 714,  405,  779,  457],
       [1394,  395, 1450,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00023.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 279,  574,  404,  655],
       [ 537,  541,  625,  603],
       [ 692,  553,  771,  609],
       [ 735,  493,  808,  547],
       [ 777,  447,  835,  484],
       [ 883,  436,  939,  480],
       [1477,  445, 1548,  505],
       [1391,  403, 1448,  447],
       [1256,  309, 1325,  413],
       [ 787,  361,  839,  401],
       [1198,  374, 1237,  405]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00024.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1625,  524, 1725,  611],
       [   0,  903,  185, 1042],
       [ 521,  463,  602,  518],
       [ 679,  447,  735,  491],
       [ 789,  451,  842,  501],
       [1467,  449, 1535,  499],
       [1241,  420, 1294,  464],
       [1285,  330, 1373,  451],
       [ 817,  420,  866,  463]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00025.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1610,  528, 1710,  597],
       [1329,  505, 1406,  564],
       [ 452,  591,  560,  661],
       [1329,  355, 1467,  526],
       [1077,  405, 1123,  451],
       [ 850,  395,  891,  432],
       [ 762,  391,  804,  430],
       [ 660,  397,  714,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00026.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1537,  684, 1671,  789],
       [1883,  666, 1917,  749],
       [1414,  409, 1648,  655],
       [1094,  472, 1160,  547],
       [ 325,  670,  466,  770],
       [ 189,  624,  317,  709],
       [ 637,  470,  706,  518],
       [1166,  428, 1212,  468],
       [1233,  418, 1277,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00027.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1591,  501, 1919,  968],
       [1141,  626, 1260,  745],
       [1206,  511, 1275,  570],
       [1312,  499, 1377,  555],
       [ 494,  713,  625,  807],
       [ 589,  501,  666,  563],
       [ 483,  476,  560,  528],
       [ 733,  401,  791,  443],
       [1248,  407, 1304,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00028.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1315,  672, 1431,  762],
       [1479,  649, 1585,  730],
       [1316,  476, 1394,  543],
       [1442,  430, 1492,  470],
       [1337,  411, 1392,  461],
       [ 492,  705,  627,  803],
       [ 717,  520,  787,  574],
       [ 714,  422,  766,  470],
       [ 633,  405,  689,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00029.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 606,  893,  785, 1043],
       [ 210,  582,  473,  791],
       [ 716,  661,  825,  747],
       [ 712,  509,  787,  564],
       [ 808,  430,  852,  470],
       [1456,  593, 1587,  713],
       [1435,  484, 1523,  553],
       [1562,  503, 1633,  559],
       [1339,  416, 1408,  472]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00030.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1850,  916, 1919, 1045],
       [1654,  634, 1810,  743],
       [1791,  622, 1900,  699],
       [1431,  474, 1527,  563],
       [ 816,  557,  898,  634],
       [ 594,  613,  708,  689],
       [ 325,  680,  466,  772],
       [ 519,  459,  660,  586],
       [ 848,  482,  912,  534],
       [ 804,  424,  856,  466],
       [1435,  416, 1496,  474]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00031.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1627,  597, 1796,  741],
       [1556,  484, 1637,  559],
       [1435,  422, 1491,  464],
       [1339,  418, 1392,  457],
       [ 583,  513,  664,  570],
       [ 752,  474,  812,  528],
       [ 656,  386,  750,  482],
       [ 887,  441,  939,  484]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <8x16 sparse matrix of type '<type 'numpy.float32'>'
	with 8 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00032.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1796,  603, 1917,  719],
       [1544,  491, 1623,  539],
       [1427,  488, 1504,  539],
       [1166,  416, 1217,  451],
       [1369,  382, 1414,  416],
       [1281,  376, 1333,  416],
       [ 702,  428,  758,  474],
       [ 823,  405,  875,  445],
       [ 735,  351,  810,  416],
       [ 925,  380,  967,  418]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00033.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1610,  614, 1735,  705],
       [1741,  601, 1866,  670],
       [1216,  505, 1291,  568],
       [1341,  418, 1402,  474],
       [1246,  426, 1302,  463],
       [1421,  420, 1479,  459],
       [ 444,  711,  583,  839],
       [   0,  597,  200,  852],
       [ 783,  380,  825,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00034.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1371,  722, 1514,  849],
       [ 146,  749,  339,  889],
       [  23,  720,  181,  824],
       [ 567,  641,  685,  722],
       [ 289,  464,  471,  628],
       [ 691,  516,  762,  586],
       [1339,  522, 1414,  564],
       [1442,  491, 1539,  570],
       [1531,  476, 1600,  530],
       [1421,  420, 1471,  459],
       [1302,  395, 1354,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00035.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1581,  738, 1733,  845],
       [1673,  641, 1835,  772],
       [1704,  578, 1814,  643],
       [1523,  478, 1598,  532],
       [1375,  441, 1435,  503],
       [ 164,  974,  416, 1041],
       [   0,  734,   77,  912],
       [ 360,  553,  450,  614],
       [ 508,  541,  602,  618],
       [ 741,  489,  810,  541],
       [ 496,  403,  621,  513],
       [ 792,  426,  846,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00036.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1710,  572, 1819,  657],
       [1491,  524, 1585,  603],
       [1350,  430, 1410,  474],
       [1431,  414, 1491,  463],
       [ 616,  591,  725,  682],
       [ 260,  541,  410,  676],
       [ 525,  461,  592,  507],
       [ 671,  447,  733,  495],
       [ 621,  361,  717,  445],
       [ 819,  409,  862,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00037.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1756,  686, 1917,  834],
       [1471,  514, 1552,  574],
       [1539,  480, 1619,  541],
       [ 135,  993,  381, 1043],
       [ 404,  618,  525,  705],
       [ 256,  588,  387,  674],
       [ 473,  451,  573,  549],
       [ 760,  461,  827,  518],
       [1150,  378, 1196,  422],
       [1379,  386, 1423,  432],
       [ 633,  407,  687,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00038.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1731,  684, 1881,  788],
       [1746,  589, 1873,  678],
       [1456,  436, 1516,  482],
       [1173,  424, 1235,  491],
       [ 275,  697,  425,  797],
       [ 583,  588,  712,  691],
       [ 264,  586,  394,  680],
       [ 481,  482,  560,  539],
       [ 616,  482,  692,  539],
       [ 598,  397,  671,  474],
       [ 833,  397,  887,  441],
       [1146,  389, 1187,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00039.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1594,  513, 1675,  578],
       [1227,  503, 1317,  593],
       [1394,  363, 1475,  449],
       [1169,  445, 1221,  489],
       [ 316,  584,  439,  655],
       [ 569,  514,  654,  576],
       [ 744,  453,  827,  524],
       [ 483,  480,  569,  541],
       [ 598,  420,  664,  466],
       [ 725,  411,  777,  449],
       [1148,  380, 1196,  420],
       [1219,  391, 1266,  424],
       [ 683,  361,  739,  411]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00040.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1360,  670, 1531,  855],
       [ 223,  938,  439, 1045],
       [   0,  884,  192, 1041],
       [ 517,  609,  664,  753],
       [  19,  697,  202,  807],
       [1868,  653, 1919,  772],
       [1219,  543, 1300,  611],
       [ 566,  476,  641,  522],
       [1491,  413, 1585,  514],
       [1281,  455, 1342,  503],
       [1173,  438, 1233,  495],
       [ 702,  428,  756,  468],
       [ 610,  418,  675,  464],
       [ 833,  388,  883,  436],
       [ 683,  382,  731,  426],
       [1316,  403, 1367,  445],
       [1421,  414, 1467,  455],
       [1152,  401, 1194,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00041.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1369,  755, 1516,  891],
       [1416,  586, 1527,  672],
       [1231,  534, 1335,  622],
       [1183,  466, 1248,  513],
       [1389,  459, 1460,  520],
       [1523,  474, 1594,  524],
       [1644,  484, 1794,  632],
       [1267,  428, 1321,  474],
       [ 294,  870,  496, 1013],
       [  69,  770,  314,  932],
       [ 421,  593,  546,  678],
       [ 616,  591,  714,  661],
       [ 387,  522,  491,  595],
       [ 704,  470,  791,  553],
       [ 708,  409,  762,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00042.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1837,  974, 1917, 1041],
       [1391,  766, 1592,  949],
       [1273,  591, 1369,  668],
       [1531,  555, 1641,  647],
       [1717,  574, 1814,  647],
       [1354,  514, 1433,  582],
       [1446,  432, 1508,  476],
       [1325,  414, 1383,  459],
       [ 706,  726,  837,  832],
       [ 446,  699,  617,  838],
       [ 200,  761,  366,  864],
       [ 271,  595,  392,  664],
       [ 471,  549,  589,  639],
       [ 633,  578,  727,  653],
       [ 610,  474,  694,  532],
       [ 556,  439,  629,  486],
       [ 758,  468,  819,  513],
       [ 798,  391,  854,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00043.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1517,  939, 1735, 1045],
       [1569,  714, 1716,  838],
       [1875,  768, 1919,  926],
       [1394,  478, 1471,  545],
       [1560,  491, 1639,  553],
       [1350,  438, 1410,  491],
       [ 341,  861,  544, 1011],
       [ 256,  701,  416,  818],
       [ 525,  557,  610,  613],
       [ 685,  516,  783,  593],
       [ 850,  509,  921,  566],
       [ 760,  463,  825,  513],
       [ 641,  453,  716,  509],
       [ 502,  480,  575,  526]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00044.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1533,  599, 1652,  705],
       [1762,  603, 1887,  680],
       [1460,  513, 1546,  591],
       [1402,  461, 1467,  511],
       [1177,  457, 1235,  505],
       [1435,  414, 1487,  470],
       [ 167,  914,  429, 1043],
       [ 135,  661,  287,  766],
       [ 785,  622,  875,  699],
       [ 658,  578,  750,  655],
       [ 546,  528,  637,  597],
       [ 669,  455,  731,  497],
       [ 625,  414,  681,  453],
       [ 787,  430,  850,  484],
       [ 735,  395,  796,  439],
       [ 910,  420,  954,  457],
       [1064,  418, 1112,  455],
       [ 837,  397,  877,  434],
       [1389,  389, 1431,  422],
       [1167,  391, 1204,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <20x16 sparse matrix of type '<type 'numpy.float32'>'
	with 20 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00045.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1685,  661, 1841,  786],
       [1566,  551, 1666,  622],
       [1254,  574, 1346,  659],
       [1069,  491, 1131,  543],
       [1542,  482, 1617,  541],
       [1221,  447, 1273,  484],
       [1446,  432, 1512,  480],
       [ 194,  720,  377,  851],
       [ 231,  639,  360,  716],
       [ 612,  572,  721,  663],
       [ 448,  503,  539,  564],
       [ 683,  438,  739,  491],
       [ 775,  472,  833,  516],
       [ 877,  470,  939,  513],
       [ 762,  399,  808,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00046.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1506,  930, 1717, 1041],
       [1752,  584, 1864,  676],
       [1108,  645, 1214,  738],
       [1331,  547, 1416,  605],
       [1571,  503, 1654,  561],
       [  73,  814,  283,  943],
       [ 535,  526,  629,  599],
       [ 750,  451,  817,  513],
       [ 610,  420,  666,  468],
       [ 527,  495,  592,  543],
       [1175,  447, 1235,  499],
       [1448,  436, 1502,  482],
       [1304,  401, 1366,  445],
       [1373,  393, 1425,  436],
       [ 837,  407,  881,  441],
       [ 758,  389,  798,  432],
       [ 921,  397,  973,  432],
       [1154,  386, 1200,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00047.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1602,  772, 1767,  901],
       [1804,  628, 1916,  720],
       [1581,  507, 1669,  586],
       [1254,  563, 1342,  632],
       [1381,  449, 1458,  511],
       [1469,  441, 1537,  495],
       [1173,  432, 1237,  493],
       [1162,  391, 1204,  438],
       [ 556,  636,  673,  734],
       [ 492,  561,  591,  630],
       [ 679,  424,  739,  491],
       [ 819,  386,  871,  436],
       [ 698,  382,  748,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00048.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1475,  861, 1673, 1020],
       [1869,  651, 1917,  789],
       [1627,  526, 1729,  603],
       [1506,  526, 1606,  609],
       [1237,  526, 1325,  611],
       [1191,  449, 1250,  501],
       [1264,  422, 1327,  470],
       [1071,  422, 1123,  463],
       [1164,  403, 1206,  432],
       [ 156,  584,  323,  734],
       [ 737,  482,  798,  545],
       [ 660,  455,  723,  501],
       [ 758,  384,  806,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00049.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1400,  730, 1573,  895],
       [1719,  655, 1881,  782],
       [1256,  543, 1344,  624],
       [1366,  505, 1452,  578],
       [1091,  509, 1154,  563],
       [1194,  463, 1256,  513],
       [1067,  439, 1116,  482],
       [1331,  420, 1387,  463],
       [1400,  418, 1454,  457],
       [ 325,  684,  467,  788],
       [   0,  749,  154,  856],
       [ 454,  457,  550,  553],
       [ 831,  407,  875,  449],
       [ 746,  399,  796,  438],
       [1067,  397, 1110,  438]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00050.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1433,  766, 1608,  936],
       [1577,  705, 1762,  851],
       [1139,  693, 1244,  793],
       [1275,  580, 1373,  649],
       [1081,  539, 1154,  605],
       [1444,  499, 1525,  559],
       [1083,  466, 1133,  513],
       [1502,  474, 1569,  516],
       [ 241,  697,  392,  807],
       [ 389,  545,  471,  609],
       [ 598,  503,  681,  570],
       [ 604,  393,  677,  459],
       [1285,  405, 1337,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00051.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1502,  878, 1692, 1039],
       [1139,  780, 1277,  926],
       [1691,  655, 1831,  774],
       [1667,  568, 1777,  641],
       [1121,  595, 1206,  674],
       [1392,  478, 1464,  532],
       [ 708,  741,  831,  853],
       [ 371,  770,  556,  905],
       [ 558,  507,  642,  570],
       [ 564,  453,  627,  497],
       [ 719,  424,  775,  468],
       [1319,  403, 1367,  443],
       [ 702,  349,  750,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00052.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1233,  972, 1402, 1043],
       [1596,  603, 1721,  703],
       [1391,  455, 1454,  501],
       [1431,  418, 1491,  463],
       [1333,  413, 1389,  455],
       [1162,  407, 1210,  447],
       [ 219,  947,  444, 1039],
       [ 227,  728,  392,  838],
       [ 666,  530,  766,  614],
       [ 852,  507,  919,  564],
       [ 698,  420,  756,  466]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00053.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 662,  716,  800,  836],
       [ 625,  597,  719,  670],
       [ 562,  528,  644,  589],
       [1517,  543, 1602,  605],
       [1558,  499, 1633,  545],
       [1412,  474, 1487,  532],
       [1206,  484, 1269,  541],
       [ 789,  434,  848,  486],
       [ 916,  414,  962,  451],
       [1152,  411, 1196,  451],
       [1071,  384, 1110,  418],
       [1217,  376, 1256,  413],
       [1277,  384, 1323,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00054.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1781,  732, 1917,  845],
       [1821,  632, 1919,  726],
       [1579,  574, 1696,  672],
       [1304,  634, 1416,  734],
       [1202,  484, 1258,  539],
       [1071,  445, 1125,  497],
       [1248,  416, 1306,  468],
       [1327,  418, 1377,  459],
       [1152,  395, 1202,  441],
       [ 827,  518,  904,  588],
       [ 762,  468,  821,  516],
       [ 702,  430,  758,  476],
       [ 848,  382,  896,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00055.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1314,  647, 1425,  745],
       [1094,  574, 1183,  657],
       [1333,  493, 1421,  572],
       [1419,  486, 1483,  536],
       [1191,  457, 1254,  528],
       [1406,  411, 1458,  441],
       [1306,  391, 1350,  434],
       [ 592,  618,  696,  695],
       [ 891,  432,  942,  482],
       [ 829,  403,  875,  441],
       [ 781,  384,  829,  416]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00056.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1206,  982, 1385, 1043],
       [ 452,  757,  600,  872],
       [ 750,  478,  812,  532],
       [1275,  586, 1391,  705],
       [1516,  651, 1667,  789],
       [1531,  472, 1602,  528],
       [1366,  436, 1429,  489],
       [1152,  405, 1200,  443],
       [1302,  397, 1342,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00057.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1544,  951, 1789, 1047],
       [1758,  601, 1879,  682],
       [1471,  511, 1560,  580],
       [1194,  480, 1258,  530],
       [1367,  447, 1423,  493],
       [ 702,  536,  781,  593],
       [ 821,  407,  871,  447],
       [1317,  401, 1364,  441],
       [1069,  370, 1114,  409]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00058.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1698,  657, 1860,  786],
       [1302,  636, 1410,  730],
       [1489,  532, 1567,  597],
       [1387,  461, 1456,  509],
       [1077,  428, 1133,  482],
       [1164,  393, 1208,  434],
       [1427,  416, 1469,  463],
       [1210,  364, 1260,  403],
       [ 277,  830,  500, 1011],
       [  52,  693,  229,  811],
       [ 806,  436,  852,  470],
       [ 871,  364,  914,  397]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00059.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1754,  705, 1902,  822],
       [1533,  561, 1631,  630],
       [1537,  484, 1608,  538],
       [1098,  536, 1191,  622],
       [1196,  453, 1260,  513],
       [1248,  403, 1304,  459],
       [1364,  366, 1406,  403],
       [ 637,  545,  735,  636],
       [ 444,  513,  533,  578],
       [ 858,  382,  902,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_4_00060.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1185,  845, 1387, 1043],
       [1862,  772, 1917,  891],
       [1775,  607, 1887,  691],
       [1275,  570, 1379,  661],
       [1319,  472, 1404,  549],
       [1425,  413, 1481,  463],
       [   0,  818,  179, 1046],
       [ 612,  601,  723,  703],
       [ 352,  572,  454,  638],
       [ 616,  420,  675,  468],
       [ 764,  443,  825,  491]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00001.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1375,  722, 1516,  841],
       [1667,  572, 1785,  641],
       [1367,  447, 1435,  505],
       [1085,  459, 1139,  507],
       [1417,  409, 1467,  449],
       [1154,  399, 1198,  436],
       [ 119,  674,  279,  782],
       [ 756,  466,  816,  509],
       [ 804,  411,  854,  463],
       [ 612,  420,  667,  463]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00002.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  876,  154, 1046],
       [  69,  653,  264,  795],
       [ 473,  497,  556,  561],
       [1127,  597, 1210,  670],
       [1508,  543, 1614,  620],
       [1489,  457, 1554,  503],
       [1194,  463, 1256,  520],
       [1356,  382, 1396,  414],
       [1150,  393, 1194,  434],
       [1204,  358, 1264,  412],
       [ 833,  395,  879,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00003.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1823,  747, 1919,  893],
       [1279,  586, 1381,  682],
       [1608,  524, 1698,  589],
       [1181,  461, 1239,  516],
       [1239,  399, 1302,  463],
       [1410,  413, 1452,  453],
       [1360,  357, 1406,  413],
       [ 166,  922,  404, 1041],
       [   0,  761,  148,  880],
       [ 448,  559,  571,  668],
       [ 454,  484,  552,  557],
       [ 629,  411,  691,  457]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00004.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1548,  949, 1754, 1047],
       [1808,  628, 1919,  714],
       [1269,  588, 1360,  668],
       [1483,  470, 1556,  520],
       [1294,  466, 1385,  539],
       [1398,  389, 1464,  451],
       [1283,  413, 1364,  468],
       [ 233,  851,  487, 1045],
       [ 602,  582,  704,  666],
       [ 410,  534,  500,  601],
       [ 646,  443,  725,  509],
       [ 619,  403,  691,  459],
       [1069,  405, 1110,  443],
       [1142,  389, 1189,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00005.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1535,  968, 1750, 1045],
       [1404,  563, 1537,  661],
       [1396,  484, 1494,  555],
       [1631,  553, 1725,  611],
       [1475,  428, 1546,  507],
       [1175,  451, 1235,  522],
       [1085,  493, 1146,  543],
       [ 621,  559,  744,  649],
       [ 273,  707,  425,  807],
       [ 748,  459,  810,  514],
       [ 594,  439,  654,  480],
       [ 752,  380,  806,  430],
       [1148,  407, 1192,  443],
       [1064,  384, 1104,  418],
       [1298,  382, 1342,  422],
       [1360,  376, 1402,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00006.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1652,  780, 1908,  970],
       [1625,  626, 1791,  755],
       [1896,  695, 1919,  786],
       [1585,  480, 1700,  576],
       [1252,  582, 1360,  691],
       [1125,  672, 1241,  774],
       [1191,  478, 1248,  530],
       [1073,  443, 1125,  501],
       [1360,  432, 1414,  482],
       [ 319,  695,  458,  789],
       [ 579,  509,  658,  566],
       [ 762,  445,  833,  505],
       [ 827,  395,  873,  434],
       [ 696,  382,  746,  414],
       [1400,  399, 1448,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00007.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1283,  626, 1387,  714],
       [1089,  564, 1181,  653],
       [1775,  564, 1919,  703],
       [1542,  978, 1744, 1051],
       [1466,  491, 1544,  566],
       [1460,  436, 1519,  484],
       [1362,  436, 1412,  474],
       [1391,  407, 1437,  441],
       [1144,  397, 1200,  438],
       [1060,  372, 1114,  424],
       [ 589,  503,  669,  557],
       [ 714,  422,  769,  464],
       [ 839,  388,  885,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00008.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1171,  943, 1358, 1049],
       [1673,  626, 1802,  739],
       [1552,  489, 1631,  549],
       [1450,  505, 1521,  555],
       [1187,  457, 1256,  524],
       [1066,  436, 1131,  511],
       [1450,  443, 1504,  480],
       [   0,  993,   71, 1047],
       [ 310,  664,  458,  770],
       [ 719,  420,  767,  455],
       [1400,  407, 1452,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00009.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1621,  616, 1741,  701],
       [1696,  561, 1810,  653],
       [1269,  582, 1375,  680],
       [1092,  555, 1206,  678],
       [1542,  497, 1617,  545],
       [1471,  447, 1521,  488],
       [ 391,  726,  587,  876],
       [   0,  630,  208,  860],
       [ 385,  618,  504,  695],
       [ 573,  507,  652,  570],
       [1369,  401, 1416,  434]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00010.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1567,  974, 1777, 1045],
       [1208,  949, 1462, 1043],
       [1691,  582, 1798,  647],
       [1566,  509, 1644,  566],
       [1433,  438, 1494,  480],
       [ 537,  663,  658,  757],
       [ 177,  480,  477,  713],
       [ 673,  511,  773,  595],
       [ 589,  474,  656,  524],
       [ 700,  426,  762,  472]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00011.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1729,  595, 1848,  672],
       [1531,  503, 1608,  559],
       [ 781,  605,  871,  678],
       [ 139,  782,  327,  905],
       [  42,  707,  206,  799],
       [ 433,  411,  616,  559],
       [ 729,  499,  800,  559],
       [ 785,  424,  850,  472],
       [1329,  409, 1377,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00012.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1694,  616, 1812,  701],
       [1298,  491, 1362,  534],
       [1394,  468, 1462,  520],
       [1441,  426, 1496,  472],
       [1156,  405, 1210,  453],
       [ 702,  697,  829,  816],
       [ 367,  761,  581,  939],
       [ 110,  799,  321,  949],
       [ 135,  639,  289,  739],
       [ 379,  538,  471,  603],
       [ 514,  553,  612,  618],
       [ 879,  461,  929,  505],
       [ 579,  374,  694,  472],
       [ 819,  420,  869,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00013.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1450,  641, 1554,  711],
       [1531,  557, 1631,  641],
       [1531,  474, 1608,  538],
       [1189,  472, 1260,  539],
       [1452,  430, 1506,  468],
       [1071,  422, 1121,  468],
       [ 841,  505,  914,  574],
       [ 669,  538,  766,  622],
       [ 502,  563,  606,  645],
       [ 431,  495,  517,  566],
       [ 550,  451,  610,  499],
       [ 669,  455,  733,  488],
       [ 671,  341,  766,  418],
       [ 923,  393,  962,  428]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00014.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1827,  747, 1917,  901],
       [1694,  568, 1808,  653],
       [1277,  595, 1383,  716],
       [1092,  511, 1167,  586],
       [1548,  488, 1623,  545],
       [1456,  434, 1525,  484],
       [ 331,  653,  466,  757],
       [   0,  739,  152,  836],
       [ 660,  457,  725,  514],
       [ 573,  424,  642,  470],
       [ 777,  438,  842,  499],
       [ 900,  422,  952,  463],
       [1167,  432, 1217,  470],
       [1060,  409, 1116,  457],
       [1251,  399, 1301,  457],
       [1374,  403, 1408,  441],
       [ 648,  401,  698,  436],
       [ 760,  391,  804,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00015.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1541,  970, 1762, 1047],
       [1156,  732, 1312,  874],
       [1731,  586, 1842,  666],
       [1562,  491, 1654,  566],
       [1410,  451, 1469,  493],
       [1304,  461, 1369,  524],
       [1223,  520, 1300,  580],
       [1079,  493, 1148,  564],
       [ 579,  497,  656,  566],
       [ 383,  545,  473,  601],
       [1169,  420, 1212,  457],
       [ 745,  393,  795,  445],
       [ 842,  382,  894,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00016.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1752,  588, 1892,  689],
       [1379,  720, 1521,  836],
       [1129,  666, 1254,  795],
       [1421,  559, 1519,  653],
       [1516,  526, 1587,  586],
       [1217,  497, 1281,  549],
       [1050,  472, 1108,  522],
       [1371,  455, 1437,  493],
       [ 102,  672,  264,  772],
       [ 562,  451,  625,  488],
       [ 698,  426,  760,  472],
       [1335,  405, 1383,  447],
       [1156,  401, 1200,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00017.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1711,  792, 1919,  982],
       [1729,  678, 1858,  778],
       [1335,  655, 1442,  753],
       [1079,  622, 1171,  711],
       [1494,  534, 1577,  597],
       [1448,  461, 1508,  509],
       [1189,  464, 1254,  522],
       [1321,  411, 1369,  449],
       [1375,  386, 1425,  430],
       [ 569,  618,  700,  728],
       [ 371,  659,  496,  738],
       [ 439,  514,  525,  580],
       [ 664,  391,  717,  430],
       [ 771,  378,  823,  416],
       [1219,  388, 1267,  424]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00018.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 517,  707,  644,  809],
       [ 263,  699,  403,  809],
       [   0,  972,   75, 1044],
       [  96,  618,  277,  766],
       [ 598,  507,  675,  564],
       [ 733,  474,  816,  541],
       [ 592,  434,  658,  478],
       [1721,  688, 1869,  795],
       [1273,  582, 1385,  680],
       [1637,  551, 1733,  624],
       [1394,  461, 1462,  511],
       [1256,  434, 1314,  474],
       [1158,  426, 1206,  457],
       [1441,  422, 1508,  478],
       [1291,  349, 1352,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00019.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1542,  928, 1771, 1043],
       [1525,  545, 1619,  614],
       [1558,  493, 1650,  559],
       [1321,  505, 1396,  555],
       [1204,  509, 1269,  557],
       [1329,  372, 1412,  474],
       [1166,  420, 1216,  464],
       [ 573,  845,  735,  988],
       [ 442,  741,  602,  880],
       [ 377,  591,  514,  720],
       [ 123,  689,  258,  768],
       [ 423,  482,  529,  576],
       [ 539,  530,  623,  595],
       [ 717,  516,  789,  570],
       [ 810,  409,  866,  451],
       [ 712,  430,  771,  472],
       [ 691,  382,  742,  424]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00020.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 631,  864,  791, 1014],
       [  50,  759,  298,  957],
       [ 691,  524,  775,  597],
       [ 821,  513,  892,  568],
       [ 431,  526,  508,  578],
       [ 596,  478,  683,  549],
       [ 583,  418,  658,  478],
       [ 669,  443,  729,  489],
       [ 802,  430,  852,  470],
       [1783,  709, 1919,  826],
       [1764,  588, 1902,  705],
       [1460,  632, 1579,  724],
       [1310,  659, 1431,  759],
       [1217,  499, 1287,  568],
       [1408,  422, 1525,  541]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00021.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 156,  939,  379, 1041],
       [   0,  738,  131,  856],
       [ 464,  547,  591,  651],
       [ 817,  572,  900,  647],
       [1837,  978, 1917, 1045],
       [1341,  668, 1469,  793],
       [1546,  501, 1737,  674],
       [1431,  426, 1483,  461],
       [1319,  403, 1367,  445],
       [1214,  332, 1294,  447],
       [1152,  384, 1196,  418],
       [ 794,  430,  850,  482],
       [ 708,  414,  766,  466],
       [ 581,  441,  642,  482],
       [ 904,  405,  942,  441],
       [ 679,  372,  731,  422],
       [1058,  384, 1098,  413]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00022.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1858,  653, 1917,  886],
       [1550,  497, 1631,  545],
       [1381,  447, 1446,  505],
       [1244,  361, 1364,  518],
       [1179,  443, 1233,  491],
       [1060,  439, 1114,  480],
       [ 602,  595,  698,  676],
       [ 366,  539,  456,  609],
       [ 637,  449,  714,  518],
       [ 885,  455,  937,  505]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00023.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1802,  630, 1917,  713],
       [1302,  409, 1504,  641],
       [1489,  513, 1575,  601],
       [1244,  549, 1331,  634],
       [1085,  534, 1162,  601],
       [ 269,  628,  417,  728],
       [ 752,  476,  814,  518],
       [ 550,  447,  614,  497],
       [ 725,  397,  783,  447],
       [1142,  403, 1194,  445],
       [ 923,  395,  966,  430]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00024.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1444,  816, 1639, 1007],
       [1142,  772, 1277,  911],
       [1433,  486, 1812,  893],
       [1185,  480, 1250,  538],
       [ 319,  678,  466,  766],
       [   0,  784,   79,  895],
       [ 569,  482,  654,  547]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <7x16 sparse matrix of type '<type 'numpy.float32'>'
	with 7 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00025.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1741,  674, 1917, 1043],
       [1287,  624, 1396,  720],
       [ 391,  638,  514,  713],
       [ 364,  547,  466,  613],
       [ 573,  522,  652,  576],
       [1081,  432, 1127,  478],
       [1244,  416, 1298,  457],
       [1423,  403, 1485,  461],
       [ 708,  414,  767,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00026.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 404,  793,  562,  924],
       [ 225,  695,  391,  816],
       [ 602,  499,  675,  549],
       [ 567,  444,  627,  485],
       [ 692,  438,  746,  486],
       [1100,  524, 1173,  580],
       [1312,  478, 1377,  539],
       [1525,  464, 1617,  538],
       [1067,  438, 1117,  480],
       [1160,  395, 1206,  436]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00027.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 348,  828,  531,  957],
       [ 256,  591,  377,  682],
       [ 692,  541,  773,  607],
       [ 516,  509,  604,  576],
       [1156,  720, 1283,  838],
       [1446,  597, 1556,  688],
       [1727,  561, 1864,  678],
       [1081,  532, 1162,  593],
       [1198,  459, 1260,  513],
       [ 706,  422,  760,  464]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <10x16 sparse matrix of type '<type 'numpy.float32'>'
	with 10 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00028.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1800,  897, 1916, 1047],
       [1137,  747, 1273,  880],
       [1277,  578, 1381,  672],
       [   0,  743,  173,  845],
       [ 667,  553,  752,  618],
       [ 494,  476,  567,  532],
       [ 800,  439,  854,  480],
       [ 642,  422,  700,  466],
       [1073,  468, 1129,  511],
       [1350,  422, 1416,  476],
       [1242,  420, 1292,  461]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00029.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 240,  936,  443, 1045],
       [ 373,  555,  467,  614],
       [ 783,  443,  835,  489],
       [ 617,  411,  675,  453],
       [1531,  932, 1758, 1039],
       [1102,  591, 1192,  670],
       [1317,  509, 1392,  563],
       [1439,  489, 1527,  551],
       [1079,  459, 1133,  505],
       [1169,  445, 1229,  493],
       [1433,  434, 1485,  476],
       [1246,  422, 1291,  466],
       [1141,  399, 1191,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00030.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1196,  964, 1377, 1045],
       [   0,  999,   91, 1047],
       [ 496,  722,  627,  811],
       [ 200,  634,  339,  724],
       [ 644,  580,  733,  651],
       [ 548,  461,  616,  503],
       [1519,  688, 1664,  799],
       [1608,  591, 1746,  701],
       [1254,  566, 1356,  655],
       [1104,  578, 1189,  651],
       [1517,  497, 1596,  563],
       [1321,  513, 1398,  568],
       [1177,  474, 1256,  539],
       [1417,  414, 1466,  449],
       [1066,  426, 1117,  470],
       [1296,  374, 1339,  422]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00031.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1192,  911, 1360, 1041],
       [1548,  955, 1760, 1039],
       [1512,  684, 1646,  788],
       [1287,  622, 1414,  739],
       [1698,  614, 1831,  711],
       [1529,  476, 1602,  534],
       [1085,  514, 1158,  591],
       [ 398,  626,  529,  713],
       [ 244,  607,  358,  680],
       [ 466,  501,  550,  557],
       [ 717,  526,  783,  570],
       [ 771,  459,  825,  501],
       [1081,  468, 1135,  516],
       [1346,  413, 1406,  470],
       [1169,  422, 1219,  466],
       [ 650,  407,  698,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00032.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1139,  743, 1291,  909],
       [1785,  616, 1908,  701],
       [1123,  599, 1217,  674],
       [1429,  468, 1516,  549],
       [1227,  503, 1298,  566],
       [ 383,  691,  519,  778],
       [   0,  745,  185,  848],
       [ 610,  486,  692,  547],
       [ 485,  478,  564,  534],
       [1346,  441, 1402,  482],
       [ 598,  432,  658,  474],
       [ 810,  432,  858,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00033.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1273,  995, 1442, 1047],
       [ 389,  551,  487,  611],
       [   0,  822,   33,  889],
       [1364,  688, 1491,  797],
       [1583,  564, 1719,  689],
       [1437,  509, 1519,  568],
       [1202,  486, 1266,  553],
       [1300,  480, 1364,  526],
       [1498,  466, 1562,  511],
       [ 673,  503,  744,  553],
       [ 710,  413,  775,  463],
       [ 617,  414,  669,  457],
       [1154,  414, 1210,  451],
       [1327,  405, 1375,  438],
       [1071,  393, 1108,  432]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00034.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1306,  636, 1412,  745],
       [1429,  595, 1525,  676],
       [1631,  632, 1760,  720],
       [1696,  568, 1798,  639],
       [1202,  497, 1270,  549],
       [1394,  461, 1462,  505],
       [1081,  459, 1137,  514],
       [1252,  420, 1302,  461],
       [ 577,  622,  692,  713],
       [ 325,  568,  425,  628],
       [ 566,  457,  633,  501],
       [ 796,  413,  846,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00035.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 612,  622,  710,  695],
       [   0,  857,   92, 1022],
       [1762,  899, 1919, 1045],
       [1300,  657, 1423,  745],
       [1102,  599, 1200,  695],
       [1535,  549, 1627,  618],
       [1310,  493, 1389,  549],
       [1072,  441, 1128,  489],
       [1358,  439, 1417,  478],
       [ 746,  476,  814,  532],
       [ 533,  459,  598,  507],
       [ 667,  403,  721,  434],
       [1150,  368, 1187,  401],
       [1348,  349, 1416,  414]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00036.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1825,  747, 1919,  870],
       [1452,  624, 1573,  716],
       [1096,  557, 1177,  632],
       [1471,  516, 1552,  574],
       [ 348,  576,  467,  661],
       [ 758,  480,  825,  530],
       [1408,  378, 1492,  459],
       [1298,  388, 1339,  420],
       [1160,  405, 1217,  453],
       [ 827,  405,  875,  449],
       [ 646,  401,  692,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00037.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1850,  974, 1919, 1043],
       [1181,  876, 1356, 1043],
       [1702,  668, 1850,  768],
       [1491,  413, 1606,  526],
       [1200,  478, 1273,  539],
       [ 464,  738,  604,  845],
       [  46,  720,  217,  816],
       [ 541,  459,  617,  516],
       [1085,  447, 1135,  493],
       [1258,  428, 1304,  470],
       [1346,  432, 1402,  470],
       [ 833,  405,  879,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00038.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 692,  738,  819,  847],
       [   0,  770,  117,  883],
       [1644,  493, 1816,  636],
       [1442,  497, 1521,  555],
       [1352,  518, 1425,  591],
       [1108,  563, 1189,  643],
       [1292,  599, 1404,  713],
       [1166,  447, 1223,  488],
       [1402,  407, 1448,  447],
       [ 691,  530,  767,  589],
       [ 417,  532,  508,  591],
       [ 652,  403,  710,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00039.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1583,  970, 1791, 1043],
       [1196,  895, 1366, 1045],
       [1592,  718, 1742,  861],
       [1623,  624, 1742,  707],
       [1231,  547, 1314,  611],
       [1491,  464, 1560,  516],
       [ 706,  699,  833,  797],
       [   0,  789,  108,  898],
       [ 354,  561,  460,  628],
       [ 842,  509,  914,  563],
       [ 589,  443,  646,  484],
       [ 792,  441,  846,  482],
       [1150,  416, 1194,  449]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00040.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1404,  795, 1554,  930],
       [1658,  559, 1764,  630],
       [1187,  486, 1252,  543],
       [1348,  391, 1396,  434],
       [1219,  357, 1277,  430],
       [1146,  407, 1192,  439],
       [1071,  384, 1110,  413],
       [  69,  701,  227,  791],
       [ 369,  555,  464,  614],
       [ 846,  495,  912,  543],
       [ 546,  463,  614,  509],
       [ 687,  393,  737,  424],
       [ 904,  416,  950,  451],
       [ 850,  384,  889,  420]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00041.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1292,  634, 1404,  724],
       [1404,  443, 1467,  499],
       [1183,  480, 1248,  528],
       [1254,  397, 1337,  488],
       [1071,  449, 1127,  488],
       [1144,  393, 1194,  436],
       [ 416,  699,  560,  824],
       [ 423,  526,  508,  578],
       [ 558,  453,  619,  499],
       [ 662,  399,  704,  432],
       [ 902,  409,  948,  445]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00042.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 216,  926,  433, 1043],
       [ 666,  751,  800,  857],
       [ 367,  653,  489,  738],
       [ 639,  511,  716,  572],
       [ 581,  438,  641,  480],
       [1092,  566, 1177,  638],
       [1287,  605, 1381,  686],
       [1506,  514, 1600,  591],
       [1331,  461, 1450,  591],
       [1171,  445, 1239,  503],
       [1058,  414, 1112,  468],
       [1237,  401, 1287,  438],
       [1312,  399, 1362,  439]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00043.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 217,  693,  371,  801],
       [ 477,  984,  671, 1043],
       [ 202,  605,  333,  678],
       [ 642,  564,  741,  641],
       [ 587,  503,  666,  564],
       [ 827,  513,  898,  568],
       [1185,  951, 1379, 1047],
       [1629, 1001, 1817, 1041],
       [1742,  664, 1910,  799],
       [1516,  593, 1717,  814],
       [1239,  547, 1331,  628],
       [1079,  522, 1158,  603],
       [1291,  459, 1356,  511],
       [1375,  449, 1442,  499],
       [1064,  443, 1121,  501],
       [ 739,  416,  787,  463],
       [1396,  405, 1448,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],
      dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00044.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 108,  982,  367, 1047],
       [   0,  716,  171,  862],
       [ 344,  668,  475,  757],
       [ 631,  757,  773,  886],
       [ 781,  570,  869,  641],
       [ 475,  528,  558,  593],
       [ 473,  478,  546,  526],
       [ 781,  443,  835,  495],
       [ 694,  428,  748,  468],
       [ 891,  418,  939,  457],
       [1154,  801, 1321,  982],
       [1404,  779, 1589,  954],
       [1091,  572, 1183,  676],
       [1417,  570, 1516,  643],
       [1510,  545, 1598,  605],
       [1510,  470, 1571,  514],
       [1335,  428, 1385,  476],
       [1152,  395, 1212,  441],
       [1058,  391, 1106,  441]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <19x16 sparse matrix of type '<type 'numpy.float32'>'
	with 19 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00045.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1771,  847, 1919, 1032],
       [1802,  730, 1919,  839],
       [1702,  580, 1817,  659],
       [1427,  497, 1504,  561],
       [1192,  466, 1267,  539],
       [1064,  463, 1133,  530],
       [1369,  438, 1431,  497],
       [1429,  422, 1485,  466],
       [  77,  839,  273,  959],
       [ 767,  626,  866,  703],
       [ 606,  576,  718,  668],
       [ 366,  522,  496,  611],
       [ 587,  514,  666,  563],
       [ 819,  516,  889,  578],
       [ 596,  439,  658,  497],
       [ 869,  447,  925,  491]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <16x16 sparse matrix of type '<type 'numpy.float32'>'
	with 16 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00046.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 179,  895,  460, 1041],
       [ 244,  588,  389,  678],
       [ 517,  563,  604,  616],
       [ 554,  436,  639,  491],
       [ 702,  430,  758,  472],
       [ 762,  449,  829,  503],
       [ 875,  466,  927,  513],
       [ 896,  418,  942,  457],
       [ 677,  393,  719,  428],
       [1108,  622, 1216,  732],
       [1289,  599, 1417,  709],
       [1627,  620, 1746,  716],
       [1477,  513, 1573,  586],
       [1537,  493, 1617,  547],
       [1366,  447, 1423,  493],
       [1179,  428, 1223,  468],
       [1408,  416, 1456,  451]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00047.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1610, 1026, 1804, 1047],
       [1698,  647, 1850,  772],
       [1767,  609, 1894,  697],
       [   0,  911,  141, 1048],
       [ 358,  636,  491,  728],
       [ 629,  561,  744,  657],
       [ 494,  466,  589,  532],
       [ 681,  447,  739,  489],
       [ 662,  378,  725,  426],
       [1237,  516, 1304,  570],
       [1479,  524, 1566,  584],
       [1494,  463, 1560,  507],
       [1271,  436, 1319,  480],
       [1085,  407, 1121,  447],
       [1402,  403, 1452,  439],
       [ 839,  388,  887,  430],
       [ 927,  393,  964,  428],
       [1310,  399, 1346,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
       1.], dtype=float32), 'height': 1080, 'gt_overlaps': <18x16 sparse matrix of type '<type 'numpy.float32'>'
	with 18 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00048.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1389,  716, 1525,  826],
       [1706,  668, 1850,  766],
       [1644,  551, 1741,  609],
       [1358,  522, 1429,  574],
       [1094,  497, 1152,  551],
       [1373,  453, 1431,  491],
       [1483,  453, 1542,  488],
       [ 635,  618,  737,  689],
       [ 414,  601,  529,  691],
       [   0,  772,   75,  890],
       [ 581,  499,  660,  559],
       [ 766,  445,  841,  503],
       [ 631,  405,  692,  449],
       [1250,  418, 1306,  459]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00049.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  857,  242, 1022],
       [1156,  680, 1262,  784],
       [1548,  693, 1685,  793],
       [1606,  528, 1694,  588],
       [1494,  538, 1579,  597],
       [1394,  470, 1467,  516],
       [1321,  493, 1396,  553],
       [1181,  489, 1246,  541],
       [ 335,  547,  441,  620],
       [ 608,  482,  681,  539],
       [ 777,  474,  839,  526],
       [ 692,  426,  746,  484],
       [1075,  430, 1129,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00050.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1298,  659, 1410,  753],
       [1475,  624, 1591,  716],
       [1548,  568, 1644,  641],
       [1739,  703, 1891,  803],
       [   2,  724,  183,  828],
       [ 469,  582,  571,  668],
       [1093,  523, 1166,  591],
       [1202,  488, 1273,  547],
       [1075,  430, 1129,  472],
       [ 541,  449,  610,  501],
       [ 710,  413,  769,  463],
       [ 844,  401,  892,  436],
       [1323,  405, 1369,  445],
       [ 766,  384,  814,  426]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00051.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1871,  786, 1919,  889],
       [1152,  747, 1285,  870],
       [1319,  659, 1435,  755],
       [1102,  524, 1183,  582],
       [1394,  453, 1456,  501],
       [1317,  405, 1366,  447],
       [1244,  411, 1298,  459],
       [1162,  411, 1210,  449],
       [   0,  997,   69, 1048],
       [ 394,  534,  487,  593],
       [ 641,  470,  710,  524],
       [ 656,  393,  708,  434],
       [ 775,  374,  823,  407]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00052.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[   0,  766,  123,  902],
       [ 414,  616,  537,  699],
       [1171,  749, 1319,  878],
       [1529,  545, 1608,  611],
       [1312,  478, 1379,  545],
       [1200,  480, 1267,  528],
       [ 575,  438,  633,  482],
       [ 733,  411,  783,  451],
       [1379,  457, 1439,  499]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <9x16 sparse matrix of type '<type 'numpy.float32'>'
	with 9 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00053.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1783,  709, 1917,  843],
       [1446,  614, 1573,  713],
       [1287,  624, 1392,  716],
       [1496,  539, 1592,  611],
       [1431,  413, 1483,  463],
       [1317,  405, 1371,  459],
       [ 360,  663,  483,  751],
       [ 367,  541,  475,  618],
       [ 621,  484,  696,  539],
       [ 671,  388,  723,  422],
       [1077,  413, 1125,  447]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <11x16 sparse matrix of type '<type 'numpy.float32'>'
	with 11 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00054.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1756,  714, 1917,  839],
       [1535,  472, 1604,  532],
       [1398,  468, 1477,  538],
       [1091,  497, 1152,  553],
       [1260,  445, 1319,  486],
       [ 314,  636,  485,  772],
       [ 256,  595,  373,  682],
       [ 573,  505,  650,  564],
       [ 562,  445,  635,  507],
       [ 725,  416,  781,  451],
       [1308,  405, 1362,  447],
       [1400,  414, 1450,  455]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <12x16 sparse matrix of type '<type 'numpy.float32'>'
	with 12 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00055.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1142,  676, 1254,  778],
       [1558,  572, 1675,  668],
       [1717,  570, 1829,  657],
       [1354,  541, 1441,  599],
       [ 362,  841,  537,  966],
       [ 371,  653,  492,  741],
       [ 556,  484,  658,  576],
       [ 500,  474,  573,  524],
       [1502,  474, 1577,  522],
       [1381,  455, 1435,  507],
       [1094,  451, 1135,  489],
       [ 671,  422,  723,  468],
       [1237,  409, 1285,  443]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00056.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1566,  722, 1716,  836],
       [1708,  586, 1816,  657],
       [1502,  541, 1591,  618],
       [1117,  557, 1192,  622],
       [1287,  472, 1350,  509],
       [1185,  461, 1246,  511],
       [1058,  468, 1123,  514],
       [ 667,  564,  766,  624],
       [ 589,  513,  658,  561],
       [ 667,  418,  733,  480],
       [1394,  413, 1442,  449],
       [1246,  416, 1291,  457],
       [ 623,  407,  669,  453]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 'height': 1080, 'gt_overlaps': <13x16 sparse matrix of type '<type 'numpy.float32'>'
	with 13 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00057.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1221,  838, 1373,  978],
       [1777,  711, 1917,  863],
       [1302,  630, 1416,  732],
       [1100,  607, 1191,  691],
       [1385,  572, 1481,  632],
       [1514,  476, 1577,  528],
       [1304,  480, 1367,  532],
       [1152,  426, 1200,  472],
       [ 794,  447,  844,  501],
       [ 692,  434,  750,  478],
       [ 731,  691,  844,  784],
       [ 485,  732,  627,  834],
       [ 210,  741,  379,  878],
       [ 277,  605,  392,  688]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00058.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[1627,  789, 1796,  916],
       [ 641,  730,  810,  905],
       [ 191,  784,  367,  889],
       [ 196,  603,  346,  714],
       [ 537,  539,  627,  611],
       [ 510,  484,  577,  538],
       [ 710,  522,  791,  578],
       [ 848,  507,  919,  561],
       [1731,  599, 1842,  678],
       [1431,  580, 1524,  657],
       [1200,  513, 1269,  572],
       [1360,  426, 1433,  484],
       [1241,  466, 1306,  516],
       [1241,  426, 1306,  466]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <14x16 sparse matrix of type '<type 'numpy.float32'>'
	with 14 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00059.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 294,  861,  510, 1032],
       [   0,  930,  152, 1047],
       [ 548,  543,  627,  611],
       [ 454,  489,  544,  555],
       [ 825,  514,  912,  572],
       [ 683,  441,  737,  497],
       [ 806,  428,  856,  468],
       [ 902,  420,  946,  461],
       [ 627,  414,  683,  457],
       [1331,  695, 1444,  795],
       [1723,  824, 1910,  961],
       [1402,  593, 1502,  678],
       [1466,  501, 1564,  570],
       [1496,  451, 1554,  491],
       [1335,  516, 1408,  570],
       [1173,  451, 1231,  491],
       [1241,  413, 1289,  451]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <17x16 sparse matrix of type '<type 'numpy.float32'>'
	with 17 stored elements in Compressed Sparse Row format>}, {'gt_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'max_classes': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'image': '/media/ad/DATA/aicitychallenge/tf-faster-rcnn/data/car_track1/dat/1/Loc1_5_00060.jpeg', 'flipped': True, 'width': 1920, 'boxes': array([[ 317,  884,  506, 1024],
       [   4,  905,  166, 1047],
       [ 196,  624,  329,  718],
       [ 429,  601,  539,  674],
       [ 644,  568,  742,  655],
       [1804,  943, 1917, 1041],
       [1514,  684, 1656,  780],
       [1652,  626, 1829,  738],
       [1667,  549, 1773,  614],
       [1252,  574, 1348,  643],
       [1312,  478, 1369,  530],
       [1173,  443, 1223,  478],
       [ 694,  449,  748,  489],
       [ 894,  416,  946,  472],
       [ 592,  420,  656,  468]], dtype=uint16), 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
      dtype=float32), 'height': 1080, 'gt_overlaps': <15x16 sparse matrix of type '<type 'numpy.float32'>'
	with 15 stored elements in Compressed Sparse Row format>}]
1
[]
0
Traceback (most recent call last):
  File "./tools/trainval_net.py", line 142, in <module>
    max_iters=args.max_iters)
  File "/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tools/../lib/model/train_val.py", line 381, in train_net
    sw.train_model(sess, max_iters)
  File "/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tools/../lib/model/train_val.py", line 291, in train_model
    blobs_val = self.data_layer_val.forward()
  File "/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tools/../lib/roi_data_layer/layer.py", line 88, in forward
    blobs = self._get_next_minibatch()
  File "/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tools/../lib/roi_data_layer/layer.py", line 84, in _get_next_minibatch
    return get_minibatch(minibatch_db, self._num_classes)
  File "/media/ad/DATA/aicitychallenge/tf-faster-rcnn/tools/../lib/roi_data_layer/minibatch.py", line 26, in get_minibatch
    assert(cfg.TRAIN.BATCH_SIZE % num_images == 0), \
ZeroDivisionError: integer division or modulo by zero
Command exited with non-zero status 1
11.90user 1.78system 0:10.24elapsed 133%CPU (0avgtext+0avgdata 2276084maxresident)k
0inputs+0outputs (0major+595670minor)pagefaults 0swaps
